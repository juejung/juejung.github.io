

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>24. Machine Learning I: Introduction to Machine Learning &mdash; Computational Economics 1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="25. Machine Learning II: Categorization Algorithm" href="Slides_MachineLearning_2.html" />
    <link rel="prev" title="23. Growth Models" href="Slides_Growth.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Computational Economics
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Slides_CourseAdministration.html">1. Course Administration</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Basics.html">2. First Steps in Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_DataStructures.html">3. Python Data Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Loop.html">4. Basic Programming Techniques</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Debugging.html">5. Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Arrays.html">6. Vectors and Matrices</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Plot.html">7. Plotting using <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Functions.html">8. Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_OOP.html">9. Object Oriented Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Data_1.html">10. Working with Data I: Data Cleaning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Data_2.html">11. Working with Data II: Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Data_3.html">12. Working with Data III: Case Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_WebData.html">13. Working with Data from the Web I</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_WebData_2.html">14. Working with Data from the Web II</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_RegularExpressions.html">15. Regular Expressions</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Random.html">16. Random Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Random2.html">17. Random Numbers II: An Infectious Disease Simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Root.html">18. Root Finding</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Optimization_1.html">19. Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Optimization_2_Cake.html">20. Constrained Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_OLG_I.html">21. A Simple OLG Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_OLG_II.html">22. An OLG Model with Labor-Leisure Choice</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Growth.html">23. Growth Models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">24. Machine Learning I: Introduction to Machine Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#different-types-of-machine-learning-algorithms">24.1. Different Types of Machine Learning Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#a-first-regression-model-example">24.2. A First Regression Model Example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#downloading-the-data">24.2.1. Downloading the Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#inspecting-the-data">24.2.2. Inspecting the Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#splitting-the-data">24.2.3. Splitting the Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#visualize-data-to-gain-insight">24.2.4. Visualize data to gain insight</a></li>
<li class="toctree-l3"><a class="reference internal" href="#prepare-data">24.2.5. Prepare data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-a-regression-model">24.2.6. Training a Regression Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fine-tune-model">24.2.7. Fine Tune Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#key-concepts-and-summary">24.3. Key Concepts and Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#self-check-questions">24.4. Self-Check Questions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Slides_MachineLearning_2.html">25. Machine Learning II: Categorization Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="Slides_Assignments.html">26. Assignments</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Computational Economics</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li><span class="section-number">24. </span>Machine Learning I: Introduction to Machine Learning</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/Slides_MachineLearning_1.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="machine-learning-i-introduction-to-machine-learning">
<h1><span class="section-number">24. </span>Machine Learning I: Introduction to Machine Learning<a class="headerlink" href="#machine-learning-i-introduction-to-machine-learning" title="Permalink to this headline">Â¶</a></h1>
<div class="sidebar" id="machinelearningi">
<p class="sidebar-title">Section Learning Objectives</p>
<blockquote>
<div><ul class="simple">
<li><p>Introduction to machine learning</p></li>
<li><p>Simple example</p></li>
</ul>
</div></blockquote>
</div>
<p id="index-0">This chapter and the next are heavily built on two chapters in <a class="reference internal" href="Slides_MachineLearning_2.html#geron2019" id="id1"><span>[Geron2019]</span></a>
Hands-On Machine Learning with Scikit-Learn, Kera &amp; TensorFlow.
You can find a link to the GitHub page of this textbook at <a class="reference external" href="https://github.com/ageron/handson-ml/">Geron GitHub</a></p>
<p>Machine learning is ubiquitous. Machine learning algorithm guide your daily
google searches, determine the way Netflix presents its offerings to you, guide
your selections when shopping on sites such as Amazon, translate your spoken
words into code that your Phone or any other of the many voice assistants can
process further into meaningful services for you, drive Teslas semi-autonomous,
or simply recognize your face on a photo you upload onto Facebook. These are
just a few of the many many examples where Machine Learning has entered your
life, whether you are aware of it or not.</p>
<div class="figure align-center" id="fig0-ml-timeline">
<a class="reference internal image-reference" href="_images/MachineLearningTimeLine.jpeg"><img alt="_images/MachineLearningTimeLine.jpeg" src="_images/MachineLearningTimeLine.jpeg" style="width: 540.0px; height: 290.7px;" /></a>
<p class="caption"><span class="caption-number">Fig. 24.1 </span><span class="caption-text">Brief History of Machine Learning</span><a class="headerlink" href="#fig0-ml-timeline" title="Permalink to this image">Â¶</a></p>
</div>
<p>One of the earliest examples of a Machine Learning algorithm that you are
familiar with is the <strong>Spam Filter</strong>. We will be using this example to further
explain what machine learning does and how different machine learning
algorithms can be classified.</p>
<div class="section" id="different-types-of-machine-learning-algorithms">
<h2><span class="section-number">24.1. </span>Different Types of Machine Learning Algorithms<a class="headerlink" href="#different-types-of-machine-learning-algorithms" title="Permalink to this headline">Â¶</a></h2>
<p>Machine learning algorithms can be classified according to the following
criteria:</p>
<blockquote>
<div><ol class="arabic simple">
<li><dl class="simple">
<dt>Supervised vs. unsupervised vs. reinforcement learning</dt><dd><p>Are they trained (estimated) with human supervision, without supervision,
or do they reinforce actions based on rewards and penalties.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Online vs. batch learning</dt><dd><p>Do they learn incrementally as data becomes available or do they require
âall of the dataâ at once</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Instance-based vs. model-based learning</dt><dd><p>Do they compare new data points to known data points or do they detect
patterns building a predictive model (based on parameters)</p>
</dd>
</dl>
</li>
</ol>
</div></blockquote>
<p>Letâs discuss this classification in some more detail.
In <strong>supervised learning</strong>, the training set (i.e., data) you feed to the
algorithm includes the desired outcome or solution, called label (i.e., the
dependent or outcome variable). In other words, if you know what your outcome
variable is, i.e., what it measures, then we say it has a label because you are
able to classify the outcome variable according to some criteria.</p>
<p>If, on the other hand, you do not even know what exactly your outcome variable
is, i.e., it is missing a label that would allow a quick classification of this
variable, then we are talking about so called <strong>Unsupervised learning</strong> which
deals with unlabeled data. In this instance we are usually trying to find some
patterns in the outcome variable that we can then use for a possible
interpretation of what the outcome variable actually measures.</p>
<p><a class="reference internal" href="#fig1-ml-classification"><span class="std std-numref">Fig. 24.2</span></a> summarizes the different types of machine
learning according to our first classification above where we distinguished
between</p>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Supervised Learning,</p></li>
<li><p>Unsupervised Learning, and</p></li>
<li><p>Reinforcement Learning.</p></li>
</ol>
</div></blockquote>
<div class="figure align-center" id="fig1-ml-classification">
<a class="reference internal image-reference" href="_images/MLclassification.png"><img alt="_images/MLclassification.png" src="_images/MLclassification.png" style="width: 699.0px; height: 500.0px;" /></a>
<p class="caption"><span class="caption-number">Fig. 24.2 </span><span class="caption-text">Classification of ML algorithms.</span><a class="headerlink" href="#fig1-ml-classification" title="Permalink to this image">Â¶</a></p>
</div>
<p><a class="reference internal" href="#tab-metricsvsml"><span class="std std-numref">Table 24.1</span></a> contrasts the language we use in Econometrics with the
language commonly used in Machine Learning.</p>
<table class="docutils align-default" id="tab-metricsvsml">
<caption><span class="caption-number">Table 24.1 </span><span class="caption-text">The Language of Econometrics and Machine Learning</span><a class="headerlink" href="#tab-metricsvsml" title="Permalink to this table">Â¶</a></caption>
<colgroup>
<col style="width: 15%" />
<col style="width: 29%" />
<col style="width: 56%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Item</p></th>
<th class="head"><p>Econometrics</p></th>
<th class="head"><p>Machine Learning2011</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Data</p></td>
<td><p>Data/Obs.</p></td>
<td><p>Training data/set</p></td>
</tr>
<tr class="row-odd"><td><p>y</p></td>
<td><p>Dependent var</p></td>
<td><p>Label</p></td>
</tr>
<tr class="row-even"><td><p>x or X</p></td>
<td><p>Independent var</p></td>
<td><p>Feature/predictor</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>Estimation</p></td>
<td><p>Training an algorithm or model</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="a-first-regression-model-example">
<h2><span class="section-number">24.2. </span>A First Regression Model Example<a class="headerlink" href="#a-first-regression-model-example" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="downloading-the-data">
<h3><span class="section-number">24.2.1. </span>Downloading the Data<a class="headerlink" href="#downloading-the-data" title="Permalink to this headline">Â¶</a></h3>
<p>We again start by first importing some libraries.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># https://github.com/ageron/handson-ml/</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tarfile</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="n">urllib</span>
</pre></div>
</div>
<p>We first need to download the data from GitHub:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">DOWNLOAD_ROOT</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/ageron/handson-ml/master/&quot;</span>
<span class="n">HOUSING_URL</span> <span class="o">=</span> <span class="n">DOWNLOAD_ROOT</span> <span class="o">+</span> <span class="s2">&quot;datasets/housing/housing.tgz&quot;</span>

<span class="k">def</span> <span class="nf">fetch_housing_data</span><span class="p">(</span><span class="n">housing_url</span><span class="o">=</span><span class="n">HOUSING_URL</span><span class="p">):</span>
    <span class="n">tgz_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;housing.tgz&quot;</span><span class="p">)</span>
    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">housing_url</span><span class="p">,</span> <span class="n">tgz_path</span><span class="p">)</span>
    <span class="n">housing_tgz</span> <span class="o">=</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">tgz_path</span><span class="p">)</span>
    <span class="n">housing_tgz</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
    <span class="n">housing_tgz</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">fetch_housing_data</span><span class="p">()</span>
</pre></div>
</div>
<p>Once that is done, we store the
data on our local drive. You want to avoid downloading the data each time you
run the script file. So download it once, store it and then comment the
download section of your code out and just read the data from your local drive
using  the <code class="docutils literal notranslate"><span class="pre">pd.read_csv()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">numpy</span></code> library.
We then can use a few commands to look at our data which is organized or stored in a
Pandas DataFrame object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;Lecture_MachineLearning_1/housing.csv&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">housing</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>   <span class="n">longitude</span>  <span class="n">latitude</span>  <span class="n">housing_median_age</span>  <span class="n">total_rooms</span>
<span class="n">total_bedrooms</span>  \
<span class="mi">0</span>    <span class="o">-</span><span class="mf">122.23</span>     <span class="mf">37.88</span>                <span class="mf">41.0</span>        <span class="mf">880.0</span>
<span class="mf">129.0</span>
<span class="mi">1</span>    <span class="o">-</span><span class="mf">122.22</span>     <span class="mf">37.86</span>                <span class="mf">21.0</span>       <span class="mf">7099.0</span>
<span class="mf">1106.0</span>
<span class="mi">2</span>    <span class="o">-</span><span class="mf">122.24</span>     <span class="mf">37.85</span>                <span class="mf">52.0</span>       <span class="mf">1467.0</span>
<span class="mf">190.0</span>
<span class="mi">3</span>    <span class="o">-</span><span class="mf">122.25</span>     <span class="mf">37.85</span>                <span class="mf">52.0</span>       <span class="mf">1274.0</span>
<span class="mf">235.0</span>
<span class="mi">4</span>    <span class="o">-</span><span class="mf">122.25</span>     <span class="mf">37.85</span>                <span class="mf">52.0</span>       <span class="mf">1627.0</span>
<span class="mf">280.0</span>

   <span class="n">population</span>  <span class="n">households</span>  <span class="n">median_income</span>  <span class="n">median_house_value</span>
<span class="n">ocean_proximity</span>
<span class="mi">0</span>       <span class="mf">322.0</span>       <span class="mf">126.0</span>         <span class="mf">8.3252</span>            <span class="mf">452600.0</span>
<span class="n">NEAR</span> <span class="n">BAY</span>
<span class="mi">1</span>      <span class="mf">2401.0</span>      <span class="mf">1138.0</span>         <span class="mf">8.3014</span>            <span class="mf">358500.0</span>
<span class="n">NEAR</span> <span class="n">BAY</span>
<span class="mi">2</span>       <span class="mf">496.0</span>       <span class="mf">177.0</span>         <span class="mf">7.2574</span>            <span class="mf">352100.0</span>
<span class="n">NEAR</span> <span class="n">BAY</span>
<span class="mi">3</span>       <span class="mf">558.0</span>       <span class="mf">219.0</span>         <span class="mf">5.6431</span>            <span class="mf">341300.0</span>
<span class="n">NEAR</span> <span class="n">BAY</span>
<span class="mi">4</span>       <span class="mf">565.0</span>       <span class="mf">259.0</span>         <span class="mf">3.8462</span>            <span class="mf">342200.0</span>
<span class="n">NEAR</span> <span class="n">BAY</span>
</pre></div>
</div>
<p>We can get a quick summary of our data using the <code class="docutils literal notranslate"><span class="pre">.info()</span></code> function on the
dataframe.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">housing</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 10 columns):
 #   Column              Non-Null Count  Dtype
---  ------              --------------  -----
 0   longitude           20640 non-null  float64
 1   latitude            20640 non-null  float64
 2   housing_median_age  20640 non-null  float64
 3   total_rooms         20640 non-null  float64
 4   total_bedrooms      20433 non-null  float64
 5   population          20640 non-null  float64
 6   households          20640 non-null  float64
 7   median_income       20640 non-null  float64
 8   median_house_value  20640 non-null  float64
 9   ocean_proximity     20640 non-null  object
dtypes: float64(9), object(1)
memory usage: 1.6+ MB
None
</pre></div>
</div>
</div>
<div class="section" id="inspecting-the-data">
<h3><span class="section-number">24.2.2. </span>Inspecting the Data<a class="headerlink" href="#inspecting-the-data" title="Permalink to this headline">Â¶</a></h3>
<p>We can also get some summary statistic for specific feature variables (in
econometrics we refer to these as independent variables). We can check the
variable <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> for instance. It is a categorical variable. We
cannot do any numerical statistics with this but we can get a feel for this
variable by counting how many observation by category we have.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;ocean_proximity&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>     <span class="mi">9136</span>
<span class="n">INLAND</span>        <span class="mi">6551</span>
<span class="n">NEAR</span> <span class="n">OCEAN</span>    <span class="mi">2658</span>
<span class="n">NEAR</span> <span class="n">BAY</span>      <span class="mi">2290</span>
<span class="n">ISLAND</span>           <span class="mi">5</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">ocean_proximity</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">int64</span>
</pre></div>
</div>
<p>Finally, we can use the <code class="docutils literal notranslate"><span class="pre">.describe()</span></code> dataframe method (or function) to get
certain summary statistics for each data column.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">housing</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>          <span class="n">longitude</span>      <span class="n">latitude</span>  <span class="n">housing_median_age</span>   <span class="n">total_rooms</span>  \
<span class="n">count</span>  <span class="mf">20640.000000</span>  <span class="mf">20640.000000</span>        <span class="mf">20640.000000</span>  <span class="mf">20640.000000</span>
<span class="n">mean</span>    <span class="o">-</span><span class="mf">119.569704</span>     <span class="mf">35.631861</span>           <span class="mf">28.639486</span>   <span class="mf">2635.763081</span>
<span class="n">std</span>        <span class="mf">2.003532</span>      <span class="mf">2.135952</span>           <span class="mf">12.585558</span>   <span class="mf">2181.615252</span>
<span class="nb">min</span>     <span class="o">-</span><span class="mf">124.350000</span>     <span class="mf">32.540000</span>            <span class="mf">1.000000</span>      <span class="mf">2.000000</span>
<span class="mi">25</span><span class="o">%</span>     <span class="o">-</span><span class="mf">121.800000</span>     <span class="mf">33.930000</span>           <span class="mf">18.000000</span>   <span class="mf">1447.750000</span>
<span class="mi">50</span><span class="o">%</span>     <span class="o">-</span><span class="mf">118.490000</span>     <span class="mf">34.260000</span>           <span class="mf">29.000000</span>   <span class="mf">2127.000000</span>
<span class="mi">75</span><span class="o">%</span>     <span class="o">-</span><span class="mf">118.010000</span>     <span class="mf">37.710000</span>           <span class="mf">37.000000</span>   <span class="mf">3148.000000</span>
<span class="nb">max</span>     <span class="o">-</span><span class="mf">114.310000</span>     <span class="mf">41.950000</span>           <span class="mf">52.000000</span>  <span class="mf">39320.000000</span>

       <span class="n">total_bedrooms</span>    <span class="n">population</span>    <span class="n">households</span>  <span class="n">median_income</span>  \
<span class="n">count</span>    <span class="mf">20433.000000</span>  <span class="mf">20640.000000</span>  <span class="mf">20640.000000</span>   <span class="mf">20640.000000</span>
<span class="n">mean</span>       <span class="mf">537.870553</span>   <span class="mf">1425.476744</span>    <span class="mf">499.539680</span>       <span class="mf">3.870671</span>
<span class="n">std</span>        <span class="mf">421.385070</span>   <span class="mf">1132.462122</span>    <span class="mf">382.329753</span>       <span class="mf">1.899822</span>
<span class="nb">min</span>          <span class="mf">1.000000</span>      <span class="mf">3.000000</span>      <span class="mf">1.000000</span>       <span class="mf">0.499900</span>
<span class="mi">25</span><span class="o">%</span>        <span class="mf">296.000000</span>    <span class="mf">787.000000</span>    <span class="mf">280.000000</span>       <span class="mf">2.563400</span>
<span class="mi">50</span><span class="o">%</span>        <span class="mf">435.000000</span>   <span class="mf">1166.000000</span>    <span class="mf">409.000000</span>       <span class="mf">3.534800</span>
<span class="mi">75</span><span class="o">%</span>        <span class="mf">647.000000</span>   <span class="mf">1725.000000</span>    <span class="mf">605.000000</span>       <span class="mf">4.743250</span>
<span class="nb">max</span>       <span class="mf">6445.000000</span>  <span class="mf">35682.000000</span>   <span class="mf">6082.000000</span>      <span class="mf">15.000100</span>

       <span class="n">median_house_value</span>
<span class="n">count</span>        <span class="mf">20640.000000</span>
<span class="n">mean</span>        <span class="mf">206855.816909</span>
<span class="n">std</span>         <span class="mf">115395.615874</span>
<span class="nb">min</span>          <span class="mf">14999.000000</span>
<span class="mi">25</span><span class="o">%</span>         <span class="mf">119600.000000</span>
<span class="mi">50</span><span class="o">%</span>         <span class="mf">179700.000000</span>
<span class="mi">75</span><span class="o">%</span>         <span class="mf">264725.000000</span>
<span class="nb">max</span>         <span class="mf">500001.000000</span>
</pre></div>
</div>
<p>We next start with analyzing our data using graphs and simple statistics.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># %matplotlib inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">housing</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="c1"># save_fig(&quot;attribute_histogram_plots&quot;)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/Slides_MachineLearning_1_figure6_1.png"><img alt="_images/Slides_MachineLearning_1_figure6_1.png" src="_images/Slides_MachineLearning_1_figure6_1.png" style="width: 15cm;" /></a>
</div>
<div class="section" id="splitting-the-data">
<h3><span class="section-number">24.2.3. </span>Splitting the Data<a class="headerlink" href="#splitting-the-data" title="Permalink to this headline">Â¶</a></h3>
<p>In machine learning it is important to be able to assess how well your trained
model can predict outcome variables (or label variables in the case of
supervised machine learning). In order to do this we need to split the sample
into a <strong>training sample</strong> that you use to train (estimate) the model with and into
a <strong>test sample</strong> that you can then use to verify how well your model makes out
of sample predictions.</p>
<p>It is important that you randomly split the sample and that both samples
maintain the features of the overall sample. For instance if your main sample
contains 45 percent men, then you want to split the sample in such a way that
the training sample has roughly 45 percent men in it and the test sample has
roughly 45 percent men in it.</p>
<p>In order to accomplish this we use the built in command <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code>
from the <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> machine learning library. When you call this function you
need to specify how large you want the test sample to be. Below we choose a
split that maintains 80 percent of the observations in the raw data for
the training sample and 20 percent for test sample. We set the random seed by
hand, so that our results become reproducible, i.e., the sample is split in
exactly the same way each time we run the script file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># to make this notebook&#39;s output identical at every run</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<p>We can now inspect the test sample.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">test_set</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>       <span class="n">longitude</span>  <span class="n">latitude</span>  <span class="n">housing_median_age</span>  <span class="n">total_rooms</span>
<span class="n">total_bedrooms</span>  \
<span class="mi">20046</span>    <span class="o">-</span><span class="mf">119.01</span>     <span class="mf">36.06</span>                <span class="mf">25.0</span>       <span class="mf">1505.0</span>
<span class="n">NaN</span>
<span class="mi">3024</span>     <span class="o">-</span><span class="mf">119.46</span>     <span class="mf">35.14</span>                <span class="mf">30.0</span>       <span class="mf">2943.0</span>
<span class="n">NaN</span>
<span class="mi">15663</span>    <span class="o">-</span><span class="mf">122.44</span>     <span class="mf">37.80</span>                <span class="mf">52.0</span>       <span class="mf">3830.0</span>
<span class="n">NaN</span>
<span class="mi">20484</span>    <span class="o">-</span><span class="mf">118.72</span>     <span class="mf">34.28</span>                <span class="mf">17.0</span>       <span class="mf">3051.0</span>
<span class="n">NaN</span>
<span class="mi">9814</span>     <span class="o">-</span><span class="mf">121.93</span>     <span class="mf">36.62</span>                <span class="mf">34.0</span>       <span class="mf">2351.0</span>
<span class="n">NaN</span>

       <span class="n">population</span>  <span class="n">households</span>  <span class="n">median_income</span>  <span class="n">median_house_value</span>  \
<span class="mi">20046</span>      <span class="mf">1392.0</span>       <span class="mf">359.0</span>         <span class="mf">1.6812</span>             <span class="mf">47700.0</span>
<span class="mi">3024</span>       <span class="mf">1565.0</span>       <span class="mf">584.0</span>         <span class="mf">2.5313</span>             <span class="mf">45800.0</span>
<span class="mi">15663</span>      <span class="mf">1310.0</span>       <span class="mf">963.0</span>         <span class="mf">3.4801</span>            <span class="mf">500001.0</span>
<span class="mi">20484</span>      <span class="mf">1705.0</span>       <span class="mf">495.0</span>         <span class="mf">5.7376</span>            <span class="mf">218600.0</span>
<span class="mi">9814</span>       <span class="mf">1063.0</span>       <span class="mf">428.0</span>         <span class="mf">3.7250</span>            <span class="mf">278000.0</span>

      <span class="n">ocean_proximity</span>
<span class="mi">20046</span>          <span class="n">INLAND</span>
<span class="mi">3024</span>           <span class="n">INLAND</span>
<span class="mi">15663</span>        <span class="n">NEAR</span> <span class="n">BAY</span>
<span class="mi">20484</span>       <span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>
<span class="mi">9814</span>       <span class="n">NEAR</span> <span class="n">OCEAN</span>
</pre></div>
</div>
<p>One thing that is important when splitting the data is to maintain the
composition of the data in the subsamples, so that subsamples correctly
represent the large sample. Let us look at an example.</p>
<p>If we analyze income using the histogram plot we have the following
distribution of income.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;median_income&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="o">&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/Slides_MachineLearning_1_figure9_1.png"><img alt="_images/Slides_MachineLearning_1_figure9_1.png" src="_images/Slides_MachineLearning_1_figure9_1.png" style="width: 15cm;" /></a>
<p>We can also make a categorical variable out of income using the following
command.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;income_cat&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;median_income&quot;</span><span class="p">],</span>
                               <span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span>
                               <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
<p>In order to do that we need to define the bins and assign labels to each bin.
Where label <code class="docutils literal notranslate"><span class="pre">1</span></code> indicates the low income group, label <code class="docutils literal notranslate"><span class="pre">2</span></code> indicates income
between zero and 1.5, etc. We can then plot histograms of this new categorical
variable.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;income_cat&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>

<span class="n">housing</span><span class="p">[</span><span class="s2">&quot;income_cat&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span>    <span class="mi">7236</span>
<span class="mi">2</span>    <span class="mi">6581</span>
<span class="mi">4</span>    <span class="mi">3639</span>
<span class="mi">5</span>    <span class="mi">2362</span>
<span class="mi">1</span>     <span class="mi">822</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">income_cat</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">int64</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="o">&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/Slides_MachineLearning_1_figure11_1.png"><img alt="_images/Slides_MachineLearning_1_figure11_1.png" src="_images/Slides_MachineLearning_1_figure11_1.png" style="width: 15cm;" /></a>
<p>When we split the sample into a training set and a test set we need to make
sure that the distribution of the different income groups is maintained in the
subsamples. We want to avoid as situation where we have, letâs say richer
households in the training sample and relatively poorer households in the
testing sample. We can accomplish this with <strong>stratified sampling</strong>. The built in
command <code class="docutils literal notranslate"><span class="pre">StratifiedShuffleSplit</span></code> will split the data ensuring that the
distribution is maintained.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedShuffleSplit</span>

<span class="n">split</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">split</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span> <span class="n">housing</span><span class="p">[</span><span class="s2">&quot;income_cat&quot;</span><span class="p">]):</span>
    <span class="n">strat_train_set</span> <span class="o">=</span> <span class="n">housing</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
    <span class="n">strat_test_set</span> <span class="o">=</span> <span class="n">housing</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
</pre></div>
</div>
<p>We can check this by comparing the histogram we made earlier for the entire
data with the histogram for the income variables of the stratified test sample.
You see that the proportions of the different income groups are maintained
because we split the sample according to the income strata in the above code
block.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">strat_test_set</span><span class="p">[</span><span class="s2">&quot;income_cat&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">strat_test_set</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span>    <span class="mf">0.350533</span>
<span class="mi">2</span>    <span class="mf">0.318798</span>
<span class="mi">4</span>    <span class="mf">0.176357</span>
<span class="mi">5</span>    <span class="mf">0.114341</span>
<span class="mi">1</span>    <span class="mf">0.039971</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">income_cat</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</pre></div>
</div>
<p>We can compare it to the income categories of the original data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;income_cat&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">housing</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">3</span>    <span class="mf">0.350581</span>
<span class="mi">2</span>    <span class="mf">0.318847</span>
<span class="mi">4</span>    <span class="mf">0.176308</span>
<span class="mi">5</span>    <span class="mf">0.114438</span>
<span class="mi">1</span>    <span class="mf">0.039826</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">income_cat</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</pre></div>
</div>
<p>We next do it more systematic across the full data, the stratified test set,
and the non-stratified test set. We then plot the proportions of the income
groups for each data set. You want the proportions in the test set be very
close to the income proportions in the full data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">income_cat_proportions</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;income_cat&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">housing</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">compare_props</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Overall&quot;</span><span class="p">:</span> <span class="n">income_cat_proportions</span><span class="p">(</span><span class="n">housing</span><span class="p">),</span>
    <span class="s2">&quot;Stratified&quot;</span><span class="p">:</span> <span class="n">income_cat_proportions</span><span class="p">(</span><span class="n">strat_test_set</span><span class="p">),</span>
    <span class="s2">&quot;Random&quot;</span><span class="p">:</span> <span class="n">income_cat_proportions</span><span class="p">(</span><span class="n">test_set</span><span class="p">),</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
<span class="n">compare_props</span><span class="p">[</span><span class="s2">&quot;Rand. </span><span class="si">%e</span><span class="s2">rror&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">compare_props</span><span class="p">[</span><span class="s2">&quot;Random&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">compare_props</span><span class="p">[</span><span class="s2">&quot;Overall&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">100</span>
<span class="n">compare_props</span><span class="p">[</span><span class="s2">&quot;Strat. </span><span class="si">%e</span><span class="s2">rror&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">compare_props</span><span class="p">[</span><span class="s2">&quot;Stratified&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">compare_props</span><span class="p">[</span><span class="s2">&quot;Overall&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">100</span>
</pre></div>
</div>
<p>Now letâs have a look at the different methods and how they compare to the
original data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">compare_props</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">Overall</span>  <span class="n">Stratified</span>    <span class="n">Random</span>  <span class="n">Rand</span><span class="o">.</span> <span class="o">%</span><span class="n">error</span>  <span class="n">Strat</span><span class="o">.</span> <span class="o">%</span><span class="n">error</span>
<span class="mi">1</span>  <span class="mf">0.039826</span>    <span class="mf">0.039971</span>  <span class="mf">0.040213</span>      <span class="mf">0.973236</span>       <span class="mf">0.364964</span>
<span class="mi">2</span>  <span class="mf">0.318847</span>    <span class="mf">0.318798</span>  <span class="mf">0.324370</span>      <span class="mf">1.732260</span>      <span class="o">-</span><span class="mf">0.015195</span>
<span class="mi">3</span>  <span class="mf">0.350581</span>    <span class="mf">0.350533</span>  <span class="mf">0.358527</span>      <span class="mf">2.266446</span>      <span class="o">-</span><span class="mf">0.013820</span>
<span class="mi">4</span>  <span class="mf">0.176308</span>    <span class="mf">0.176357</span>  <span class="mf">0.167393</span>     <span class="o">-</span><span class="mf">5.056334</span>       <span class="mf">0.027480</span>
<span class="mi">5</span>  <span class="mf">0.114438</span>    <span class="mf">0.114341</span>  <span class="mf">0.109496</span>     <span class="o">-</span><span class="mf">4.318374</span>      <span class="o">-</span><span class="mf">0.084674</span>
</pre></div>
</div>
<p>Before we move on, we drop the income category variable because we do not use
this categorical variable in our âforecastingâ model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">set_</span> <span class="ow">in</span> <span class="p">(</span><span class="n">strat_train_set</span><span class="p">,</span> <span class="n">strat_test_set</span><span class="p">):</span>
    <span class="n">set_</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;income_cat&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="visualize-data-to-gain-insight">
<h3><span class="section-number">24.2.4. </span>Visualize data to gain insight<a class="headerlink" href="#visualize-data-to-gain-insight" title="Permalink to this headline">Â¶</a></h3>
<p>We next copy the stratified training data set and assign it a shorter name.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing</span> <span class="o">=</span> <span class="n">strat_train_set</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
<p>We next make a scatter splot to get a feel for the geographic location of the
house observations. Once we plot it, we roughly see the outline of the State of
California.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;longitude&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;latitude&quot;</span><span class="p">)</span>
<span class="c1"># save_fig(&quot;bad_visualization_plot&quot;)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;latitude&#39;</span><span class="o">&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/Slides_MachineLearning_1_figure19_1.png"><img alt="_images/Slides_MachineLearning_1_figure19_1.png" src="_images/Slides_MachineLearning_1_figure19_1.png" style="width: 15cm;" /></a>
<p>We can do a little better by making the data points in the graph a bit opaque
using the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> option in the plot command. This option allows us to
specify the âopaquenessâ of the dots in the scatterplot.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;longitude&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;latitude&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># save_fig(&quot;better_visualization_plot&quot;)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;latitude&#39;</span><span class="o">&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/Slides_MachineLearning_1_figure20_1.png"><img alt="_images/Slides_MachineLearning_1_figure20_1.png" src="_images/Slides_MachineLearning_1_figure20_1.png" style="width: 15cm;" /></a>
<p>We can also adjust the data point size using a population measure. So a bigger
point represents a housing observation from a place with a higher population
density.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;longitude&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;latitude&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
    <span class="n">s</span><span class="o">=</span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;population&quot;</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;population&quot;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span>
    <span class="n">c</span><span class="o">=</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s2">&quot;jet&quot;</span><span class="p">),</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">sharex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="c1"># save_fig(&quot;housing_prices_scatterplot&quot;)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">legend</span><span class="o">.</span><span class="n">Legend</span> <span class="n">at</span> <span class="mh">0x7ff1072c59a0</span><span class="o">&gt;</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/Slides_MachineLearning_1_figure21_1.png"><img alt="_images/Slides_MachineLearning_1_figure21_1.png" src="_images/Slides_MachineLearning_1_figure21_1.png" style="width: 15cm;" /></a>
<p>We next investigate correlations between the value of the house and the other
variables in our data in order to get a feel for what a good forecasting model
should factor in.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">housing</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">median_house_value</span>    <span class="mf">1.000000</span>
<span class="n">median_income</span>         <span class="mf">0.687151</span>
<span class="n">total_rooms</span>           <span class="mf">0.135140</span>
<span class="n">housing_median_age</span>    <span class="mf">0.114146</span>
<span class="n">households</span>            <span class="mf">0.064590</span>
<span class="n">total_bedrooms</span>        <span class="mf">0.047781</span>
<span class="n">population</span>           <span class="o">-</span><span class="mf">0.026882</span>
<span class="n">longitude</span>            <span class="o">-</span><span class="mf">0.047466</span>
<span class="n">latitude</span>             <span class="o">-</span><span class="mf">0.142673</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">median_house_value</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">Pandas</span></code> library has a very powerful command that allows you to draw
scatter plots for all variable combinations. This is a visual method to inspect
the correlation between variables.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># from pandas.tools.plotting import scatter_matrix # For older versions of Pandas</span>
<span class="kn">from</span> <span class="nn">pandas.plotting</span> <span class="kn">import</span> <span class="n">scatter_matrix</span>

<span class="n">attributes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">,</span> <span class="s2">&quot;median_income&quot;</span><span class="p">,</span> <span class="s2">&quot;total_rooms&quot;</span><span class="p">,</span>
              <span class="s2">&quot;housing_median_age&quot;</span><span class="p">]</span>
<span class="n">scatter_matrix</span><span class="p">(</span><span class="n">housing</span><span class="p">[</span><span class="n">attributes</span><span class="p">],</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="c1"># save_fig(&quot;scatter_matrix_plot&quot;)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span><span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;median_house_value&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;median_house_value&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;median_income&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;median_house_value&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;total_rooms&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;median_house_value&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;housing_median_age&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;median_house_value&#39;</span><span class="o">&gt;</span><span class="p">],</span>
       <span class="p">[</span><span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;median_house_value&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;median_income&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;median_income&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;median_income&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;total_rooms&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;median_income&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;housing_median_age&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;median_income&#39;</span><span class="o">&gt;</span><span class="p">],</span>
       <span class="p">[</span><span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;median_house_value&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;total_rooms&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;median_income&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;total_rooms&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;total_rooms&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;total_rooms&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;housing_median_age&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;total_rooms&#39;</span><span class="o">&gt;</span><span class="p">],</span>
       <span class="p">[</span><span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;median_house_value&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;housing_median_age&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;median_income&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;housing_median_age&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;total_rooms&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;housing_median_age&#39;</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="o">&lt;</span><span class="n">AxesSubplot</span><span class="p">:</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;housing_median_age&#39;</span><span class="p">,</span>
<span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;housing_median_age&#39;</span><span class="o">&gt;</span><span class="p">]],</span>
      <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/Slides_MachineLearning_1_figure23_1.png"><img alt="_images/Slides_MachineLearning_1_figure23_1.png" src="_images/Slides_MachineLearning_1_figure23_1.png" style="width: 15cm;" /></a>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;median_income&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">,</span>
             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">550000</span><span class="p">])</span>
<span class="c1"># save_fig(&quot;income_vs_house_value_scatterplot&quot;)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">16.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">550000.0</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/Slides_MachineLearning_1_figure24_1.png"><img alt="_images/Slides_MachineLearning_1_figure24_1.png" src="_images/Slides_MachineLearning_1_figure24_1.png" style="width: 15cm;" /></a>
<p>Finally we can generate some additional variables that are combinations of
variables in our original data set.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;rooms_per_household&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">housing</span><span class="p">[</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">]</span>
<span class="n">housing</span><span class="p">[</span><span class="s2">&quot;bedrooms_per_room&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">housing</span><span class="p">[</span><span class="s2">&quot;total_bedrooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">]</span>
<span class="n">housing</span><span class="p">[</span><span class="s2">&quot;population_per_household&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;population&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">housing</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">]</span>

<span class="c1"># Note: there was a bug in the previous cell, in the definition of the rooms_per_household attribute. This explains why the correlation value below differs slightly from the value in the book (unless you are reading the latest version).</span>

<span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">housing</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">median_house_value</span>          <span class="mf">1.000000</span>
<span class="n">median_income</span>               <span class="mf">0.687151</span>
<span class="n">rooms_per_household</span>         <span class="mf">0.146255</span>
<span class="n">total_rooms</span>                 <span class="mf">0.135140</span>
<span class="n">housing_median_age</span>          <span class="mf">0.114146</span>
<span class="n">households</span>                  <span class="mf">0.064590</span>
<span class="n">total_bedrooms</span>              <span class="mf">0.047781</span>
<span class="n">population_per_household</span>   <span class="o">-</span><span class="mf">0.021991</span>
<span class="n">population</span>                 <span class="o">-</span><span class="mf">0.026882</span>
<span class="n">longitude</span>                  <span class="o">-</span><span class="mf">0.047466</span>
<span class="n">latitude</span>                   <span class="o">-</span><span class="mf">0.142673</span>
<span class="n">bedrooms_per_room</span>          <span class="o">-</span><span class="mf">0.259952</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">median_house_value</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</pre></div>
</div>
</div>
<div class="section" id="prepare-data">
<h3><span class="section-number">24.2.5. </span>Prepare data<a class="headerlink" href="#prepare-data" title="Permalink to this headline">Â¶</a></h3>
<p>Before training (estimating) the model we need to prepare the data for the
built in Machine Learning algorithms. We need to make sure that the data only
contains numeric data and not strings, lists, etc.</p>
<p>We first put the label variable and the rest of the data (the X variables) into
separate dataframes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing</span> <span class="o">=</span> <span class="n">strat_train_set</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># drop labels for training set</span>
<span class="n">housing_labels</span> <span class="o">=</span> <span class="n">strat_train_set</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
<p>We then check how many observations with incomplete (i.e., missing)
observations we have.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sample_incomplete_rows</span> <span class="o">=</span> <span class="n">housing</span><span class="p">[</span><span class="n">housing</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample_incomplete_rows</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>       <span class="n">longitude</span>  <span class="n">latitude</span>  <span class="n">housing_median_age</span>  <span class="n">total_rooms</span>
<span class="n">total_bedrooms</span>  \
<span class="mi">1606</span>     <span class="o">-</span><span class="mf">122.08</span>     <span class="mf">37.88</span>                <span class="mf">26.0</span>       <span class="mf">2947.0</span>
<span class="n">NaN</span>
<span class="mi">10915</span>    <span class="o">-</span><span class="mf">117.87</span>     <span class="mf">33.73</span>                <span class="mf">45.0</span>       <span class="mf">2264.0</span>
<span class="n">NaN</span>
<span class="mi">19150</span>    <span class="o">-</span><span class="mf">122.70</span>     <span class="mf">38.35</span>                <span class="mf">14.0</span>       <span class="mf">2313.0</span>
<span class="n">NaN</span>
<span class="mi">4186</span>     <span class="o">-</span><span class="mf">118.23</span>     <span class="mf">34.13</span>                <span class="mf">48.0</span>       <span class="mf">1308.0</span>
<span class="n">NaN</span>
<span class="mi">16885</span>    <span class="o">-</span><span class="mf">122.40</span>     <span class="mf">37.58</span>                <span class="mf">26.0</span>       <span class="mf">3281.0</span>
<span class="n">NaN</span>

       <span class="n">population</span>  <span class="n">households</span>  <span class="n">median_income</span> <span class="n">ocean_proximity</span>
<span class="mi">1606</span>        <span class="mf">825.0</span>       <span class="mf">626.0</span>         <span class="mf">2.9330</span>        <span class="n">NEAR</span> <span class="n">BAY</span>
<span class="mi">10915</span>      <span class="mf">1970.0</span>       <span class="mf">499.0</span>         <span class="mf">3.4193</span>       <span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>
<span class="mi">19150</span>       <span class="mf">954.0</span>       <span class="mf">397.0</span>         <span class="mf">3.7813</span>       <span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>
<span class="mi">4186</span>        <span class="mf">835.0</span>       <span class="mf">294.0</span>         <span class="mf">4.2891</span>       <span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>
<span class="mi">16885</span>      <span class="mf">1145.0</span>       <span class="mf">480.0</span>         <span class="mf">6.3580</span>      <span class="n">NEAR</span> <span class="n">OCEAN</span>
</pre></div>
</div>
<p>We next run a built in function over our data that attempts to impute missing
data with the median values of similar observations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Warning: Since Scikit-Learn 0.20, the sklearn.preprocessing.Imputer class was replaced by the sklearn.impute.SimpleImputer class.</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span> <span class="c1"># Scikit-Learn 0.20+</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">Imputer</span> <span class="k">as</span> <span class="n">SimpleImputer</span>

<span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Before we run the imputing algorithm we need to remove variables from the
dataframe that are not numeric such as categorical variables.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you would like to use categorical variables as regressors, you need to
make dummy variables for each of the categories of your categorical
variable. In other words, you need to code up a categorical variable as a
(dummy set of) numerical variables so that you can âdo mathâ with your
categorical variable information.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Remove the text attribute because median can only be calculated on numerical attributes:</span>

<span class="n">housing_num</span> <span class="o">=</span> <span class="n">housing</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;ocean_proximity&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># alternatively: housing_num = housing.select_dtypes(include=[np.number])</span>
<span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_num</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">statistics_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">housing_num</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="o">-</span><span class="mf">118.51</span>      <span class="mf">34.26</span>      <span class="mf">29.</span>      <span class="mf">2119.</span>       <span class="mf">433.</span>      <span class="mf">1164.</span>
  <span class="mf">408.</span>         <span class="mf">3.54155</span><span class="p">]</span>
<span class="p">[</span><span class="o">-</span><span class="mf">118.51</span>      <span class="mf">34.26</span>      <span class="mf">29.</span>      <span class="mf">2119.</span>       <span class="mf">433.</span>      <span class="mf">1164.</span>
  <span class="mf">408.</span>         <span class="mf">3.54155</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">housing_num</span><span class="p">)</span>

<span class="n">housing_tr</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">housing_num</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
                          <span class="n">index</span><span class="o">=</span><span class="n">housing</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">housing_tr</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>       <span class="n">longitude</span>  <span class="n">latitude</span>  <span class="n">housing_median_age</span>  <span class="n">total_rooms</span>
<span class="n">total_bedrooms</span>  \
<span class="mi">12655</span>    <span class="o">-</span><span class="mf">121.46</span>     <span class="mf">38.52</span>                <span class="mf">29.0</span>       <span class="mf">3873.0</span>
<span class="mf">797.0</span>
<span class="mi">15502</span>    <span class="o">-</span><span class="mf">117.23</span>     <span class="mf">33.09</span>                 <span class="mf">7.0</span>       <span class="mf">5320.0</span>
<span class="mf">855.0</span>
<span class="mi">2908</span>     <span class="o">-</span><span class="mf">119.04</span>     <span class="mf">35.37</span>                <span class="mf">44.0</span>       <span class="mf">1618.0</span>
<span class="mf">310.0</span>
<span class="mi">14053</span>    <span class="o">-</span><span class="mf">117.13</span>     <span class="mf">32.75</span>                <span class="mf">24.0</span>       <span class="mf">1877.0</span>
<span class="mf">519.0</span>
<span class="mi">20496</span>    <span class="o">-</span><span class="mf">118.70</span>     <span class="mf">34.28</span>                <span class="mf">27.0</span>       <span class="mf">3536.0</span>
<span class="mf">646.0</span>

       <span class="n">population</span>  <span class="n">households</span>  <span class="n">median_income</span>
<span class="mi">12655</span>      <span class="mf">2237.0</span>       <span class="mf">706.0</span>         <span class="mf">2.1736</span>
<span class="mi">15502</span>      <span class="mf">2015.0</span>       <span class="mf">768.0</span>         <span class="mf">6.3373</span>
<span class="mi">2908</span>        <span class="mf">667.0</span>       <span class="mf">300.0</span>         <span class="mf">2.8750</span>
<span class="mi">14053</span>       <span class="mf">898.0</span>       <span class="mf">483.0</span>         <span class="mf">2.2264</span>
<span class="mi">20496</span>      <span class="mf">1837.0</span>       <span class="mf">580.0</span>         <span class="mf">4.4964</span>
</pre></div>
</div>
<p>We have now created a complete dataset with no more missing observations that
only contains numeric variables.</p>
<p>We next need to handle the categorical variable of ocean proximity of a housing
unit. Let us inspect this variable first.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing_cat</span> <span class="o">=</span> <span class="n">housing</span><span class="p">[[</span><span class="s1">&#39;ocean_proximity&#39;</span><span class="p">]]</span>
<span class="n">housing_cat</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>      <span class="n">ocean_proximity</span>
<span class="mi">12655</span>          <span class="n">INLAND</span>
<span class="mi">15502</span>      <span class="n">NEAR</span> <span class="n">OCEAN</span>
<span class="mi">2908</span>           <span class="n">INLAND</span>
<span class="mi">14053</span>      <span class="n">NEAR</span> <span class="n">OCEAN</span>
<span class="mi">20496</span>       <span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>
<span class="mi">1481</span>         <span class="n">NEAR</span> <span class="n">BAY</span>
<span class="mi">18125</span>       <span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>
<span class="mi">5830</span>        <span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>
<span class="mi">17989</span>       <span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>
<span class="mi">4861</span>        <span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>
</pre></div>
</div>
<p>We next use a label encoder function which is part of the <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> toolkit.
This is basically a function that will generate dummy variables out of
categorical variables. Dummy variables are variables that are either 0 or 1 and
and it can be used to encode categorical (i.e., non numerical attributes) such
as gender. The dummy variable could be called <code class="docutils literal notranslate"><span class="pre">d_female</span></code>. It is equal to
1 if a person is female and 0 if a person is not female.</p>
<p>The ocean proximity variable has multiple categories in it, not just two as in
the gender example. For each category of the ocean proximity variable we have
to create a dummy variable. We could accomplish this separately for each dummy
variable using <code class="docutils literal notranslate"><span class="pre">if</span></code> statements or we can use the built in <code class="docutils literal notranslate"><span class="pre">OrdinalEncoder</span></code>
to do it in one line of code.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Some earlier machine learning codes used the LabelEncoder class or Pandasâ
<code class="docutils literal notranslate"><span class="pre">Series.factorize()</span></code> method to encode string categorical attributes as
integers. However, the <code class="docutils literal notranslate"><span class="pre">OrdinalEncoder</span></code> class that was introduced in
Scikit-Learn 0.20 (see PR #10521) is preferable since it is designed for
input features (X instead of labels y) and it plays well with pipelines
(introduced later). If you are using an older version of
Scikit-Learn (&lt;0.20), then you can import it from <code class="docutils literal notranslate"><span class="pre">future_encoders.py</span></code>
instead.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="c1"># New version of categorial variable encoder</span>
    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="c1"># Use old version, if new version of categorial variable encoder fails</span>
    <span class="kn">from</span> <span class="nn">future_encoders</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span> <span class="c1"># Scikit-Learn &lt; 0.20</span>

<span class="n">ordinal_encoder</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">()</span>
<span class="n">housing_cat_encoded</span> <span class="o">=</span> <span class="n">ordinal_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">housing_cat</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">housing_cat_encoded</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ordinal_encoder</span><span class="o">.</span><span class="n">categories_</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">1.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">4.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">4.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">3.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.</span><span class="p">]]</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;&lt;1H OCEAN&#39;</span><span class="p">,</span> <span class="s1">&#39;INLAND&#39;</span><span class="p">,</span> <span class="s1">&#39;ISLAND&#39;</span><span class="p">,</span> <span class="s1">&#39;NEAR BAY&#39;</span><span class="p">,</span> <span class="s1">&#39;NEAR OCEAN&#39;</span><span class="p">],</span>
      <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)]</span>
</pre></div>
</div>
<p>We have now encoded a string categorical variable into numerical values.
However, before we run regressions, we need to make dummy variables out of a
categorical variable (no matter whether itâs a string category or numeric
categories). The reason is that the machine learning algorithm will assume that
two nearby values are more similar than two distant values. This is okay if
your categories are âbadâ, âaverageâ, âgoodâ, and âexcellentâ, but it is not
thecase for the <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> variable above where categories 0 and 4 are
clearly more similar than categories 0 and 1.</p>
<p>We therefore resort to one-hot encoding, where a for each category we make a
separate variable. Let us pick one category out of the <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code>
column, say â&lt;1H OCEANâ. For this category we create a new column that we
encode as 1 (hot) if the house is less than one our from the ocean and 0(cold)
otherwise. This is also called a dummy variable.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Older machine learning codes used the <code class="docutils literal notranslate"><span class="pre">LabelBinarizer</span></code> or
<code class="docutils literal notranslate"><span class="pre">CategoricalEncoder</span></code> classes to convert each categorical value to a
one-hot vector (i.e., a dummy 0/1 variable). It is now preferable to use the
<code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code> class. Since Scikit-Learn 0.20 it can
handle string categorical inputs (see PR #10521), not just integer
categorical inputs. If you are using an older version of Scikit-Learn, you
can import the new version from future_encoders.py:</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span> <span class="c1"># just to raise an ImportError if Scikit-Learn &lt; 0.20</span>
    <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">future_encoders</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span> <span class="c1"># Scikit-Learn &lt; 0.20</span>

<span class="n">cat_encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>
<span class="n">housing_cat_1hot</span> <span class="o">=</span> <span class="n">cat_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">housing_cat</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">housing_cat_1hot</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cat_encoder</span><span class="o">.</span><span class="n">categories_</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>        <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>        <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>        <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>        <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>        <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>        <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>        <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>        <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>        <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>        <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">19</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">23</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>       <span class="mf">1.0</span>
  <span class="p">:</span>     <span class="p">:</span>
  <span class="p">(</span><span class="mi">16487</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16488</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16489</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16490</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16491</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16492</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16493</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16494</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16495</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16496</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16497</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16498</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16499</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16500</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16501</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16502</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16503</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16504</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16505</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16506</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16507</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16508</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16509</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16510</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>    <span class="mf">1.0</span>
  <span class="p">(</span><span class="mi">16511</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="mf">1.0</span>
<span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;&lt;1H OCEAN&#39;</span><span class="p">,</span> <span class="s1">&#39;INLAND&#39;</span><span class="p">,</span> <span class="s1">&#39;ISLAND&#39;</span><span class="p">,</span> <span class="s1">&#39;NEAR BAY&#39;</span><span class="p">,</span> <span class="s1">&#39;NEAR OCEAN&#39;</span><span class="p">],</span>
      <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)]</span>
</pre></div>
</div>
<p>We next  use Scikit-Learnâs FunctionTransformer class that lets
you easily create a transformer based on a transformation function. Note that
we need to set validate=False because the data contains non-float values
(validate will default to False in Scikit-Learn 0.22).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># get the right column indices: safer than hard-coding indices 3, 4, 5, 6</span>
<span class="n">rooms_ix</span><span class="p">,</span> <span class="n">bedrooms_ix</span><span class="p">,</span> <span class="n">population_ix</span><span class="p">,</span> <span class="n">household_ix</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nb">list</span><span class="p">(</span><span class="n">housing</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">,</span> <span class="s2">&quot;total_bedrooms&quot;</span><span class="p">,</span> <span class="s2">&quot;population&quot;</span><span class="p">,</span> <span class="s2">&quot;households&quot;</span><span class="p">)]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span>

<span class="k">def</span> <span class="nf">add_extra_features</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">add_bedrooms_per_room</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">rooms_per_household</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">rooms_ix</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">household_ix</span><span class="p">]</span>
    <span class="n">population_per_household</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">population_ix</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">household_ix</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">add_bedrooms_per_room</span><span class="p">:</span>
        <span class="n">bedrooms_per_room</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">bedrooms_ix</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">rooms_ix</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">rooms_per_household</span><span class="p">,</span> <span class="n">population_per_household</span><span class="p">,</span>
                     <span class="n">bedrooms_per_room</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">rooms_per_household</span><span class="p">,</span> <span class="n">population_per_household</span><span class="p">]</span>

<span class="n">attr_adder</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">add_extra_features</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                 <span class="n">kw_args</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;add_bedrooms_per_room&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>
<span class="n">housing_extra_attribs</span> <span class="o">=</span> <span class="n">attr_adder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">housing</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">housing_extra_attribs</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,:])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="o">-</span><span class="mf">121.46</span> <span class="mf">38.52</span> <span class="mf">29.0</span> <span class="mf">3873.0</span> <span class="mf">797.0</span> <span class="mf">2237.0</span> <span class="mf">706.0</span> <span class="mf">2.1736</span> <span class="s1">&#39;INLAND&#39;</span>
  <span class="mf">5.485835694050992</span> <span class="mf">3.168555240793201</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mf">117.23</span> <span class="mf">33.09</span> <span class="mf">7.0</span> <span class="mf">5320.0</span> <span class="mf">855.0</span> <span class="mf">2015.0</span> <span class="mf">768.0</span> <span class="mf">6.3373</span> <span class="s1">&#39;NEAR OCEAN&#39;</span>
  <span class="mf">6.927083333333333</span> <span class="mf">2.6236979166666665</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mf">119.04</span> <span class="mf">35.37</span> <span class="mf">44.0</span> <span class="mf">1618.0</span> <span class="mf">310.0</span> <span class="mf">667.0</span> <span class="mf">300.0</span> <span class="mf">2.875</span> <span class="s1">&#39;INLAND&#39;</span>
  <span class="mf">5.3933333333333335</span> <span class="mf">2.223333333333333</span><span class="p">]]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">housing_extra_attribs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">housing_extra_attribs</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">housing</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">+</span><span class="p">[</span><span class="s2">&quot;rooms_per_household&quot;</span><span class="p">,</span> <span class="s2">&quot;population_per_household&quot;</span><span class="p">],</span>
    <span class="n">index</span><span class="o">=</span><span class="n">housing</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">housing_extra_attribs</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">housing_extra_attribs</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>      <span class="n">longitude</span> <span class="n">latitude</span> <span class="n">housing_median_age</span> <span class="n">total_rooms</span> <span class="n">total_bedrooms</span>
\
<span class="mi">12655</span>   <span class="o">-</span><span class="mf">121.46</span>    <span class="mf">38.52</span>               <span class="mf">29.0</span>      <span class="mf">3873.0</span>          <span class="mf">797.0</span>
<span class="mi">15502</span>   <span class="o">-</span><span class="mf">117.23</span>    <span class="mf">33.09</span>                <span class="mf">7.0</span>      <span class="mf">5320.0</span>          <span class="mf">855.0</span>
<span class="mi">2908</span>    <span class="o">-</span><span class="mf">119.04</span>    <span class="mf">35.37</span>               <span class="mf">44.0</span>      <span class="mf">1618.0</span>          <span class="mf">310.0</span>
<span class="mi">14053</span>   <span class="o">-</span><span class="mf">117.13</span>    <span class="mf">32.75</span>               <span class="mf">24.0</span>      <span class="mf">1877.0</span>          <span class="mf">519.0</span>
<span class="mi">20496</span>    <span class="o">-</span><span class="mf">118.7</span>    <span class="mf">34.28</span>               <span class="mf">27.0</span>      <span class="mf">3536.0</span>          <span class="mf">646.0</span>

      <span class="n">population</span> <span class="n">households</span> <span class="n">median_income</span> <span class="n">ocean_proximity</span>
<span class="n">rooms_per_household</span>  \
<span class="mi">12655</span>     <span class="mf">2237.0</span>      <span class="mf">706.0</span>        <span class="mf">2.1736</span>          <span class="n">INLAND</span>
<span class="mf">5.485836</span>
<span class="mi">15502</span>     <span class="mf">2015.0</span>      <span class="mf">768.0</span>        <span class="mf">6.3373</span>      <span class="n">NEAR</span> <span class="n">OCEAN</span>
<span class="mf">6.927083</span>
<span class="mi">2908</span>       <span class="mf">667.0</span>      <span class="mf">300.0</span>         <span class="mf">2.875</span>          <span class="n">INLAND</span>
<span class="mf">5.393333</span>
<span class="mi">14053</span>      <span class="mf">898.0</span>      <span class="mf">483.0</span>        <span class="mf">2.2264</span>      <span class="n">NEAR</span> <span class="n">OCEAN</span>
<span class="mf">3.886128</span>
<span class="mi">20496</span>     <span class="mf">1837.0</span>      <span class="mf">580.0</span>        <span class="mf">4.4964</span>       <span class="o">&lt;</span><span class="mi">1</span><span class="n">H</span> <span class="n">OCEAN</span>
<span class="mf">6.096552</span>

      <span class="n">population_per_household</span>
<span class="mi">12655</span>                 <span class="mf">3.168555</span>
<span class="mi">15502</span>                 <span class="mf">2.623698</span>
<span class="mi">2908</span>                  <span class="mf">2.223333</span>
<span class="mi">14053</span>                 <span class="mf">1.859213</span>
<span class="mi">20496</span>                 <span class="mf">3.167241</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">num_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s1">&#39;imputer&#39;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;attribs_adder&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">add_extra_features</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
        <span class="p">(</span><span class="s1">&#39;std_scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">])</span>

<span class="n">housing_num_tr</span> <span class="o">=</span> <span class="n">num_pipeline</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">housing_num</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">future_encoders</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span> <span class="c1"># Scikit-Learn &lt; 0.20</span>


<span class="n">num_attribs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">housing_num</span><span class="p">)</span>
<span class="n">cat_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ocean_proximity&quot;</span><span class="p">]</span>

<span class="n">full_pipeline</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;num&quot;</span><span class="p">,</span> <span class="n">num_pipeline</span><span class="p">,</span> <span class="n">num_attribs</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(),</span> <span class="n">cat_attribs</span><span class="p">),</span>
    <span class="p">])</span>

<span class="n">housing_prepared</span> <span class="o">=</span> <span class="n">full_pipeline</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">housing</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">[:</span><span class="mi">3</span><span class="p">,:])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="o">-</span><span class="mf">0.94135046</span>  <span class="mf">1.34743822</span>  <span class="mf">0.02756357</span>  <span class="mf">0.58477745</span>  <span class="mf">0.64037127</span>
<span class="mf">0.73260236</span>
   <span class="mf">0.55628602</span> <span class="o">-</span><span class="mf">0.8936472</span>   <span class="mf">0.01739526</span>  <span class="mf">0.00622264</span> <span class="o">-</span><span class="mf">0.12112176</span>  <span class="mf">0.</span>
   <span class="mf">1.</span>          <span class="mf">0.</span>          <span class="mf">0.</span>          <span class="mf">0.</span>        <span class="p">]</span>
 <span class="p">[</span> <span class="mf">1.17178212</span> <span class="o">-</span><span class="mf">1.19243966</span> <span class="o">-</span><span class="mf">1.72201763</span>  <span class="mf">1.26146668</span>  <span class="mf">0.78156132</span>
<span class="mf">0.53361152</span>
   <span class="mf">0.72131799</span>  <span class="mf">1.292168</span>    <span class="mf">0.56925554</span> <span class="o">-</span><span class="mf">0.04081077</span> <span class="o">-</span><span class="mf">0.81086696</span>  <span class="mf">0.</span>
   <span class="mf">0.</span>          <span class="mf">0.</span>          <span class="mf">0.</span>          <span class="mf">1.</span>        <span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.26758118</span> <span class="o">-</span><span class="mf">0.1259716</span>   <span class="mf">1.22045984</span> <span class="o">-</span><span class="mf">0.46977281</span> <span class="o">-</span><span class="mf">0.54513828</span>
<span class="o">-</span><span class="mf">0.67467519</span>
  <span class="o">-</span><span class="mf">0.52440722</span> <span class="o">-</span><span class="mf">0.52543365</span> <span class="o">-</span><span class="mf">0.01802432</span> <span class="o">-</span><span class="mf">0.07537122</span> <span class="o">-</span><span class="mf">0.33827252</span>  <span class="mf">0.</span>
   <span class="mf">1.</span>          <span class="mf">0.</span>          <span class="mf">0.</span>          <span class="mf">0.</span>        <span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="section" id="training-a-regression-model">
<h3><span class="section-number">24.2.6. </span>Training a Regression Model<a class="headerlink" href="#training-a-regression-model" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#%% Select and train a model</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">lin_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lin_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">)</span>

<span class="c1"># let&#39;s try the full preprocessing pipeline on a few training instances</span>
<span class="n">some_data</span> <span class="o">=</span> <span class="n">housing</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
<span class="n">some_labels</span> <span class="o">=</span> <span class="n">housing_labels</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
<span class="n">some_data_prepared</span> <span class="o">=</span> <span class="n">full_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">some_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predictions:&quot;</span><span class="p">,</span> <span class="n">lin_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">some_data_prepared</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Lables:&quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">some_labels</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Predictions</span><span class="p">:</span> <span class="p">[</span> <span class="mf">85657.90192014</span> <span class="mf">305492.60737488</span> <span class="mf">152056.46122456</span>
<span class="mf">186095.70946094</span>
 <span class="mf">244550.67966089</span><span class="p">]</span>
<span class="n">Lables</span><span class="p">:</span> <span class="p">[</span><span class="mf">72100.0</span><span class="p">,</span> <span class="mf">279600.0</span><span class="p">,</span> <span class="mf">82700.0</span><span class="p">,</span> <span class="mf">112500.0</span><span class="p">,</span> <span class="mf">238300.0</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="n">housing_predictions</span> <span class="o">=</span> <span class="n">lin_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">)</span>
<span class="n">lin_mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">housing_labels</span><span class="p">,</span> <span class="n">housing_predictions</span><span class="p">)</span>
<span class="n">lin_rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">lin_mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lin_rmse</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">68627.87390018743</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="n">lin_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">housing_labels</span><span class="p">,</span> <span class="n">housing_predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lin_mae</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">49438.66860915803</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="n">tree_reg</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">)</span>

<span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
           <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
           <span class="n">min_impurity_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
           <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">min_weight_fraction_leaf</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
           <span class="n">presort</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">splitter</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>

<span class="n">housing_predictions</span> <span class="o">=</span> <span class="n">tree_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">)</span>
<span class="n">tree_mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">housing_labels</span><span class="p">,</span> <span class="n">housing_predictions</span><span class="p">)</span>
<span class="n">tree_rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tree_mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tree_rmse</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---------------------------------------------------------------------------</span><span class="ne">TypeError</span>
<span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">)</span><span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_8088</span><span class="o">/</span><span class="mf">2927567427.</span><span class="n">py</span> <span class="ow">in</span>
<span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
      <span class="mi">4</span> <span class="n">tree_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">)</span>
      <span class="mi">5</span>
<span class="o">----&gt;</span> <span class="mi">6</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
      <span class="mi">7</span>            <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
      <span class="mi">8</span>            <span class="n">min_impurity_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="ne">TypeError</span><span class="p">:</span> <span class="fm">__init__</span><span class="p">()</span> <span class="n">got</span> <span class="n">an</span> <span class="n">unexpected</span> <span class="n">keyword</span> <span class="n">argument</span>
<span class="s1">&#39;min_impurity_split&#39;</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree_reg</span><span class="p">,</span> <span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">,</span>
                         <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">tree_rmse_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f_display_scores</span><span class="p">(</span><span class="n">scores</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scores:&quot;</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean:&quot;</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Standard deviation:&quot;</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>

<span class="n">f_display_scores</span><span class="p">(</span><span class="n">tree_rmse_scores</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Scores</span><span class="p">:</span> <span class="p">[</span><span class="mf">72831.45749112</span> <span class="mf">69973.18438322</span> <span class="mf">69528.56551415</span> <span class="mf">72517.78229792</span>
 <span class="mf">69145.50006909</span> <span class="mf">79094.74123727</span> <span class="mf">68960.045444</span>   <span class="mf">73344.50225684</span>
 <span class="mf">69826.02473916</span> <span class="mf">71077.09753998</span><span class="p">]</span>
<span class="n">Mean</span><span class="p">:</span> <span class="mf">71629.89009727491</span>
<span class="n">Standard</span> <span class="n">deviation</span><span class="p">:</span> <span class="mf">2914.035468468928</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lin_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">lin_reg</span><span class="p">,</span> <span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">,</span>
                             <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">lin_rmse_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">lin_scores</span><span class="p">)</span>
<span class="n">f_display_scores</span><span class="p">(</span><span class="n">lin_rmse_scores</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Scores</span><span class="p">:</span> <span class="p">[</span><span class="mf">71762.76364394</span> <span class="mf">64114.99166359</span> <span class="mf">67771.17124356</span> <span class="mf">68635.19072082</span>
 <span class="mf">66846.14089488</span> <span class="mf">72528.03725385</span> <span class="mf">73997.08050233</span> <span class="mf">68802.33629334</span>
 <span class="mf">66443.28836884</span> <span class="mf">70139.79923956</span><span class="p">]</span>
<span class="n">Mean</span><span class="p">:</span> <span class="mf">69104.07998247063</span>
<span class="n">Standard</span> <span class="n">deviation</span><span class="p">:</span> <span class="mf">2880.328209818062</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note: we specify n_estimators=10 to avoid a warning about the fact that the default value is going to change to 100 in Scikit-Learn 0.22.</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="n">forest_reg</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">forest_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">)</span>


<span class="n">housing_predictions</span> <span class="o">=</span> <span class="n">forest_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">)</span>
<span class="n">forest_mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">housing_labels</span><span class="p">,</span> <span class="n">housing_predictions</span><span class="p">)</span>
<span class="n">forest_rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">forest_mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">forest_rmse</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">22413.454658589766</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">forest_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">forest_reg</span><span class="p">,</span> <span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">,</span>
                                <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">forest_rmse_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">forest_scores</span><span class="p">)</span>
<span class="n">f_display_scores</span><span class="p">(</span><span class="n">forest_rmse_scores</span><span class="p">)</span>


<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">lin_reg</span><span class="p">,</span> <span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="p">))</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Scores</span><span class="p">:</span> <span class="p">[</span><span class="mf">53519.05518628</span> <span class="mf">50467.33817051</span> <span class="mf">48924.16513902</span> <span class="mf">53771.72056856</span>
 <span class="mf">50810.90996358</span> <span class="mf">54876.09682033</span> <span class="mf">56012.79985518</span> <span class="mf">52256.88927227</span>
 <span class="mf">51527.73185039</span> <span class="mf">55762.56008531</span><span class="p">]</span>
<span class="n">Mean</span><span class="p">:</span> <span class="mf">52792.92669114079</span>
<span class="n">Standard</span> <span class="n">deviation</span><span class="p">:</span> <span class="mf">2262.8151900582</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">count</span>       <span class="mf">10.000000</span>
<span class="n">mean</span>     <span class="mf">69104.079982</span>
<span class="n">std</span>       <span class="mf">3036.132517</span>
<span class="nb">min</span>      <span class="mf">64114.991664</span>
<span class="mi">25</span><span class="o">%</span>      <span class="mf">67077.398482</span>
<span class="mi">50</span><span class="o">%</span>      <span class="mf">68718.763507</span>
<span class="mi">75</span><span class="o">%</span>      <span class="mf">71357.022543</span>
<span class="nb">max</span>      <span class="mf">73997.080502</span>
<span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</pre></div>
</div>
</div>
<div class="section" id="fine-tune-model">
<h3><span class="section-number">24.2.7. </span>Fine Tune Model<a class="headerlink" href="#fine-tune-model" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># try 12 (3Ã4) combinations of hyperparameters</span>
    <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span> <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]},</span>
    <span class="c1"># then try 6 (2Ã3) combinations with bootstrap set as False</span>
    <span class="p">{</span><span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">],</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]},</span>
  <span class="p">]</span>

<span class="n">forest_reg</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="c1"># train across 5 folds, that&#39;s a total of (12+6)*5=90 rounds of training</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">forest_reg</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                           <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">housing_prepared</span><span class="p">,</span> <span class="n">housing_labels</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">}</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s look at the score of each hyperparameter combination tested during the grid search:</span>
<span class="n">cvres</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span>

<span class="k">for</span> <span class="n">mean_score</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">cvres</span><span class="p">[</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">],</span> <span class="n">cvres</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">mean_score</span><span class="p">),</span> <span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">63895.161577951665</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="mf">54916.32386349543</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="mf">52885.86715332332</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">}</span>
<span class="mf">60075.3680329983</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="mf">52495.01284985185</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="mf">50187.24324926565</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">}</span>
<span class="mf">58064.73529982314</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="mf">51519.32062366315</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="mf">49969.80441627874</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">}</span>
<span class="mf">58895.824998155826</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="mf">52459.79624724529</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="mf">49898.98913455217</span> <span class="p">{</span><span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">}</span>
<span class="mf">62381.765106921855</span> <span class="p">{</span><span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="mf">54476.57050944266</span> <span class="p">{</span><span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="mf">59974.60028085155</span> <span class="p">{</span><span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
<span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="mf">52754.5632813202</span> <span class="p">{</span><span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
<span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="mf">57831.136061214274</span> <span class="p">{</span><span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
<span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="mf">51278.37877140253</span> <span class="p">{</span><span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
<span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">feature_importances</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feature_importances</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">6.96542523e-02</span> <span class="mf">6.04213840e-02</span> <span class="mf">4.21882202e-02</span> <span class="mf">1.52450557e-02</span>
 <span class="mf">1.55545295e-02</span> <span class="mf">1.58491147e-02</span> <span class="mf">1.49346552e-02</span> <span class="mf">3.79009225e-01</span>
 <span class="mf">5.47789150e-02</span> <span class="mf">1.07031322e-01</span> <span class="mf">4.82031213e-02</span> <span class="mf">6.79266007e-03</span>
 <span class="mf">1.65706303e-01</span> <span class="mf">7.83480660e-05</span> <span class="mf">1.52473276e-03</span> <span class="mf">3.02816106e-03</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">extra_attribs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;rooms_per_hhold&quot;</span><span class="p">,</span> <span class="s2">&quot;pop_per_hhold&quot;</span><span class="p">,</span> <span class="s2">&quot;bedrooms_per_room&quot;</span><span class="p">]</span>
<span class="c1">#cat_encoder = cat_pipeline.named_steps[&quot;cat_encoder&quot;] # old solution</span>
<span class="n">cat_encoder</span> <span class="o">=</span> <span class="n">full_pipeline</span><span class="o">.</span><span class="n">named_transformers_</span><span class="p">[</span><span class="s2">&quot;cat&quot;</span><span class="p">]</span>
<span class="n">cat_one_hot_attribs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cat_encoder</span><span class="o">.</span><span class="n">categories_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">attributes</span> <span class="o">=</span> <span class="n">num_attribs</span> <span class="o">+</span> <span class="n">extra_attribs</span> <span class="o">+</span> <span class="n">cat_one_hot_attribs</span>
<span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">feature_importances</span><span class="p">,</span> <span class="n">attributes</span><span class="p">),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">final_model</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">strat_test_set</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">strat_test_set</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">X_test_prepared</span> <span class="o">=</span> <span class="n">full_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">final_predictions</span> <span class="o">=</span> <span class="n">final_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_prepared</span><span class="p">)</span>

<span class="n">final_mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">final_predictions</span><span class="p">)</span>
<span class="n">final_rmse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">final_mse</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">final_rmse</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">47873.26095812988</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="n">confidence</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">squared_errors</span> <span class="o">=</span> <span class="p">(</span><span class="n">final_predictions</span> <span class="o">-</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">squared_errors</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">squared_errors</span><span class="p">)</span>

<span class="n">CI</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="n">confidence</span><span class="p">,</span> <span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                         <span class="n">loc</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">squared_errors</span><span class="p">),</span>
                         <span class="n">scale</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">sem</span><span class="p">(</span><span class="n">squared_errors</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confidence Interval&quot;</span><span class="p">,</span> <span class="n">CI</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Confidence</span> <span class="n">Interval</span> <span class="p">[</span><span class="mf">45893.36082829</span> <span class="mf">49774.46796717</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="key-concepts-and-summary">
<h2><span class="section-number">24.3. </span>Key Concepts and Summary<a class="headerlink" href="#key-concepts-and-summary" title="Permalink to this headline">Â¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Machine learning</p></li>
<li><p>The basics</p></li>
</ul>
</div>
</div>
<div class="section" id="self-check-questions">
<h2><span class="section-number">24.4. </span>Self-Check Questions<a class="headerlink" href="#self-check-questions" title="Permalink to this headline">Â¶</a></h2>
<div class="admonition-todo admonition" id="id2">
<p class="admonition-title">Todo</p>
<ul class="simple">
<li><p>Why is regression analysis machine learning. What type of machine
learning is it?</p></li>
</ul>
</div>
<dl class="citation">
<dt class="label" id="geron2019"><span class="brackets"><a class="fn-backref" href="#id1">Geron2019</a></span></dt>
<dd><p>Geron, Aurelien (2019), Hands-On Machine Learning with Scikit-Learn, Keras &amp; Tensorflow, OâReilly, 2nd edition.</p>
</dd>
</dl>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Slides_MachineLearning_2.html" class="btn btn-neutral float-right" title="25. Machine Learning II: Categorization Algorithm" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Slides_Growth.html" class="btn btn-neutral float-left" title="23. Growth Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Juergen Jung

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>