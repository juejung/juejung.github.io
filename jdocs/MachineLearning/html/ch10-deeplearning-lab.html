<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>10&nbsp; Lab Chapter 10: Deep Learning â€“ Machine Learning for Economics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ch11-surv-lab.html" rel="next">
<link href="./ch9-svm-lab.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-9f23c6a288fd7a0a695a963d2c49d14b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/jquery-3.6.3/jquery-3.6.3.min.js"></script>
<script src="site_libs/quarto-contrib/code-fullscreen-1.0.0/code-fullscreen.js" defer="true"></script>
<link href="site_libs/quarto-contrib/code-fullscreen-1.0.0/code-fullscreen.css" rel="stylesheet">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch2-statlearning-lab.html"><strong>ISL LABS</strong></a></li><li class="breadcrumb-item"><a href="./ch10-deeplearning-lab.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Lab Chapter 10: Deep Learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning for Economics</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text"><strong>INTRODUCTION</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Course Administration and Introduction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text"><strong>ISL LABS</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch2-statlearning-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Lab Chapter 2: Introduction to Python</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch3-linreg-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Lab Chapter 3: Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch4-classification-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Lab Chapter 4: Logistic Regression, LDA, QDA, and KNN</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch5-resample-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Lab Chapter 5: Cross-Validation and the Bootstrap</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch6-varselect-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Lab Chapter 6: Linear Models and Regularization Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch7-nonlin-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Lab Chapter 7: Non-Linear Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch8-baggboost-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Lab Chapter 8: Tree-Based Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch9-svm-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Lab Chapter 9: Support Vector Machines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch10-deeplearning-lab.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Lab Chapter 10: Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch11-surv-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Lab Chapter 11: Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch12-unsup-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Lab Chapter 12: Unsupervised Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch13-multipletest-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Lab Chapter 13: Multiple Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch14-reinforcementlearning-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Lab Chapter 14: Reinforcement Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text"><strong>ML APPLICATIONS</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_ex_OLS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Machine Learning: A First Example with OLS</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_ex_DoubleRobust.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Double Robust Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_ex_DoubleDebiasedML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Double Debiased Machine Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text"><strong>ML FRAMEWORKS</strong></span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml_PytorchKeras.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Section Learning Objectives</span></span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#package-library-imports" id="toc-package-library-imports" class="nav-link active" data-scroll-target="#package-library-imports"><span class="header-section-number">10.1</span> Package (library) imports</a>
  <ul class="collapse">
  <li><a href="#torch-specific-imports" id="toc-torch-specific-imports" class="nav-link" data-scroll-target="#torch-specific-imports"><span class="header-section-number">10.1.1</span> Torch-Specific Imports</a></li>
  </ul></li>
  <li><a href="#single-layer-network-on-hitters-data" id="toc-single-layer-network-on-hitters-data" class="nav-link" data-scroll-target="#single-layer-network-on-hitters-data"><span class="header-section-number">10.2</span> Single Layer Network on Hitters Data</a>
  <ul class="collapse">
  <li><a href="#linear-models" id="toc-linear-models" class="nav-link" data-scroll-target="#linear-models"><span class="header-section-number">10.2.1</span> Linear Models</a></li>
  <li><a href="#specifying-a-network-classes-and-inheritance" id="toc-specifying-a-network-classes-and-inheritance" class="nav-link" data-scroll-target="#specifying-a-network-classes-and-inheritance"><span class="header-section-number">10.2.2</span> Specifying a Network: Classes and Inheritance</a></li>
  <li><a href="#cleanup" id="toc-cleanup" class="nav-link" data-scroll-target="#cleanup"><span class="header-section-number">10.2.3</span> Cleanup</a></li>
  </ul></li>
  <li><a href="#multilayer-network-on-the-mnist-digit-data" id="toc-multilayer-network-on-the-mnist-digit-data" class="nav-link" data-scroll-target="#multilayer-network-on-the-mnist-digit-data"><span class="header-section-number">10.3</span> Multilayer Network on the MNIST Digit Data</a></li>
  <li><a href="#convolutional-neural-networks" id="toc-convolutional-neural-networks" class="nav-link" data-scroll-target="#convolutional-neural-networks"><span class="header-section-number">10.4</span> Convolutional Neural Networks</a>
  <ul class="collapse">
  <li><a href="#hardware-acceleration" id="toc-hardware-acceleration" class="nav-link" data-scroll-target="#hardware-acceleration"><span class="header-section-number">10.4.1</span> Hardware Acceleration</a></li>
  </ul></li>
  <li><a href="#using-pretrained-cnn-models" id="toc-using-pretrained-cnn-models" class="nav-link" data-scroll-target="#using-pretrained-cnn-models"><span class="header-section-number">10.5</span> Using Pretrained CNN Models</a></li>
  <li><a href="#imdb-document-classification" id="toc-imdb-document-classification" class="nav-link" data-scroll-target="#imdb-document-classification"><span class="header-section-number">10.6</span> IMDB Document Classification</a>
  <ul class="collapse">
  <li><a href="#comparison-to-lasso" id="toc-comparison-to-lasso" class="nav-link" data-scroll-target="#comparison-to-lasso"><span class="header-section-number">10.6.1</span> Comparison to Lasso</a></li>
  </ul></li>
  <li><a href="#recurrent-neural-networks" id="toc-recurrent-neural-networks" class="nav-link" data-scroll-target="#recurrent-neural-networks"><span class="header-section-number">10.7</span> Recurrent Neural Networks</a>
  <ul class="collapse">
  <li><a href="#sequential-models-for-document-classification" id="toc-sequential-models-for-document-classification" class="nav-link" data-scroll-target="#sequential-models-for-document-classification"><span class="header-section-number">10.7.1</span> Sequential Models for Document Classification</a></li>
  <li><a href="#time-series-prediction" id="toc-time-series-prediction" class="nav-link" data-scroll-target="#time-series-prediction"><span class="header-section-number">10.7.2</span> Time Series Prediction</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch2-statlearning-lab.html"><strong>ISL LABS</strong></a></li><li class="breadcrumb-item"><a href="./ch10-deeplearning-lab.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Lab Chapter 10: Deep Learning</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Lab Chapter 10: Deep Learning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!--Lab Chapter 10: Deep Learning {{{1-->
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Section Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Single layer neural network</li>
<li>Multilayer neural network</li>
<li>Convolutional neural network</li>
<li>Recurrent neural network</li>
</ul>
</div>
</div>
<p>In this section we demonstrate how to fit the examples discussed in the text. We use the <code>Python</code> <code>torch</code> package, along with the <code>pytorch_lightning</code> package which provides utilities to simplify fitting and evaluating models. This code can be impressively fast with certain special processors, such as Appleâ€™s new M1 chip. The package is well-structured, flexible, and will feel comfortable to <code>Python</code> users. A good companion is the site <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">pytorch.org/tutorials</a>. Much of our code is adapted from there, as well as the <code>pytorch_lightning</code> documentation. {The precise URLs at the time of writing are <a href="https://pytorch.org/tutorials/beginner/basics/intro.html" class="uri">https://pytorch.org/tutorials/beginner/basics/intro.html</a> and <a href="https://pytorch-lightning.readthedocs.io/en/latest/" class="uri">https://pytorch-lightning.readthedocs.io/en/latest/</a>.}</p>
<p>There are several other helper packages for <code>PyTorch</code>. For instance, the <code>torchmetrics</code> package has utilities to compute various metrics to evaluate performance when fitting a model. The <code>torchinfo</code> package provides a useful summary of the layers of a model. We use the <code>read_image()</code> function when loading test images in Section 10.9.4.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The ISLP installer does not install <code>torchinfo</code> and <code>torchvision</code>. We need to install those packages up front. Here is my recommended way of installing everything you need for this course.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>In order to install torch and torch_lightning make a new environment first Donâ€™t install Python 3.13 here as PyTorch is not fully supported on the latest Python version</p>
</div>
</div>
<pre><code># If you want to use it inside Spyder also install spyder-kernels==3.0.*
# If you want to use Quarto later also install jupyter
conda create --name myTorchLightning Python=3.11
conda activate myTorchLightning
conda install pip
pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
pip install torchinfo
pip install pytorch_lightning
pip install islp
pip install spyder-kernels==3.0.*
pip install jupyter</code></pre>
<p>We start with several standard imports that we have seen in other contexts.</p>
<!--Package (library) imports {{{2-->
<section id="package-library-imports" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="package-library-imports"><span class="header-section-number">10.1</span> Package (library) imports</h2>
<div id="75c57011" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplots</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> <span class="op">\</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>     (LinearRegression,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>      LogisticRegression,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>      Lasso)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ISLP <span class="im">import</span> load_data</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ISLP.models <span class="im">import</span> ModelSpec <span class="im">as</span> MS</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> <span class="op">\</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>     (train_test_split,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>      GridSearchCV)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="torch-specific-imports" class="level3" data-number="10.1.1">
<h3 data-number="10.1.1" class="anchored" data-anchor-id="torch-specific-imports"><span class="header-section-number">10.1.1</span> Torch-Specific Imports</h3>
<p>There are a number of imports for <code>torch</code>. (These are not included with <code>ISLP</code>, so must be installed separately.) First we import the main library and essential tools used to specify sequentially-structured networks.</p>
<div id="d3199a81" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> RMSprop</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d5e2ae89" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchmetrics <span class="im">import</span> (MeanAbsoluteError,</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>                          R2Score)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchinfo <span class="im">import</span> summary</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.io <span class="im">import</span> read_image</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The package <code>pytorch_lightning</code> is a somewhat higher-level interface to <code>torch</code> that simplifies the specification and fitting of models by reducing the amount of boilerplate code needed (compared to using <code>torch</code> alone).</p>
<div id="edbfe318" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytorch_lightning <span class="im">import</span> Trainer</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytorch_lightning.loggers <span class="im">import</span> CSVLogger</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In order to reproduce results we use <code>seed_everything()</code>. We will also instruct <code>torch</code> to use deterministic algorithms where possible.</p>
<div id="df5a1fdd" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#from pytorch_lightning.utilities.seed import seed_everything</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lightning_fabric.utilities.seed <span class="im">import</span> seed_everything</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>seed_everything(<span class="dv">0</span>, workers<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>torch.use_deterministic_algorithms(<span class="va">True</span>, warn_only<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Seed set to 0</code></pre>
</div>
</div>
<p>We will use several datasets shipped with <code>torchvision</code> for our examples: a pretrained network for image classification, as well as some transforms used for preprocessing.</p>
<div id="42941c68" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets <span class="im">import</span> MNIST, CIFAR100</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> (resnet50,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                                ResNet50_Weights)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> (Resize,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>                                    Normalize,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                                    CenterCrop,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                                    ToTensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We have provided a few utilities in <code>ISLP</code> specifically for this lab. The <code>SimpleDataModule</code> and <code>SimpleModule</code> are simple versions of objects used in <code>pytorch_lightning</code>, the high-level module for fitting <code>torch</code> models. Although more advanced uses such as computing on graphical processing units (GPUs) and parallel data processing are possible in this module, we will not be focusing much on these in this lab. The <code>ErrorTracker</code> handles collections of targets and predictions over each mini-batch in the validation or test stage, allowing computation of the metric over the entire validation or test data set.</p>
<div id="04377f01" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ISLP.torch <span class="im">import</span> (SimpleDataModule,</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>                        SimpleModule,</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>                        ErrorTracker,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>                        rec_num_workers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In addition we have included some helper functions to load the <code>IMDb</code> database, as well as a lookup that maps integers to particular keys in the database. Weâ€™ve included a slightly modified copy of the preprocessed <code>IMDb</code> data from <code>keras</code>, a separate package for fitting deep learning models. This saves us significant preprocessing and allows us to focus on specifying and fitting the models themselves.</p>
<div id="e9c2986a" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ISLP.torch.imdb <span class="im">import</span> (load_lookup,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                             load_tensor,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>                             load_sparse,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>                             load_sequential)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>IMPORTANT. SET this environment variable after importing all the libraries. Otherwise <code>PyTorch</code> throws error You maybe have to restart the console as well for this to take. Make sure you install this on Python 3.11 (not newer as of Jan 6, 2025 as PyTorch does not work on newer versions of Python yet)</p>
</div>
</div>
<div id="56481b60" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"CUBLAS_WORKSPACE_CONFIG"</span>]<span class="op">=</span><span class="st">":4096:8"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, we introduce some utility imports not directly related to <code>torch</code>. The <code>glob()</code> function from the <code>glob</code> module is used to find all files matching wildcard characters, which we will use in our example applying the <code>ResNet50</code> model to some of our own images. The <code>json</code> module will be used to load a JSON file for looking up classes to identify the labels of the pictures in the <code>ResNet50</code> example.</p>
<div id="4673d4c3" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> glob <span class="im">import</span> glob</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!--Single Layer Network on Hitters Data {{{2-->
</section>
</section>
<section id="single-layer-network-on-hitters-data" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="single-layer-network-on-hitters-data"><span class="header-section-number">10.2</span> Single Layer Network on Hitters Data</h2>
<p>We start by fitting the models in Section 10.6 on the <code>Hitters</code> data.</p>
<div id="afa28194" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>Hitters <span class="op">=</span> load_data(<span class="st">'Hitters'</span>).dropna()</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> Hitters.shape[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will fit two linear models (least squares and lasso) and compare their performance to that of a neural network. For this comparison we will use mean absolute error on a validation dataset. <span class="math display">\[\begin{equation*}
\begin{split}
\mbox{MAE}(y,\hat{y}) = \frac{1}{n} \sum_{i=1}^n |y_i-\hat{y}_i|.
\end{split}
\end{equation*}\]</span> We set up the model matrix and the response.</p>
<div id="edc9bb8b" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MS(Hitters.columns.drop(<span class="st">'Salary'</span>), intercept<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> model.fit_transform(Hitters).to_numpy()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> Hitters[<span class="st">'Salary'</span>].to_numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>to_numpy()</code> method above converts <code>pandas</code> data frames or series to <code>numpy</code> arrays. We do this because we will need to use <code>sklearn</code> to fit the lasso model, and it requires this conversion. We also use a linear regression method from <code>sklearn</code>, rather than the method in Chapter~3 from <code>statsmodels</code>, to facilitate the comparisons.</p>
<p>We now split the data into test and training, fixing the random state used by <code>sklearn</code> to do the split.</p>
<div id="9aa19433" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>(X_train,</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a> X_test,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a> Y_train,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a> Y_test) <span class="op">=</span> train_test_split(X,</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>                            Y,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>                            test_size<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                            random_state<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!-- Linear Models {{{3-->
<section id="linear-models" class="level3" data-number="10.2.1">
<h3 data-number="10.2.1" class="anchored" data-anchor-id="linear-models"><span class="header-section-number">10.2.1</span> Linear Models</h3>
<p>We fit the linear model and evaluate the test error directly.</p>
<div id="b16f3180" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>hit_lm <span class="op">=</span> LinearRegression().fit(X_train, Y_train)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>Yhat_test <span class="op">=</span> hit_lm.predict(X_test)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">abs</span>(Yhat_test <span class="op">-</span> Y_test).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>259.7152883314631</code></pre>
</div>
</div>
<p>Next we fit the lasso using <code>sklearn</code>. We are using mean absolute error to select and evaluate a model, rather than mean squared error. The specialized solver we used in Section 6.5.2 uses only mean squared error. So here, with a bit more work, we create a cross-validation grid and perform the cross-validation directly.</p>
<p>We encode a pipeline with two steps: we first normalize the features using a <code>StandardScaler()</code> transform, and then fit the lasso without further normalization.</p>
<div id="9a79183a" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler(with_mean<span class="op">=</span><span class="va">True</span>, with_std<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>lasso <span class="op">=</span> Lasso(warm_start<span class="op">=</span><span class="va">True</span>, max_iter<span class="op">=</span><span class="dv">30000</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>standard_lasso <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">'scaler'</span>, scaler),</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>                                 (<span class="st">'lasso'</span>, lasso)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We need to create a grid of values for <span class="math inline">\(\lambda\)</span>. As is common practice, we choose a grid of 100 values of <span class="math inline">\(\lambda\)</span>, uniform on the log scale from <code>lam_max</code> down to <code>0.01*lam_max</code>. Here <code>lam_max</code> is the smallest value of <span class="math inline">\(\lambda\)</span> with an all-zero solution. This value equals the largest absolute inner-product between any predictor and the (centered) response. {The derivation of this result is beyond the scope of this book.}</p>
<div id="a394a806" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>X_s <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> X_s.shape[<span class="dv">0</span>]</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>lam_max <span class="op">=</span> np.fabs(X_s.T.dot(Y_train <span class="op">-</span> Y_train.mean())).<span class="bu">max</span>() <span class="op">/</span> n</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'alpha'</span>: np.exp(np.linspace(<span class="dv">0</span>, np.log(<span class="fl">0.01</span>), <span class="dv">100</span>))</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>             <span class="op">*</span> lam_max}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that we had to transform the data first, since the scale of the variables impacts the choice of <span class="math inline">\(\lambda\)</span>. We now perform cross-validation using this sequence of <span class="math inline">\(\lambda\)</span> values.</p>
<div id="972ce686" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> KFold(<span class="dv">10</span>,</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>           shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>           random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(lasso,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>                    param_grid,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>                    cv<span class="op">=</span>cv,</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>                    scoring<span class="op">=</span><span class="st">'neg_mean_absolute_error'</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>grid.fit(X_train, Y_train)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We extract the lasso model with best cross-validated mean absolute error, and evaluate its performance on <code>X_test</code> and <code>Y_test</code>, which were not used in cross-validation.</p>
<div id="9a57dd89" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>trained_lasso <span class="op">=</span> grid.best_estimator_</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>Yhat_test <span class="op">=</span> trained_lasso.predict(X_test)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>np.fabs(Yhat_test <span class="op">-</span> Y_test).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>257.23820107995</code></pre>
</div>
</div>
<p>This is similar to the results we got for the linear model fit by least squares. However, these results can vary a lot for different train/test splits; we encourage the reader to try a different seed in code block 12 and rerun the subsequent code up to this point.</p>
<!-- Specifying a Network: Classes and Inheritance {{{3-->
</section>
<section id="specifying-a-network-classes-and-inheritance" class="level3" data-number="10.2.2">
<h3 data-number="10.2.2" class="anchored" data-anchor-id="specifying-a-network-classes-and-inheritance"><span class="header-section-number">10.2.2</span> Specifying a Network: Classes and Inheritance</h3>
<p>To fit the neural network, we first set up a model structure that describes the network. Doing so requires us to define new classes specific to the model we wish to fit. Typically this is done in <code>pytorch</code> by sub-classing a generic representation of a network, which is the approach we take here. Although this example is simple, we will go through the steps in some detail, since it will serve us well for the more complex examples to follow.</p>
<div id="9b485c9c" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> HittersModel(nn.Module):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(HittersModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sequential <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>            nn.Linear(input_size, <span class="dv">50</span>),</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.4</span>),</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">50</span>, <span class="dv">1</span>))</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.flatten(<span class="va">self</span>.sequential(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>class</code> statement identifies the code chunk as a declaration for a class <code>HittersModel</code> that inherits from the base class <code>nn.Module</code>. This base class is ubiquitous in <code>torch</code> and represents the mappings in the neural networks.</p>
<p>Indented beneath the <code>class</code> statement are the methods of this class: in this case <code>__init__</code> and <code>forward</code>. The <code>__init__</code> method is called when an instance of the class is created as in the cell below. In the methods, <code>self</code> always refers to an instance of the class. In the <code>__init__</code> method, we have attached two objects to <code>self</code> as attributes: <code>flatten</code> and <code>sequential</code>. These are used in the <code>forward</code> method to describe the map that this module implements.</p>
<p>There is one additional line in the <code>__init__</code> method, which is a call to <code>super()</code>. This function allows subclasses (i.e.&nbsp;<code>HittersModel</code>) to access methods of the class they inherit from. For example, the class <code>nn.Module</code> has its own <code>__init__</code> method, which is different from the <code>HittersModel.__init__()</code> method weâ€™ve written above. Using <code>super()</code> allows us to call the method of the base class. For <code>torch</code> models, we will always be making this <code>super()</code> call as it is necessary for the model to be properly interpreted by <code>torch</code>.</p>
<p>The object <code>nn.Module</code> has more methods than simply <code>__init__</code> and <code>forward</code>. These methods are directly accessible to <code>HittersModel</code> instances because of this inheritance. One such method we will see shortly is the <code>eval()</code> method, used to disable dropout for when we want to evaluate the model on test data.</p>
<div id="4a2d811b" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>hit_model <span class="op">=</span> HittersModel(X.shape[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The object <code>self.sequential</code> is a composition of four maps. The first maps the 19 features of <code>Hitters</code> to 50 dimensions, introducing <span class="math inline">\(50\times 19+50\)</span> parameters for the weights and <em>intercept</em> of the map (often called the <em>bias</em>). This layer is then mapped to a ReLU layer followed by a 40% dropout layer, and finally a linear map down to 1 dimension, again with a bias. The total number of trainable parameters is therefore <span class="math inline">\(50\times 19+50+50+1=1051\)</span>.</p>
<p>The package <code>torchinfo</code> provides a <code>summary()</code> function that neatly summarizes this information. We specify the size of the input and see the size of each tensor as it passes through layers of the network.</p>
<div id="4dbf524c" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>summary(hit_model,</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>        input_size<span class="op">=</span>X_train.shape,</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        col_names<span class="op">=</span>[<span class="st">'input_size'</span>,</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'output_size'</span>,</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'num_params'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>===================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #
===================================================================================================================
HittersModel                             [175, 19]                 [175]                     --
â”œâ”€Flatten: 1-1                           [175, 19]                 [175, 19]                 --
â”œâ”€Sequential: 1-2                        [175, 19]                 [175, 1]                  --
â”‚    â””â”€Linear: 2-1                       [175, 19]                 [175, 50]                 1,000
â”‚    â””â”€ReLU: 2-2                         [175, 50]                 [175, 50]                 --
â”‚    â””â”€Dropout: 2-3                      [175, 50]                 [175, 50]                 --
â”‚    â””â”€Linear: 2-4                       [175, 50]                 [175, 1]                  51
===================================================================================================================
Total params: 1,051
Trainable params: 1,051
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.18
===================================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.07
Params size (MB): 0.00
Estimated Total Size (MB): 0.09
===================================================================================================================</code></pre>
</div>
</div>
<p>We have truncated the end of the output slightly, here and in subsequent uses.</p>
<p>We now need to transform our training data into a form accessible to <code>torch</code>. The basic datatype in <code>torch</code> is a <code>tensor</code>, which is very similar to an <code>ndarray</code> from early chapters. We also note here that <code>torch</code> typically works with 32-bit (<em>single precision</em>) rather than 64-bit (<em>double precision</em>) floating point numbers. We therefore convert our data to <code>np.float32</code> before forming the tensor. The <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> tensors are then arranged into a <code>Dataset</code> recognized by <code>torch</code> using <code>TensorDataset()</code>.</p>
<div id="0b39fa2c" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>X_train_t <span class="op">=</span> torch.tensor(X_train.astype(np.float32))</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>Y_train_t <span class="op">=</span> torch.tensor(Y_train.astype(np.float32))</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>hit_train <span class="op">=</span> TensorDataset(X_train_t, Y_train_t)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We do the same for the test data.</p>
<div id="2d374c89" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>X_test_t <span class="op">=</span> torch.tensor(X_test.astype(np.float32))</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>Y_test_t <span class="op">=</span> torch.tensor(Y_test.astype(np.float32))</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>hit_test <span class="op">=</span> TensorDataset(X_test_t, Y_test_t)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, this dataset is passed to a <code>DataLoader()</code> which ultimately passes data into our network. While this may seem like a lot of overhead, this structure is helpful for more complex tasks where data may live on different machines, or where data must be passed to a GPU. We provide a helper function <code>SimpleDataModule()</code> in <code>ISLP</code> to make this task easier for standard usage. One of its arguments is <code>num_workers</code>, which indicates how many processes we will use for loading the data. For small data like <code>Hitters</code> this will have little effect, but it does provide an advantage for the <code>MNIST</code> and <code>CIFAR100</code> examples below. The <code>torch</code> package will inspect the process running and determine a maximum number of workers. {This depends on the computing hardware and the number of cores available.} Weâ€™ve included a function <code>rec_num_workers()</code> to compute this so we know how many workers might be reasonable (here the max was 16).</p>
<div id="de84e158" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>max_num_workers <span class="op">=</span> rec_num_workers()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The general training setup in <code>pytorch_lightning</code> involves training, validation and test data. These are each represented by different data loaders. During each epoch, we run a training step to learn the model and a validation step to track the error. The test data is typically used at the end of training to evaluate the model.</p>
<p>In this case, as we had split only into test and training, weâ€™ll use the test data as validation data with the argument <code>validation=hit_test</code>. The <code>validation</code> argument can be a float between 0 and 1, an integer, or a <code>Dataset</code>. If a float (respectively, integer), it is interpreted as a percentage (respectively number) of the <em>training</em> observations to be used for validation. If it is a <code>Dataset</code>, it is passed directly to a data loader.</p>
<div id="0d8bb031" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>hit_dm <span class="op">=</span> SimpleDataModule(hit_train,</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>                          hit_test,</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>                          batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>                          num_workers<span class="op">=</span><span class="bu">min</span>(<span class="dv">4</span>, max_num_workers),</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>                          validation<span class="op">=</span>hit_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next we must provide a <code>pytorch_lightning</code> module that controls the steps performed during the training process. We provide methods for our <code>SimpleModule()</code> that simply record the value of the loss function and any additional metrics at the end of each epoch. These operations are controlled by the methods <code>SimpleModule.[training/test/validation]_step()</code>, though we will not be modifying these in our examples.</p>
<div id="1c4d4d10" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>hit_module <span class="op">=</span> SimpleModule.regression(hit_model,</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>                           metrics<span class="op">=</span>{<span class="st">'mae'</span>:MeanAbsoluteError()})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>By using the <code>SimpleModule.regression()</code> method, we indicate that we will use squared-error loss as in (10.23). We have also asked for mean absolute error to be tracked as well in the metrics that are logged.</p>
<p>We log our results via <code>CSVLogger()</code>, which in this case stores the results in a CSV file within a directory <code>logs/hitters</code>. After the fitting is complete, this allows us to load the results as a <code>pd.DataFrame()</code> and visualize them below. There are several ways to log the results within <code>pytorch_lightning</code>, though we will not cover those here in detail.</p>
<div id="72c902cc" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>hit_logger <span class="op">=</span> CSVLogger(<span class="st">'logs'</span>, name<span class="op">=</span><span class="st">'hitters'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally we are ready to train our model and log the results. We use the <code>Trainer()</code> object from <code>pytorch_lightning</code> to do this work. The argument <code>datamodule=hit_dm</code> tells the trainer how training/validation/test logs are produced, while the first argument <code>hit_module</code> specifies the network architecture as well as the training/validation/test steps. The <code>callbacks</code> argument allows for several tasks to be carried out at various points while training a model. Here our <code>ErrorTracker()</code> callback will enable us to compute validation error while training and, finally, the test error. We now fit the model for 50 epochs.</p>
<div id="44164664" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>hit_trainer <span class="op">=</span> Trainer(deterministic<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>                      max_epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>                      log_every_n_steps<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>                      logger<span class="op">=</span>hit_logger,</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>                      enable_progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>                      callbacks<span class="op">=</span>[ErrorTracker()])</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>hit_trainer.fit(hit_module, datamodule<span class="op">=</span>hit_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type         | Params | Mode 
-----------------------------------------------
0 | model | HittersModel | 1.1 K  | train
1 | loss  | MSELoss      | 0      | train
-----------------------------------------------
1.1 K     Trainable params
0         Non-trainable params
1.1 K     Total params
0.004     Total estimated model params size (MB)
8         Modules in train mode
0         Modules in eval mode
`Trainer.fit` stopped: `max_epochs=50` reached.</code></pre>
</div>
</div>
<p>At each step of SGD, the algorithm randomly selects 32 training observations for the computation of the gradient. Recall from Section 10.7 that an epoch amounts to the number of SGD steps required to process <span class="math inline">\(n\)</span> observations. Since the training set has <span class="math inline">\(n=175\)</span>, and we specified a <code>batch_size</code> of 32 in the construction of <code>hit_dm</code>, an epoch is <span class="math inline">\(175/32=5.5\)</span> SGD steps.</p>
<p>After having fit the model, we can evaluate performance on our test data using the <code>test()</code> method of our trainer.</p>
<div id="621fd5e5" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>hit_trainer.test(hit_module, datamodule<span class="op">=</span>hit_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       Test metric             DataLoader 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        test_loss               123543.3125
        test_mae            248.27792358398438
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>[{'test_loss': 123543.3125, 'test_mae': 248.27792358398438}]</code></pre>
</div>
</div>
<p>The results of the fit have been logged into a CSV file. We can find the results specific to this run in the <code>experiment.metrics_file_path</code> attribute of our logger. Note that each time the model is fit, the logger will output results into a new subdirectory of our directory <code>logs/hitters</code>.</p>
<p>We now create a plot of the MAE (mean absolute error) as a function of the number of epochs. First we retrieve the logged summaries.</p>
<div id="ae488431" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>hit_results <span class="op">=</span> pd.read_csv(hit_logger.experiment.metrics_file_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Since we will produce similar plots in later examples, we write a simple generic function to produce this plot.</p>
<div id="7853a178" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> summary_plot(results,</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>                 ax,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>                 col<span class="op">=</span><span class="st">'loss'</span>,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>                 valid_legend<span class="op">=</span><span class="st">'Validation'</span>,</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>                 training_legend<span class="op">=</span><span class="st">'Training'</span>,</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>                 ylabel<span class="op">=</span><span class="st">'Loss'</span>,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>                 fontsize<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (column,</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>         color,</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>         label) <span class="kw">in</span> <span class="bu">zip</span>([<span class="ss">f'train_</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">_epoch'</span>,</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>                        <span class="ss">f'valid_</span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">'</span>],</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>                       [<span class="st">'black'</span>,</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'red'</span>],</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>                       [training_legend,</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>                        valid_legend]):</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>        results.plot(x<span class="op">=</span><span class="st">'epoch'</span>,</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>                     y<span class="op">=</span>column,</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>                     label<span class="op">=</span>label,</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>                     marker<span class="op">=</span><span class="st">'o'</span>,</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>                     color<span class="op">=</span>color,</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>                     ax<span class="op">=</span>ax)</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(ylabel)</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ax</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now set up our axes, and use our function to produce the MAE plot.</p>
<div id="08a33647" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> summary_plot(hit_results,</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>                  ax,</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>                  col<span class="op">=</span><span class="st">'mae'</span>,</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>                  ylabel<span class="op">=</span><span class="st">'MAE'</span>,</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>                  valid_legend<span class="op">=</span><span class="st">'Validation (=Test)'</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="dv">0</span>, <span class="dv">400</span>])</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(np.linspace(<span class="dv">0</span>, <span class="dv">50</span>, <span class="dv">11</span>).astype(<span class="bu">int</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="ch10-deeplearning-lab_files/figure-html/cell-33-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="ch10-deeplearning-lab_files/figure-html/cell-33-output-1.png" width="519" height="508" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We can predict directly from the final model, and evaluate its performance on the test data. Before fitting, we call the <code>eval()</code> method of <code>hit_model</code>. This tells <code>torch</code> to effectively consider this model to be fitted, so that we can use it to predict on new data. For our model here, the biggest change is that the dropout layers will be turned off, i.e.&nbsp;no weights will be randomly dropped in predicting on new data.</p>
<div id="774c6f17" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>hit_model.<span class="bu">eval</span>()</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> hit_module(X_test_t)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">abs</span>(Y_test_t <span class="op">-</span> preds).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>tensor(248.2779, grad_fn=&lt;MeanBackward0&gt;)</code></pre>
</div>
</div>
<!-- Cleanup {{{3-->
</section>
<section id="cleanup" class="level3" data-number="10.2.3">
<h3 data-number="10.2.3" class="anchored" data-anchor-id="cleanup"><span class="header-section-number">10.2.3</span> Cleanup</h3>
<p>In setting up our data module, we had initiated several worker processes that will remain running. We delete all references to the torch objects to ensure these processes will be killed.</p>
<div id="f3a28652" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span>(Hitters,</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    hit_model, hit_dm,</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    hit_logger,</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    hit_test, hit_train,</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    X, Y,</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    X_test, X_train,</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    Y_test, Y_train,</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    X_test_t, Y_test_t,</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    hit_trainer, hit_module)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!--Multilayer Network on the MNIST Digit Data {{{2-->
</section>
</section>
<section id="multilayer-network-on-the-mnist-digit-data" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="multilayer-network-on-the-mnist-digit-data"><span class="header-section-number">10.3</span> Multilayer Network on the MNIST Digit Data</h2>
<p>The <code>torchvision</code> package comes with a number of example datasets, including the <code>MNIST</code> digit data. Our first step is to retrieve the training and test data sets; the <code>MNIST()</code> function within <code>torchvision.datasets</code> is provided for this purpose. The data will be downloaded the first time this function is executed, and stored in the directory <code>data/MNIST</code>.</p>
<div id="f9378d6d" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>(mnist_train,</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a> mnist_test) <span class="op">=</span> [MNIST(root<span class="op">=</span><span class="st">'data'</span>,</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>                      train<span class="op">=</span>train,</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>                      download<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>                      transform<span class="op">=</span>ToTensor())</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> train <span class="kw">in</span> [<span class="va">True</span>, <span class="va">False</span>]]</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>mnist_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>Dataset MNIST
    Number of datapoints: 60000
    Root location: data
    Split: Train
    StandardTransform
Transform: ToTensor()</code></pre>
</div>
</div>
<p>There are 60,000 images in the training data and 10,000 in the test data. The images are <span class="math inline">\(28\times 28\)</span>, and stored as a matrix of pixels. We need to transform each one into a vector.</p>
<p>Neural networks are somewhat sensitive to the scale of the inputs, much as ridge and lasso regularization are affected by scaling. Here the inputs are eight-bit grayscale values between 0 and 255, so we rescale to the unit interval. {Note: eight bits means <span class="math inline">\(2^8\)</span>, which equals 256. Since the convention is to start at <span class="math inline">\(0\)</span>, the possible values range from <span class="math inline">\(0\)</span> to <span class="math inline">\(255\)</span>.} This transformation, along with some reordering of the axes, is performed by the <code>ToTensor()</code> transform from the <code>torchvision.transforms</code> package.</p>
<p>As in our <code>Hitters</code> example, we form a data module from the training and test datasets, setting aside 20% of the training images for validation.</p>
<div id="d85f46de" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>mnist_dm <span class="op">=</span> SimpleDataModule(mnist_train,</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>                            mnist_test,</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>                            validation<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>                            num_workers<span class="op">=</span>max_num_workers,</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>                            batch_size<span class="op">=</span><span class="dv">256</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Letâ€™s take a look at the data that will get fed into our network. We loop through the first few chunks of the test dataset, breaking after 2 batches:</p>
<div id="41f1b255" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, (X_ ,Y_) <span class="kw">in</span> <span class="bu">enumerate</span>(mnist_dm.train_dataloader()):</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'X: '</span>, X_.shape)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Y: '</span>, Y_.shape)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> idx <span class="op">&gt;=</span> <span class="dv">1</span>:</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>X:  torch.Size([256, 1, 28, 28])
Y:  torch.Size([256])
X:  torch.Size([256, 1, 28, 28])
Y:  torch.Size([256])</code></pre>
</div>
</div>
<p>We see that the <span class="math inline">\(X\)</span> for each batch consists of 256 images of size <code>1x28x28</code>. Here the <code>1</code> indicates a single channel (greyscale). For RGB images such as <code>CIFAR100</code> below, we will see that the <code>1</code> in the size will be replaced by <code>3</code> for the three RGB channels.</p>
<p>Now we are ready to specify our neural network.</p>
<div id="cd00cd10" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MNISTModel(nn.Module):</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MNISTModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1 <span class="op">=</span> nn.Sequential(</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>, <span class="dv">256</span>),</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.4</span>))</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer2 <span class="op">=</span> nn.Sequential(</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">256</span>, <span class="dv">128</span>),</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.3</span>))</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._forward <span class="op">=</span> nn.Sequential(</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.layer1,</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.layer2,</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">128</span>, <span class="dv">10</span>))</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>._forward(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We see that in the first layer, each <code>1x28x28</code> image is flattened, then mapped to 256 dimensions where we apply a ReLU activation with 40% dropout. A second layer maps the first layerâ€™s output down to 128 dimensions, applying a ReLU activation with 30% dropout. Finally, the 128 dimensions are mapped down to 10, the number of classes in the <code>MNIST</code> data.</p>
<div id="1b284b2c" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>mnist_model <span class="op">=</span> MNISTModel()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can check that the model produces output of expected size based on our existing batch <code>X_</code> above.</p>
<div id="0fefa14f" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>mnist_model(X_).size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>torch.Size([256, 10])</code></pre>
</div>
</div>
<p>Letâ€™s take a look at the summary of the model. Instead of an <code>input_size</code> we can pass a tensor of correct shape. In this case, we pass through the final batched <code>X_</code> from above.</p>
<div id="8be43b38" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>summary(mnist_model,</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>        input_data<span class="op">=</span>X_,</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>        col_names<span class="op">=</span>[<span class="st">'input_size'</span>,</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'output_size'</span>,</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'num_params'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>===================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #
===================================================================================================================
MNISTModel                               [256, 1, 28, 28]          [256, 10]                 --
â”œâ”€Sequential: 1-1                        [256, 1, 28, 28]          [256, 10]                 --
â”‚    â””â”€Sequential: 2-1                   [256, 1, 28, 28]          [256, 256]                --
â”‚    â”‚    â””â”€Flatten: 3-1                 [256, 1, 28, 28]          [256, 784]                --
â”‚    â”‚    â””â”€Linear: 3-2                  [256, 784]                [256, 256]                200,960
â”‚    â”‚    â””â”€ReLU: 3-3                    [256, 256]                [256, 256]                --
â”‚    â”‚    â””â”€Dropout: 3-4                 [256, 256]                [256, 256]                --
â”‚    â””â”€Sequential: 2-2                   [256, 256]                [256, 128]                --
â”‚    â”‚    â””â”€Linear: 3-5                  [256, 256]                [256, 128]                32,896
â”‚    â”‚    â””â”€ReLU: 3-6                    [256, 128]                [256, 128]                --
â”‚    â”‚    â””â”€Dropout: 3-7                 [256, 128]                [256, 128]                --
â”‚    â””â”€Linear: 2-3                       [256, 128]                [256, 10]                 1,290
===================================================================================================================
Total params: 235,146
Trainable params: 235,146
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 60.20
===================================================================================================================
Input size (MB): 0.80
Forward/backward pass size (MB): 0.81
Params size (MB): 0.94
Estimated Total Size (MB): 2.55
===================================================================================================================</code></pre>
</div>
</div>
<p>Having set up both the model and the data module, fitting this model is now almost identical to the <code>Hitters</code> example. In contrast to our regression model, here we will use the <code>SimpleModule.classification()</code> method which uses the cross-entropy loss function instead of mean squared error.</p>
<div id="78470d9a" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>mnist_module <span class="op">=</span> SimpleModule.classification(mnist_model, num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>mnist_logger <span class="op">=</span> CSVLogger(<span class="st">'logs'</span>, name<span class="op">=</span><span class="st">'MNIST'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we are ready to go. The final step is to supply training data, and fit the model.</p>
<div id="5d02c5f0" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>mnist_trainer <span class="op">=</span> Trainer(deterministic<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>                        max_epochs<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>                        logger<span class="op">=</span>mnist_logger,</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>                        enable_progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>                        callbacks<span class="op">=</span>[ErrorTracker()])</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>mnist_trainer.fit(mnist_module,</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>                  datamodule<span class="op">=</span>mnist_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type             | Params | Mode 
---------------------------------------------------
0 | model | MNISTModel       | 235 K  | train
1 | loss  | CrossEntropyLoss | 0      | train
---------------------------------------------------
235 K     Trainable params
0         Non-trainable params
235 K     Total params
0.941     Total estimated model params size (MB)
13        Modules in train mode
0         Modules in eval mode
`Trainer.fit` stopped: `max_epochs=30` reached.</code></pre>
</div>
</div>
<p>We have suppressed the output here, which is a progress report on the fitting of the model, grouped by epoch. This is very useful, since on large datasets fitting can take time. Fitting this model took 245 seconds on a MacBook Pro with an Apple M1 Pro chip with 10 cores and 16 GB of RAM. Here we specified a validation split of 20%, so training is actually performed on 80% of the 60,000 observations in the training set. This is an alternative to actually supplying validation data, like we did for the <code>Hitters</code> data. SGD uses batches of 256 observations in computing the gradient, and doing the arithmetic, we see that an epoch corresponds to 188 gradient steps.</p>
<p><code>SimpleModule.classification()</code> includes an accuracy metric by default. Other classification metrics can be added from <code>torchmetrics</code>. We will use our <code>summary_plot()</code> function to display accuracy across epochs.</p>
<div id="6fad687c" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>mnist_results <span class="op">=</span> pd.read_csv(mnist_logger.experiment.metrics_file_path)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>summary_plot(mnist_results,</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>             ax,</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>             col<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>             ylabel<span class="op">=</span><span class="st">'Accuracy'</span>)</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="fl">0.5</span>, <span class="dv">1</span>])</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(np.linspace(<span class="dv">0</span>, <span class="dv">30</span>, <span class="dv">7</span>).astype(<span class="bu">int</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="ch10-deeplearning-lab_files/figure-html/cell-45-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="ch10-deeplearning-lab_files/figure-html/cell-45-output-1.png" width="517" height="508" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Once again we evaluate the accuracy using the <code>test()</code> method of our trainer. This model achieves 97% accuracy on the test data.</p>
<div id="dba89f22" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>mnist_trainer.test(mnist_module,</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>                   datamodule<span class="op">=</span>mnist_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       Test metric             DataLoader 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      test_accuracy         0.9632999897003174
        test_loss           0.14743490517139435
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>[{'test_loss': 0.14743490517139435, 'test_accuracy': 0.9632999897003174}]</code></pre>
</div>
</div>
<p>Table 10.1 also reports the error rates resulting from LDA (Chapter 4) and multiclass logistic regression. For LDA we refer the reader to Section 4.7.3. Although we could use the <code>sklearn</code> function <code>LogisticRegression()</code> to fit multiclass logistic regression, we are set up here to fit such a model with <code>torch</code>. We just have an input layer and an output layer, and omit the hidden layers!</p>
<div id="498ce491" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MNIST_MLR(nn.Module):</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MNIST_MLR, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Sequential(nn.Flatten(),</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>                                    nn.Linear(<span class="dv">784</span>, <span class="dv">10</span>))</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.linear(x)</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>mlr_model <span class="op">=</span> MNIST_MLR()</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>mlr_module <span class="op">=</span> SimpleModule.classification(mlr_model, num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>mlr_logger <span class="op">=</span> CSVLogger(<span class="st">'logs'</span>, name<span class="op">=</span><span class="st">'MNIST_MLR'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="944aa68e" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>mlr_trainer <span class="op">=</span> Trainer(deterministic<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>                      max_epochs<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>                      enable_progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>                      callbacks<span class="op">=</span>[ErrorTracker()])</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>mlr_trainer.fit(mlr_module, datamodule<span class="op">=</span>mnist_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/jjung/anaconda3/envs/islp/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type             | Params | Mode 
---------------------------------------------------
0 | model | MNIST_MLR        | 7.9 K  | train
1 | loss  | CrossEntropyLoss | 0      | train
---------------------------------------------------
7.9 K     Trainable params
0         Non-trainable params
7.9 K     Total params
0.031     Total estimated model params size (MB)
5         Modules in train mode
0         Modules in eval mode
`Trainer.fit` stopped: `max_epochs=30` reached.</code></pre>
</div>
</div>
<p>We fit the model just as before and compute the test results.</p>
<div id="ccfbd17f" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>mlr_trainer.test(mlr_module,</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>                 datamodule<span class="op">=</span>mnist_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       Test metric             DataLoader 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      test_accuracy          0.920799970626831
        test_loss           0.33121004700660706
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>[{'test_loss': 0.33121004700660706, 'test_accuracy': 0.920799970626831}]</code></pre>
</div>
</div>
<p>The accuracy is above 90% even for this pretty simple model.</p>
<p>As in the <code>Hitters</code> example, we delete some of the objects we created above.</p>
<div id="b8622539" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span>(mnist_test,</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    mnist_train,</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>    mnist_model,</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>    mnist_dm,</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    mnist_trainer,</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    mnist_module,</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>    mnist_results,</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>    mlr_model,</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>    mlr_module,</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>    mlr_trainer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!--Convolutional Neural Networks {{{2-->
</section>
<section id="convolutional-neural-networks" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="convolutional-neural-networks"><span class="header-section-number">10.4</span> Convolutional Neural Networks</h2>
<p>In this section we fit a CNN to the <code>CIFAR100</code> data, which is available in the <code>torchvision</code> package. It is arranged in a similar fashion as the <code>MNIST</code> data.</p>
<div id="0f4c7eee" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>(cifar_train,</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a> cifar_test) <span class="op">=</span> [CIFAR100(root<span class="op">=</span><span class="st">"data"</span>,</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>                         train<span class="op">=</span>train,</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>                         download<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>             <span class="cf">for</span> train <span class="kw">in</span> [<span class="va">True</span>, <span class="va">False</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Files already downloaded and verified
Files already downloaded and verified</code></pre>
</div>
</div>
<div id="66149e9c" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> ToTensor()</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>cifar_train_X <span class="op">=</span> torch.stack([transform(x) <span class="cf">for</span> x <span class="kw">in</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>                            cifar_train.data])</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>cifar_test_X <span class="op">=</span> torch.stack([transform(x) <span class="cf">for</span> x <span class="kw">in</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>                            cifar_test.data])</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>cifar_train <span class="op">=</span> TensorDataset(cifar_train_X,</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>                            torch.tensor(cifar_train.targets))</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>cifar_test <span class="op">=</span> TensorDataset(cifar_test_X,</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>                            torch.tensor(cifar_test.targets))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>CIFAR100</code> dataset consists of 50,000 training images, each represented by a three-dimensional tensor: each three-color image is represented as a set of three channels, each of which consists of <span class="math inline">\(32\times 32\)</span> eight-bit pixels. We standardize as we did for the digits, but keep the array structure. This is accomplished with the <code>ToTensor()</code> transform.</p>
<p>Creating the data module is similar to the <code>MNIST</code> example.</p>
<div id="87049b14" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>cifar_dm <span class="op">=</span> SimpleDataModule(cifar_train,</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>                            cifar_test,</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>                            validation<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>                            num_workers<span class="op">=</span>max_num_workers,</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>                            batch_size<span class="op">=</span><span class="dv">128</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We again look at the shape of typical batches in our data loaders.</p>
<div id="e8a34e06" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, (X_ ,Y_) <span class="kw">in</span> <span class="bu">enumerate</span>(cifar_dm.train_dataloader()):</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'X: '</span>, X_.shape)</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Y: '</span>, Y_.shape)</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> idx <span class="op">&gt;=</span> <span class="dv">1</span>:</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>X:  torch.Size([128, 3, 32, 32])
Y:  torch.Size([128])
X:  torch.Size([128, 3, 32, 32])
Y:  torch.Size([128])</code></pre>
</div>
</div>
<p>Before we start, we look at some of the training images; similar code produced Figure 10.5 on page 445. The example below also illustrates that <code>TensorDataset</code> objects can be indexed with integers â€” we are choosing random images from the training data by indexing <code>cifar_train</code>. In order to display correctly, we must reorder the dimensions by a call to <code>np.transpose()</code>.</p>
<div id="28947e93" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> subplots(<span class="dv">5</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(<span class="dv">4</span>)</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> rng.choice(np.arange(<span class="bu">len</span>(cifar_train)), <span class="dv">25</span>,</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>                     replace<span class="op">=</span><span class="va">False</span>).reshape((<span class="dv">5</span>,<span class="dv">5</span>))</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>        idx <span class="op">=</span> indices[i,j]</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>        axes[i,j].imshow(np.transpose(cifar_train[idx][<span class="dv">0</span>],</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>                                      [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>]),</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>                                      interpolation<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>        axes[i,j].set_xticks([])</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>        axes[i,j].set_yticks([])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="ch10-deeplearning-lab_files/figure-html/cell-55-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="ch10-deeplearning-lab_files/figure-html/cell-55-output-1.png" width="762" height="758" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Here the <code>imshow()</code> method recognizes from the shape of its argument that it is a 3-dimensional array, with the last dimension indexing the three RGB color channels.</p>
<p>We specify a moderately-sized CNN for demonstration purposes, similar in structure to Figure 10.8. We use several layers, each consisting of convolution, ReLU, and max-pooling steps. We first define a module that defines one of these layers. As in our previous examples, we overwrite the <code>__init__()</code> and <code>forward()</code> methods of <code>nn.Module</code>. This user-defined module can now be used in ways just like <code>nn.Linear()</code> or <code>nn.Dropout()</code>.</p>
<div id="3592131b" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BuildingBlock(nn.Module):</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>                 in_channels,</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>                 out_channels):</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(BuildingBlock, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> nn.Conv2d(in_channels<span class="op">=</span>in_channels,</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>                              out_channels<span class="op">=</span>out_channels,</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>                              kernel_size<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">3</span>),</span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>                              padding<span class="op">=</span><span class="st">'same'</span>)</span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activation <span class="op">=</span> nn.ReLU()</span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.pool(<span class="va">self</span>.activation(<span class="va">self</span>.conv(x)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Notice that we used the <code>padding = "same"</code> argument to <code>nn.Conv2d()</code>, which ensures that the output channels have the same dimension as the input channels. There are 32 channels in the first hidden layer, in contrast to the three channels in the input layer. We use a <span class="math inline">\(3\times 3\)</span> convolution filter for each channel in all the layers. Each convolution is followed by a max-pooling layer over <span class="math inline">\(2\times2\)</span> blocks.</p>
<p>In forming our deep learning model for the <code>CIFAR100</code> data, we use several of our <code>BuildingBlock()</code> modules sequentially. This simple example illustrates some of the power of <code>torch</code>. Users can define modules of their own, which can be combined in other modules. Ultimately, everything is fit by a generic trainer.</p>
<div id="1c98dd9d" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CIFARModel(nn.Module):</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(CIFARModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>        sizes <span class="op">=</span> [(<span class="dv">3</span>,<span class="dv">32</span>),</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>                 (<span class="dv">32</span>,<span class="dv">64</span>),</span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>                 (<span class="dv">64</span>,<span class="dv">128</span>),</span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a>                 (<span class="dv">128</span>,<span class="dv">256</span>)]</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> nn.Sequential(<span class="op">*</span>[BuildingBlock(in_, out_)</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>                                    <span class="cf">for</span> in_, out_ <span class="kw">in</span> sizes])</span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output <span class="op">=</span> nn.Sequential(nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a>                                    nn.Linear(<span class="dv">2</span><span class="op">*</span><span class="dv">2</span><span class="op">*</span><span class="dv">256</span>, <span class="dv">512</span>),</span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a>                                    nn.ReLU(),</span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a>                                    nn.Linear(<span class="dv">512</span>, <span class="dv">100</span>))</span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb80-17"><a href="#cb80-17" aria-hidden="true" tabindex="-1"></a>        val <span class="op">=</span> <span class="va">self</span>.conv(x)</span>
<span id="cb80-18"><a href="#cb80-18" aria-hidden="true" tabindex="-1"></a>        val <span class="op">=</span> torch.flatten(val, start_dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb80-19"><a href="#cb80-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.output(val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We build the model and look at the summary. (We had created examples of <code>X_</code> earlier.)</p>
<div id="846b6893" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>cifar_model <span class="op">=</span> CIFARModel()</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>summary(cifar_model,</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>        input_data<span class="op">=</span>X_,</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>        col_names<span class="op">=</span>[<span class="st">'input_size'</span>,</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'output_size'</span>,</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'num_params'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>===================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #
===================================================================================================================
CIFARModel                               [128, 3, 32, 32]          [128, 100]                --
â”œâ”€Sequential: 1-1                        [128, 3, 32, 32]          [128, 256, 2, 2]          --
â”‚    â””â”€BuildingBlock: 2-1                [128, 3, 32, 32]          [128, 32, 16, 16]         --
â”‚    â”‚    â””â”€Conv2d: 3-1                  [128, 3, 32, 32]          [128, 32, 32, 32]         896
â”‚    â”‚    â””â”€ReLU: 3-2                    [128, 32, 32, 32]         [128, 32, 32, 32]         --
â”‚    â”‚    â””â”€MaxPool2d: 3-3               [128, 32, 32, 32]         [128, 32, 16, 16]         --
â”‚    â””â”€BuildingBlock: 2-2                [128, 32, 16, 16]         [128, 64, 8, 8]           --
â”‚    â”‚    â””â”€Conv2d: 3-4                  [128, 32, 16, 16]         [128, 64, 16, 16]         18,496
â”‚    â”‚    â””â”€ReLU: 3-5                    [128, 64, 16, 16]         [128, 64, 16, 16]         --
â”‚    â”‚    â””â”€MaxPool2d: 3-6               [128, 64, 16, 16]         [128, 64, 8, 8]           --
â”‚    â””â”€BuildingBlock: 2-3                [128, 64, 8, 8]           [128, 128, 4, 4]          --
â”‚    â”‚    â””â”€Conv2d: 3-7                  [128, 64, 8, 8]           [128, 128, 8, 8]          73,856
â”‚    â”‚    â””â”€ReLU: 3-8                    [128, 128, 8, 8]          [128, 128, 8, 8]          --
â”‚    â”‚    â””â”€MaxPool2d: 3-9               [128, 128, 8, 8]          [128, 128, 4, 4]          --
â”‚    â””â”€BuildingBlock: 2-4                [128, 128, 4, 4]          [128, 256, 2, 2]          --
â”‚    â”‚    â””â”€Conv2d: 3-10                 [128, 128, 4, 4]          [128, 256, 4, 4]          295,168
â”‚    â”‚    â””â”€ReLU: 3-11                   [128, 256, 4, 4]          [128, 256, 4, 4]          --
â”‚    â”‚    â””â”€MaxPool2d: 3-12              [128, 256, 4, 4]          [128, 256, 2, 2]          --
â”œâ”€Sequential: 1-2                        [128, 1024]               [128, 100]                --
â”‚    â””â”€Dropout: 2-5                      [128, 1024]               [128, 1024]               --
â”‚    â””â”€Linear: 2-6                       [128, 1024]               [128, 512]                524,800
â”‚    â””â”€ReLU: 2-7                         [128, 512]                [128, 512]                --
â”‚    â””â”€Linear: 2-8                       [128, 512]                [128, 100]                51,300
===================================================================================================================
Total params: 964,516
Trainable params: 964,516
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 2.01
===================================================================================================================
Input size (MB): 1.57
Forward/backward pass size (MB): 63.54
Params size (MB): 3.86
Estimated Total Size (MB): 68.97
===================================================================================================================</code></pre>
</div>
</div>
<p>The total number of trainable parameters is 964,516. By studying the size of the parameters, we can see that the channels halve in both dimensions after each of these max-pooling operations. After the last of these we have a layer with 256 channels of dimension <span class="math inline">\(2\times 2\)</span>. These are then flattened to a dense layer of size 1,024; in other words, each of the <span class="math inline">\(2\times 2\)</span> matrices is turned into a <span class="math inline">\(4\)</span>-vector, and put side-by-side in one layer. This is followed by a dropout regularization layer, then another dense layer of size 512, and finally, the output layer.</p>
<p>Up to now, we have been using a default optimizer in <code>SimpleModule()</code>. For these data, experiments show that a smaller learning rate performs better than the default 0.01. We use a custom optimizer here with a learning rate of 0.001. Besides this, the logging and training follow a similar pattern to our previous examples. The optimizer takes an argument <code>params</code> that informs the optimizer which parameters are involved in SGD (stochastic gradient descent).</p>
<p>We saw earlier that entries of a moduleâ€™s parameters are tensors. In passing the parameters to the optimizer we are doing more than simply passing arrays; part of the structure of the graph is encoded in the tensors themselves.</p>
<div id="2aca129d" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>cifar_optimizer <span class="op">=</span> RMSprop(cifar_model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>cifar_module <span class="op">=</span> SimpleModule.classification(cifar_model,</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>                                    num_classes<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>                                    optimizer<span class="op">=</span>cifar_optimizer)</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>cifar_logger <span class="op">=</span> CSVLogger(<span class="st">'logs'</span>, name<span class="op">=</span><span class="st">'CIFAR100'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="407c7905" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>cifar_trainer <span class="op">=</span> Trainer(deterministic<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>                        max_epochs<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>                        logger<span class="op">=</span>cifar_logger,</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>                        enable_progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>                        callbacks<span class="op">=</span>[ErrorTracker()])</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>cifar_trainer.fit(cifar_module,</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>                  datamodule<span class="op">=</span>cifar_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type             | Params | Mode 
---------------------------------------------------
0 | model | CIFARModel       | 964 K  | train
1 | loss  | CrossEntropyLoss | 0      | train
---------------------------------------------------
964 K     Trainable params
0         Non-trainable params
964 K     Total params
3.858     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
`Trainer.fit` stopped: `max_epochs=30` reached.</code></pre>
</div>
</div>
<p>This model takes 10 minutes or more to run and achieves about 42% accuracy on the test data. Although this is not terrible for 100-class data (a random classifier gets 1% accuracy), searching the web we see results around 75%. Typically it takes a lot of architecture carpentry, fiddling with regularization, and time, to achieve such results.</p>
<p>Letâ€™s take a look at the validation and training accuracy across epochs.</p>
<div id="2a8c7e87" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>log_path <span class="op">=</span> cifar_logger.experiment.metrics_file_path</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>cifar_results <span class="op">=</span> pd.read_csv(log_path)</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>summary_plot(cifar_results,</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>             ax,</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>             col<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>             ylabel<span class="op">=</span><span class="st">'Accuracy'</span>)</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">6</span>).astype(<span class="bu">int</span>))</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="dv">0</span>, <span class="dv">1</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="ch10-deeplearning-lab_files/figure-html/cell-61-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="ch10-deeplearning-lab_files/figure-html/cell-61-output-1.png" width="514" height="508" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Finally, we evaluate our model on our test data.</p>
<div id="bb78edae" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>cifar_trainer.test(cifar_module,</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>                   datamodule<span class="op">=</span>cifar_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       Test metric             DataLoader 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      test_accuracy         0.4343000054359436
        test_loss           2.4330503940582275
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>[{'test_loss': 2.4330503940582275, 'test_accuracy': 0.4343000054359436}]</code></pre>
</div>
</div>
<!-- Hardware Acceleration {{{3-->
<section id="hardware-acceleration" class="level3" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="hardware-acceleration"><span class="header-section-number">10.4.1</span> Hardware Acceleration</h3>
<p>As deep learning has become ubiquitous in machine learning, hardware manufacturers have produced special libraries that can often speed up the gradient-descent steps.</p>
<p>For instance, Mac OS devices with the M1 chip may have the <em>Metal</em> programming framework enabled, which can speed up the <code>torch</code> computations. We present an example of how to use this acceleration.</p>
<p>The main changes are to the <code>Trainer()</code> call as well as to the metrics that will be evaluated on the data. These metrics must be told where the data will be located at evaluation time. This is accomplished with a call to the <code>to()</code> method of the metrics.</p>
<div id="cc71552f" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, metric <span class="kw">in</span> cifar_module.metrics.items():</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>        cifar_module.metrics[name] <span class="op">=</span> metric.to(<span class="st">'mps'</span>)</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>    cifar_trainer_mps <span class="op">=</span> Trainer(accelerator<span class="op">=</span><span class="st">'mps'</span>,</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>                                deterministic<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>                                enable_progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>                                max_epochs<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>    cifar_trainer_mps.fit(cifar_module,</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>                          datamodule<span class="op">=</span>cifar_dm)</span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>    cifar_trainer_mps.test(cifar_module,</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>                          datamodule<span class="op">=</span>cifar_dm)</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This yields approximately two- or three-fold acceleration for each epoch. We have protected this code block using <code>try:</code> and <code>except:</code> clauses; if it works, we get the speedup, if it fails, nothing happens.</p>
<!--Using Pretrained CNN Models {{{2-->
</section>
</section>
<section id="using-pretrained-cnn-models" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="using-pretrained-cnn-models"><span class="header-section-number">10.5</span> Using Pretrained CNN Models</h2>
<p>We now show how to use a CNN pretrained on the <code>imagenet</code> database to classify natural images, and demonstrate how we produced Figure 10.10. We copied six JPEG images from a digital photo album into the directory <code>book_images</code>. These images are available from the data section of &lt;www.statlearning.com&gt;, the ISLP book website. Download <code>book_images.zip</code>; when clicked it creates the <code>book_images</code> directory.</p>
<p>The pretrained network we use is called <code>resnet50</code>; specification details can be found on the web. We will read in the images, and convert them into the array format expected by the <code>torch</code> software to match the specifications in <code>resnet50</code>. The conversion involves a resize, a crop and then a predefined standardization for each of the three channels. We now read in the images and preprocess them.</p>
<div id="aebec727" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>resize <span class="op">=</span> Resize((<span class="dv">232</span>,<span class="dv">232</span>))</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>crop <span class="op">=</span> CenterCrop(<span class="dv">224</span>)</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>normalize <span class="op">=</span> Normalize([<span class="fl">0.485</span>,<span class="fl">0.456</span>,<span class="fl">0.406</span>],</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>                      [<span class="fl">0.229</span>,<span class="fl">0.224</span>,<span class="fl">0.225</span>])</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>imgfiles <span class="op">=</span> <span class="bu">sorted</span>([f <span class="cf">for</span> f <span class="kw">in</span> glob(<span class="st">'data/book_images/*'</span>)])</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> torch.stack([torch.div(crop(resize(read_image(f))), <span class="dv">255</span>)</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> f <span class="kw">in</span> imgfiles])</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> normalize(imgs)</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>imgs.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>torch.Size([5, 3, 224, 224])</code></pre>
</div>
</div>
<p>We now set up the trained network with the weights we read in code block~6. The model has 50 layers, with a fair bit of complexity.</p>
<div id="719cf38c" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>resnet_model <span class="op">=</span> resnet50(weights<span class="op">=</span>ResNet50_Weights.DEFAULT)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>summary(resnet_model,</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>        input_data<span class="op">=</span>imgs,</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>        col_names<span class="op">=</span>[<span class="st">'input_size'</span>,</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'output_size'</span>,</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'num_params'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>===================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #
===================================================================================================================
ResNet                                   [5, 3, 224, 224]          [5, 1000]                 --
â”œâ”€Conv2d: 1-1                            [5, 3, 224, 224]          [5, 64, 112, 112]         9,408
â”œâ”€BatchNorm2d: 1-2                       [5, 64, 112, 112]         [5, 64, 112, 112]         128
â”œâ”€ReLU: 1-3                              [5, 64, 112, 112]         [5, 64, 112, 112]         --
â”œâ”€MaxPool2d: 1-4                         [5, 64, 112, 112]         [5, 64, 56, 56]           --
â”œâ”€Sequential: 1-5                        [5, 64, 56, 56]           [5, 256, 56, 56]          --
â”‚    â””â”€Bottleneck: 2-1                   [5, 64, 56, 56]           [5, 256, 56, 56]          --
â”‚    â”‚    â””â”€Conv2d: 3-1                  [5, 64, 56, 56]           [5, 64, 56, 56]           4,096
â”‚    â”‚    â””â”€BatchNorm2d: 3-2             [5, 64, 56, 56]           [5, 64, 56, 56]           128
â”‚    â”‚    â””â”€ReLU: 3-3                    [5, 64, 56, 56]           [5, 64, 56, 56]           --
â”‚    â”‚    â””â”€Conv2d: 3-4                  [5, 64, 56, 56]           [5, 64, 56, 56]           36,864
â”‚    â”‚    â””â”€BatchNorm2d: 3-5             [5, 64, 56, 56]           [5, 64, 56, 56]           128
â”‚    â”‚    â””â”€ReLU: 3-6                    [5, 64, 56, 56]           [5, 64, 56, 56]           --
â”‚    â”‚    â””â”€Conv2d: 3-7                  [5, 64, 56, 56]           [5, 256, 56, 56]          16,384
â”‚    â”‚    â””â”€BatchNorm2d: 3-8             [5, 256, 56, 56]          [5, 256, 56, 56]          512
â”‚    â”‚    â””â”€Sequential: 3-9              [5, 64, 56, 56]           [5, 256, 56, 56]          16,896
â”‚    â”‚    â””â”€ReLU: 3-10                   [5, 256, 56, 56]          [5, 256, 56, 56]          --
â”‚    â””â”€Bottleneck: 2-2                   [5, 256, 56, 56]          [5, 256, 56, 56]          --
â”‚    â”‚    â””â”€Conv2d: 3-11                 [5, 256, 56, 56]          [5, 64, 56, 56]           16,384
â”‚    â”‚    â””â”€BatchNorm2d: 3-12            [5, 64, 56, 56]           [5, 64, 56, 56]           128
â”‚    â”‚    â””â”€ReLU: 3-13                   [5, 64, 56, 56]           [5, 64, 56, 56]           --
â”‚    â”‚    â””â”€Conv2d: 3-14                 [5, 64, 56, 56]           [5, 64, 56, 56]           36,864
â”‚    â”‚    â””â”€BatchNorm2d: 3-15            [5, 64, 56, 56]           [5, 64, 56, 56]           128
â”‚    â”‚    â””â”€ReLU: 3-16                   [5, 64, 56, 56]           [5, 64, 56, 56]           --
â”‚    â”‚    â””â”€Conv2d: 3-17                 [5, 64, 56, 56]           [5, 256, 56, 56]          16,384
â”‚    â”‚    â””â”€BatchNorm2d: 3-18            [5, 256, 56, 56]          [5, 256, 56, 56]          512
â”‚    â”‚    â””â”€ReLU: 3-19                   [5, 256, 56, 56]          [5, 256, 56, 56]          --
â”‚    â””â”€Bottleneck: 2-3                   [5, 256, 56, 56]          [5, 256, 56, 56]          --
â”‚    â”‚    â””â”€Conv2d: 3-20                 [5, 256, 56, 56]          [5, 64, 56, 56]           16,384
â”‚    â”‚    â””â”€BatchNorm2d: 3-21            [5, 64, 56, 56]           [5, 64, 56, 56]           128
â”‚    â”‚    â””â”€ReLU: 3-22                   [5, 64, 56, 56]           [5, 64, 56, 56]           --
â”‚    â”‚    â””â”€Conv2d: 3-23                 [5, 64, 56, 56]           [5, 64, 56, 56]           36,864
â”‚    â”‚    â””â”€BatchNorm2d: 3-24            [5, 64, 56, 56]           [5, 64, 56, 56]           128
â”‚    â”‚    â””â”€ReLU: 3-25                   [5, 64, 56, 56]           [5, 64, 56, 56]           --
â”‚    â”‚    â””â”€Conv2d: 3-26                 [5, 64, 56, 56]           [5, 256, 56, 56]          16,384
â”‚    â”‚    â””â”€BatchNorm2d: 3-27            [5, 256, 56, 56]          [5, 256, 56, 56]          512
â”‚    â”‚    â””â”€ReLU: 3-28                   [5, 256, 56, 56]          [5, 256, 56, 56]          --
â”œâ”€Sequential: 1-6                        [5, 256, 56, 56]          [5, 512, 28, 28]          --
â”‚    â””â”€Bottleneck: 2-4                   [5, 256, 56, 56]          [5, 512, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-29                 [5, 256, 56, 56]          [5, 128, 56, 56]          32,768
â”‚    â”‚    â””â”€BatchNorm2d: 3-30            [5, 128, 56, 56]          [5, 128, 56, 56]          256
â”‚    â”‚    â””â”€ReLU: 3-31                   [5, 128, 56, 56]          [5, 128, 56, 56]          --
â”‚    â”‚    â””â”€Conv2d: 3-32                 [5, 128, 56, 56]          [5, 128, 28, 28]          147,456
â”‚    â”‚    â””â”€BatchNorm2d: 3-33            [5, 128, 28, 28]          [5, 128, 28, 28]          256
â”‚    â”‚    â””â”€ReLU: 3-34                   [5, 128, 28, 28]          [5, 128, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-35                 [5, 128, 28, 28]          [5, 512, 28, 28]          65,536
â”‚    â”‚    â””â”€BatchNorm2d: 3-36            [5, 512, 28, 28]          [5, 512, 28, 28]          1,024
â”‚    â”‚    â””â”€Sequential: 3-37             [5, 256, 56, 56]          [5, 512, 28, 28]          132,096
â”‚    â”‚    â””â”€ReLU: 3-38                   [5, 512, 28, 28]          [5, 512, 28, 28]          --
â”‚    â””â”€Bottleneck: 2-5                   [5, 512, 28, 28]          [5, 512, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-39                 [5, 512, 28, 28]          [5, 128, 28, 28]          65,536
â”‚    â”‚    â””â”€BatchNorm2d: 3-40            [5, 128, 28, 28]          [5, 128, 28, 28]          256
â”‚    â”‚    â””â”€ReLU: 3-41                   [5, 128, 28, 28]          [5, 128, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-42                 [5, 128, 28, 28]          [5, 128, 28, 28]          147,456
â”‚    â”‚    â””â”€BatchNorm2d: 3-43            [5, 128, 28, 28]          [5, 128, 28, 28]          256
â”‚    â”‚    â””â”€ReLU: 3-44                   [5, 128, 28, 28]          [5, 128, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-45                 [5, 128, 28, 28]          [5, 512, 28, 28]          65,536
â”‚    â”‚    â””â”€BatchNorm2d: 3-46            [5, 512, 28, 28]          [5, 512, 28, 28]          1,024
â”‚    â”‚    â””â”€ReLU: 3-47                   [5, 512, 28, 28]          [5, 512, 28, 28]          --
â”‚    â””â”€Bottleneck: 2-6                   [5, 512, 28, 28]          [5, 512, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-48                 [5, 512, 28, 28]          [5, 128, 28, 28]          65,536
â”‚    â”‚    â””â”€BatchNorm2d: 3-49            [5, 128, 28, 28]          [5, 128, 28, 28]          256
â”‚    â”‚    â””â”€ReLU: 3-50                   [5, 128, 28, 28]          [5, 128, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-51                 [5, 128, 28, 28]          [5, 128, 28, 28]          147,456
â”‚    â”‚    â””â”€BatchNorm2d: 3-52            [5, 128, 28, 28]          [5, 128, 28, 28]          256
â”‚    â”‚    â””â”€ReLU: 3-53                   [5, 128, 28, 28]          [5, 128, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-54                 [5, 128, 28, 28]          [5, 512, 28, 28]          65,536
â”‚    â”‚    â””â”€BatchNorm2d: 3-55            [5, 512, 28, 28]          [5, 512, 28, 28]          1,024
â”‚    â”‚    â””â”€ReLU: 3-56                   [5, 512, 28, 28]          [5, 512, 28, 28]          --
â”‚    â””â”€Bottleneck: 2-7                   [5, 512, 28, 28]          [5, 512, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-57                 [5, 512, 28, 28]          [5, 128, 28, 28]          65,536
â”‚    â”‚    â””â”€BatchNorm2d: 3-58            [5, 128, 28, 28]          [5, 128, 28, 28]          256
â”‚    â”‚    â””â”€ReLU: 3-59                   [5, 128, 28, 28]          [5, 128, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-60                 [5, 128, 28, 28]          [5, 128, 28, 28]          147,456
â”‚    â”‚    â””â”€BatchNorm2d: 3-61            [5, 128, 28, 28]          [5, 128, 28, 28]          256
â”‚    â”‚    â””â”€ReLU: 3-62                   [5, 128, 28, 28]          [5, 128, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-63                 [5, 128, 28, 28]          [5, 512, 28, 28]          65,536
â”‚    â”‚    â””â”€BatchNorm2d: 3-64            [5, 512, 28, 28]          [5, 512, 28, 28]          1,024
â”‚    â”‚    â””â”€ReLU: 3-65                   [5, 512, 28, 28]          [5, 512, 28, 28]          --
â”œâ”€Sequential: 1-7                        [5, 512, 28, 28]          [5, 1024, 14, 14]         --
â”‚    â””â”€Bottleneck: 2-8                   [5, 512, 28, 28]          [5, 1024, 14, 14]         --
â”‚    â”‚    â””â”€Conv2d: 3-66                 [5, 512, 28, 28]          [5, 256, 28, 28]          131,072
â”‚    â”‚    â””â”€BatchNorm2d: 3-67            [5, 256, 28, 28]          [5, 256, 28, 28]          512
â”‚    â”‚    â””â”€ReLU: 3-68                   [5, 256, 28, 28]          [5, 256, 28, 28]          --
â”‚    â”‚    â””â”€Conv2d: 3-69                 [5, 256, 28, 28]          [5, 256, 14, 14]          589,824
â”‚    â”‚    â””â”€BatchNorm2d: 3-70            [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-71                   [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-72                 [5, 256, 14, 14]          [5, 1024, 14, 14]         262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-73            [5, 1024, 14, 14]         [5, 1024, 14, 14]         2,048
â”‚    â”‚    â””â”€Sequential: 3-74             [5, 512, 28, 28]          [5, 1024, 14, 14]         526,336
â”‚    â”‚    â””â”€ReLU: 3-75                   [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”‚    â””â”€Bottleneck: 2-9                   [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”‚    â”‚    â””â”€Conv2d: 3-76                 [5, 1024, 14, 14]         [5, 256, 14, 14]          262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-77            [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-78                   [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-79                 [5, 256, 14, 14]          [5, 256, 14, 14]          589,824
â”‚    â”‚    â””â”€BatchNorm2d: 3-80            [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-81                   [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-82                 [5, 256, 14, 14]          [5, 1024, 14, 14]         262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-83            [5, 1024, 14, 14]         [5, 1024, 14, 14]         2,048
â”‚    â”‚    â””â”€ReLU: 3-84                   [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”‚    â””â”€Bottleneck: 2-10                  [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”‚    â”‚    â””â”€Conv2d: 3-85                 [5, 1024, 14, 14]         [5, 256, 14, 14]          262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-86            [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-87                   [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-88                 [5, 256, 14, 14]          [5, 256, 14, 14]          589,824
â”‚    â”‚    â””â”€BatchNorm2d: 3-89            [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-90                   [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-91                 [5, 256, 14, 14]          [5, 1024, 14, 14]         262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-92            [5, 1024, 14, 14]         [5, 1024, 14, 14]         2,048
â”‚    â”‚    â””â”€ReLU: 3-93                   [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”‚    â””â”€Bottleneck: 2-11                  [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”‚    â”‚    â””â”€Conv2d: 3-94                 [5, 1024, 14, 14]         [5, 256, 14, 14]          262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-95            [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-96                   [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-97                 [5, 256, 14, 14]          [5, 256, 14, 14]          589,824
â”‚    â”‚    â””â”€BatchNorm2d: 3-98            [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-99                   [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-100                [5, 256, 14, 14]          [5, 1024, 14, 14]         262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-101           [5, 1024, 14, 14]         [5, 1024, 14, 14]         2,048
â”‚    â”‚    â””â”€ReLU: 3-102                  [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”‚    â””â”€Bottleneck: 2-12                  [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”‚    â”‚    â””â”€Conv2d: 3-103                [5, 1024, 14, 14]         [5, 256, 14, 14]          262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-104           [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-105                  [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-106                [5, 256, 14, 14]          [5, 256, 14, 14]          589,824
â”‚    â”‚    â””â”€BatchNorm2d: 3-107           [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-108                  [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-109                [5, 256, 14, 14]          [5, 1024, 14, 14]         262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-110           [5, 1024, 14, 14]         [5, 1024, 14, 14]         2,048
â”‚    â”‚    â””â”€ReLU: 3-111                  [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”‚    â””â”€Bottleneck: 2-13                  [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”‚    â”‚    â””â”€Conv2d: 3-112                [5, 1024, 14, 14]         [5, 256, 14, 14]          262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-113           [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-114                  [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-115                [5, 256, 14, 14]          [5, 256, 14, 14]          589,824
â”‚    â”‚    â””â”€BatchNorm2d: 3-116           [5, 256, 14, 14]          [5, 256, 14, 14]          512
â”‚    â”‚    â””â”€ReLU: 3-117                  [5, 256, 14, 14]          [5, 256, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-118                [5, 256, 14, 14]          [5, 1024, 14, 14]         262,144
â”‚    â”‚    â””â”€BatchNorm2d: 3-119           [5, 1024, 14, 14]         [5, 1024, 14, 14]         2,048
â”‚    â”‚    â””â”€ReLU: 3-120                  [5, 1024, 14, 14]         [5, 1024, 14, 14]         --
â”œâ”€Sequential: 1-8                        [5, 1024, 14, 14]         [5, 2048, 7, 7]           --
â”‚    â””â”€Bottleneck: 2-14                  [5, 1024, 14, 14]         [5, 2048, 7, 7]           --
â”‚    â”‚    â””â”€Conv2d: 3-121                [5, 1024, 14, 14]         [5, 512, 14, 14]          524,288
â”‚    â”‚    â””â”€BatchNorm2d: 3-122           [5, 512, 14, 14]          [5, 512, 14, 14]          1,024
â”‚    â”‚    â””â”€ReLU: 3-123                  [5, 512, 14, 14]          [5, 512, 14, 14]          --
â”‚    â”‚    â””â”€Conv2d: 3-124                [5, 512, 14, 14]          [5, 512, 7, 7]            2,359,296
â”‚    â”‚    â””â”€BatchNorm2d: 3-125           [5, 512, 7, 7]            [5, 512, 7, 7]            1,024
â”‚    â”‚    â””â”€ReLU: 3-126                  [5, 512, 7, 7]            [5, 512, 7, 7]            --
â”‚    â”‚    â””â”€Conv2d: 3-127                [5, 512, 7, 7]            [5, 2048, 7, 7]           1,048,576
â”‚    â”‚    â””â”€BatchNorm2d: 3-128           [5, 2048, 7, 7]           [5, 2048, 7, 7]           4,096
â”‚    â”‚    â””â”€Sequential: 3-129            [5, 1024, 14, 14]         [5, 2048, 7, 7]           2,101,248
â”‚    â”‚    â””â”€ReLU: 3-130                  [5, 2048, 7, 7]           [5, 2048, 7, 7]           --
â”‚    â””â”€Bottleneck: 2-15                  [5, 2048, 7, 7]           [5, 2048, 7, 7]           --
â”‚    â”‚    â””â”€Conv2d: 3-131                [5, 2048, 7, 7]           [5, 512, 7, 7]            1,048,576
â”‚    â”‚    â””â”€BatchNorm2d: 3-132           [5, 512, 7, 7]            [5, 512, 7, 7]            1,024
â”‚    â”‚    â””â”€ReLU: 3-133                  [5, 512, 7, 7]            [5, 512, 7, 7]            --
â”‚    â”‚    â””â”€Conv2d: 3-134                [5, 512, 7, 7]            [5, 512, 7, 7]            2,359,296
â”‚    â”‚    â””â”€BatchNorm2d: 3-135           [5, 512, 7, 7]            [5, 512, 7, 7]            1,024
â”‚    â”‚    â””â”€ReLU: 3-136                  [5, 512, 7, 7]            [5, 512, 7, 7]            --
â”‚    â”‚    â””â”€Conv2d: 3-137                [5, 512, 7, 7]            [5, 2048, 7, 7]           1,048,576
â”‚    â”‚    â””â”€BatchNorm2d: 3-138           [5, 2048, 7, 7]           [5, 2048, 7, 7]           4,096
â”‚    â”‚    â””â”€ReLU: 3-139                  [5, 2048, 7, 7]           [5, 2048, 7, 7]           --
â”‚    â””â”€Bottleneck: 2-16                  [5, 2048, 7, 7]           [5, 2048, 7, 7]           --
â”‚    â”‚    â””â”€Conv2d: 3-140                [5, 2048, 7, 7]           [5, 512, 7, 7]            1,048,576
â”‚    â”‚    â””â”€BatchNorm2d: 3-141           [5, 512, 7, 7]            [5, 512, 7, 7]            1,024
â”‚    â”‚    â””â”€ReLU: 3-142                  [5, 512, 7, 7]            [5, 512, 7, 7]            --
â”‚    â”‚    â””â”€Conv2d: 3-143                [5, 512, 7, 7]            [5, 512, 7, 7]            2,359,296
â”‚    â”‚    â””â”€BatchNorm2d: 3-144           [5, 512, 7, 7]            [5, 512, 7, 7]            1,024
â”‚    â”‚    â””â”€ReLU: 3-145                  [5, 512, 7, 7]            [5, 512, 7, 7]            --
â”‚    â”‚    â””â”€Conv2d: 3-146                [5, 512, 7, 7]            [5, 2048, 7, 7]           1,048,576
â”‚    â”‚    â””â”€BatchNorm2d: 3-147           [5, 2048, 7, 7]           [5, 2048, 7, 7]           4,096
â”‚    â”‚    â””â”€ReLU: 3-148                  [5, 2048, 7, 7]           [5, 2048, 7, 7]           --
â”œâ”€AdaptiveAvgPool2d: 1-9                 [5, 2048, 7, 7]           [5, 2048, 1, 1]           --
â”œâ”€Linear: 1-10                           [5, 2048]                 [5, 1000]                 2,049,000
===================================================================================================================
Total params: 25,557,032
Trainable params: 25,557,032
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 20.45
===================================================================================================================
Input size (MB): 3.01
Forward/backward pass size (MB): 889.16
Params size (MB): 102.23
Estimated Total Size (MB): 994.40
===================================================================================================================</code></pre>
</div>
</div>
<p>We set the mode to <code>eval()</code> to ensure that the model is ready to predict on new data.</p>
<div id="6f2dd7c2" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>resnet_model.<span class="bu">eval</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=1000, bias=True)
)</code></pre>
</div>
</div>
<p>Inspecting the output above, we see that when setting up the <code>resnet_model</code>, the authors defined a <code>Bottleneck</code>, much like our <code>BuildingBlock</code> module.</p>
<p>We now feed our six images through the fitted network.</p>
<div id="f0bddc85" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>img_preds <span class="op">=</span> resnet_model(imgs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Letâ€™s look at the predicted probabilities for each of the top 3 choices. First we compute the probabilities by applying the softmax to the logits in <code>img_preds</code>. Note that we have had to call the <code>detach()</code> method on the tensor <code>img_preds</code> in order to convert it to our a more familiar <code>ndarray</code>.</p>
<div id="7d37b9d8" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>img_probs <span class="op">=</span> np.exp(np.asarray(img_preds.detach()))</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>img_probs <span class="op">/=</span> img_probs.<span class="bu">sum</span>(<span class="dv">1</span>)[:,<span class="va">None</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In order to see the class labels, we must download the index file associated with <code>imagenet</code>. {This is avalable from the book website and <a href="https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json">s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json</a>.}</p>
<div id="2313134a" class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>labs <span class="op">=</span> json.load(<span class="bu">open</span>(<span class="st">'data/json_data/imagenet_class_index.json'</span>))</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> pd.DataFrame([(<span class="bu">int</span>(k), v[<span class="dv">1</span>]) <span class="cf">for</span> k, v <span class="kw">in</span></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>                           labs.items()],</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>                           columns<span class="op">=</span>[<span class="st">'idx'</span>, <span class="st">'label'</span>])</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> class_labels.set_index(<span class="st">'idx'</span>)</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> class_labels.sort_index()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Weâ€™ll now construct a data frame for each image file with the labels with the three highest probabilities as estimated by the model above.</p>
<div id="dd6ddace" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, imgfile <span class="kw">in</span> <span class="bu">enumerate</span>(imgfiles):</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>    img_df <span class="op">=</span> class_labels.copy()</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>    img_df[<span class="st">'prob'</span>] <span class="op">=</span> img_probs[i]</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>    img_df <span class="op">=</span> img_df.sort_values(by<span class="op">=</span><span class="st">'prob'</span>, ascending<span class="op">=</span><span class="va">False</span>)[:<span class="dv">3</span>]</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Image: </span><span class="sc">{</span>imgfile<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(img_df.reset_index().drop(columns<span class="op">=</span>[<span class="st">'idx'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Image: data/book_images/Cape_Weaver.jpeg
      label      prob
0   jacamar  0.297500
1     macaw  0.068107
2  lorikeet  0.051104
Image: data/book_images/Hawk_Fountain.jpeg
            label      prob
0            kite  0.184681
1           robin  0.084021
2  great_grey_owl  0.061274
Image: data/book_images/Hawk_cropped.jpeg
            label      prob
0            kite  0.453834
1  great_grey_owl  0.015914
2             jay  0.012210
Image: data/book_images/Lhasa_Apso.jpeg
             label      prob
0            Lhasa  0.260317
1         Shih-Tzu  0.097196
2  Tibetan_terrier  0.032819
Image: data/book_images/Sleeping_Cat.jpeg
         label      prob
0  Persian_cat  0.163070
1        tabby  0.074143
2    tiger_cat  0.042578</code></pre>
</div>
</div>
<p>We see that the model is quite confident about <code>Flamingo.jpg</code>, but a little less so for the other images.</p>
<p>We end this section with our usual cleanup.</p>
<div id="5558666d" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span>(cifar_test,</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>    cifar_train,</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>    cifar_dm,</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>    cifar_module,</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>    cifar_logger,</span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>    cifar_optimizer,</span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a>    cifar_trainer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!--IMDB Document Classification {{{2-->
</section>
<section id="imdb-document-classification" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="imdb-document-classification"><span class="header-section-number">10.6</span> IMDB Document Classification</h2>
<p>We now implement models for sentiment classification (Section 10.4) on the <code>IMDB</code> dataset. As mentioned above code block~8, we are using a preprocessed version of the <code>IMDB</code> dataset found in the <code>keras</code> package. As <code>keras</code> uses <code>tensorflow</code>, a different tensor and deep learning library, we have converted the data to be suitable for <code>torch</code>. The code used to convert from <code>keras</code> is available in the module <code>ISLP.torch._make_imdb</code>. It requires some of the <code>keras</code> packages to run. These data use a dictionary of size 10,000.</p>
<p>We have stored three different representations of the review data for this lab:</p>
<ul>
<li><code>load_tensor()</code>, a sparse tensor version usable by <code>torch</code>;</li>
<li><code>load_sparse()</code>, a sparse matrix version usable by <code>sklearn</code>, since we will compare with a lasso fit;</li>
<li><code>load_sequential()</code>, a padded version of the original sequence representation, limited to the last 500 words of each review.</li>
</ul>
<div id="1ec5bbf6" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>(imdb_seq_train,</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a> imdb_seq_test) <span class="op">=</span> load_sequential(root<span class="op">=</span><span class="st">'data/IMDB'</span>)</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>padded_sample <span class="op">=</span> np.asarray(imdb_seq_train.tensors[<span class="dv">0</span>][<span class="dv">0</span>])</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>sample_review <span class="op">=</span> padded_sample[padded_sample <span class="op">&gt;</span> <span class="dv">0</span>][:<span class="dv">12</span>]</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>sample_review[:<span class="dv">12</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/jjung/anaconda3/envs/islp/lib/python3.11/site-packages/ISLP/torch/imdb.py:131: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  S_test) = [torch.load(_get_imdb(f'IMDB_{r}', root))</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>array([   1,   14,   22,   16,   43,  530,  973, 1622, 1385,   65,  458,
       4468], dtype=int32)</code></pre>
</div>
</div>
<p>The datasets <code>imdb_seq_train</code> and <code>imdb_seq_test</code> are both instances of the class <code>TensorDataset</code>. The tensors used to construct them can be found in the <code>tensors</code> attribute, with the first tensor the features <code>X</code> and the second the outcome <code>Y</code>. We have taken the first row of features and stored it as <code>padded_sample</code>. In the preprocessing used to form these data, sequences were padded with 0s in the beginning if they were not long enough, hence we remove this padding by restricting to entries where <code>padded_sample &gt; 0</code>. We then provide the first 12 words of the sample review.</p>
<p>We can find these words in the <code>lookup</code> dictionary from the <code>ISLP.torch.imdb</code> module.</p>
<div id="f598431e" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>lookup <span class="op">=</span> load_lookup(root<span class="op">=</span><span class="st">'data/IMDB'</span>)</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a><span class="co">' '</span>.join(lookup[i] <span class="cf">for</span> i <span class="kw">in</span> sample_review)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>"&lt;START&gt; this film was just brilliant casting location scenery story direction everyone's"</code></pre>
</div>
</div>
<p>For our first model, we have created a binary feature for each of the 10,000 possible words in the dataset, with an entry of one in the <span class="math inline">\(i,j\)</span> entry if word <span class="math inline">\(j\)</span> appears in review <span class="math inline">\(i\)</span>. As most reviews are quite short, such a feature matrix has over 98% zeros. These data are accessed using <code>load_tensor()</code> from the <code>ISLP</code> library.</p>
<div id="19313788" class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>max_num_workers<span class="op">=</span><span class="dv">10</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>(imdb_train,</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a> imdb_test) <span class="op">=</span> load_tensor(root<span class="op">=</span><span class="st">'data/IMDB'</span>)</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>imdb_dm <span class="op">=</span> SimpleDataModule(imdb_train,</span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>                           imdb_test,</span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>                           validation<span class="op">=</span><span class="dv">2000</span>,</span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>                           num_workers<span class="op">=</span><span class="bu">min</span>(<span class="dv">6</span>, max_num_workers),</span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>                           batch_size<span class="op">=</span><span class="dv">512</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/jjung/anaconda3/envs/islp/lib/python3.11/site-packages/ISLP/torch/imdb.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  X_test, X_train = [torch.load(_get_imdb(f'IMDB_{r}', root))</code></pre>
</div>
</div>
<p>Weâ€™ll use a two-layer model for our first model.</p>
<div id="40986906" class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> IMDBModel(nn.Module):</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size):</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(IMDBModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense1 <span class="op">=</span> nn.Linear(input_size, <span class="dv">16</span>)</span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activation <span class="op">=</span> nn.ReLU()</span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense2 <span class="op">=</span> nn.Linear(<span class="dv">16</span>, <span class="dv">16</span>)</span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output <span class="op">=</span> nn.Linear(<span class="dv">16</span>, <span class="dv">1</span>)</span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-10"><a href="#cb111-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb111-11"><a href="#cb111-11" aria-hidden="true" tabindex="-1"></a>        val <span class="op">=</span> x</span>
<span id="cb111-12"><a href="#cb111-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _map <span class="kw">in</span> [<span class="va">self</span>.dense1,</span>
<span id="cb111-13"><a href="#cb111-13" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.activation,</span>
<span id="cb111-14"><a href="#cb111-14" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.dense2,</span>
<span id="cb111-15"><a href="#cb111-15" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.activation,</span>
<span id="cb111-16"><a href="#cb111-16" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.output]:</span>
<span id="cb111-17"><a href="#cb111-17" aria-hidden="true" tabindex="-1"></a>            val <span class="op">=</span> _map(val)</span>
<span id="cb111-18"><a href="#cb111-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.flatten(val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now instantiate our model and look at a summary.</p>
<div id="fedf707e" class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>imdb_model <span class="op">=</span> IMDBModel(imdb_test.tensors[<span class="dv">0</span>].size()[<span class="dv">1</span>])</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>summary(imdb_model,</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>        input_size<span class="op">=</span>imdb_test.tensors[<span class="dv">0</span>].size(),</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>        col_names<span class="op">=</span>[<span class="st">'input_size'</span>,</span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'output_size'</span>,</span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'num_params'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>===================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #
===================================================================================================================
IMDBModel                                [25000, 10003]            [25000]                   --
â”œâ”€Linear: 1-1                            [25000, 10003]            [25000, 16]               160,064
â”œâ”€ReLU: 1-2                              [25000, 16]               [25000, 16]               --
â”œâ”€Linear: 1-3                            [25000, 16]               [25000, 16]               272
â”œâ”€ReLU: 1-4                              [25000, 16]               [25000, 16]               --
â”œâ”€Linear: 1-5                            [25000, 16]               [25000, 1]                17
===================================================================================================================
Total params: 160,353
Trainable params: 160,353
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 4.01
===================================================================================================================
Input size (MB): 1000.30
Forward/backward pass size (MB): 6.60
Params size (MB): 0.64
Estimated Total Size (MB): 1007.54
===================================================================================================================</code></pre>
</div>
</div>
<p>Weâ€™ll again use a smaller learning rate for these data, hence we pass an <code>optimizer</code> to the <code>SimpleModule</code>. Since the reviews are classified into positive or negative sentiment, we use <code>SimpleModule.binary_classification()</code>. {Our use of <code>binary_classification()</code> instead of <code>classification()</code> is due to some subtlety in how <code>torchmetrics.Accuracy()</code> works, as well as the data type of the targets.}</p>
<div id="876e220b" class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>imdb_optimizer <span class="op">=</span> RMSprop(imdb_model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>imdb_module <span class="op">=</span> SimpleModule.binary_classification(</span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>                         imdb_model,</span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a>                         optimizer<span class="op">=</span>imdb_optimizer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Having loaded the datasets into a data module and created a <code>SimpleModule</code>, the remaining steps are familiar.</p>
<div id="7402f1b6" class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>imdb_logger <span class="op">=</span> CSVLogger(<span class="st">'logs'</span>, name<span class="op">=</span><span class="st">'IMDB'</span>)</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>imdb_trainer <span class="op">=</span> Trainer(deterministic<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>                       max_epochs<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a>                       logger<span class="op">=</span>imdb_logger,</span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a>                       enable_progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a>                       callbacks<span class="op">=</span>[ErrorTracker()])</span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a>imdb_trainer.fit(imdb_module,</span>
<span id="cb115-8"><a href="#cb115-8" aria-hidden="true" tabindex="-1"></a>                 datamodule<span class="op">=</span>imdb_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type              | Params | Mode 
----------------------------------------------------
0 | model | IMDBModel         | 160 K  | train
1 | loss  | BCEWithLogitsLoss | 0      | train
----------------------------------------------------
160 K     Trainable params
0         Non-trainable params
160 K     Total params
0.641     Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
/home/jjung/anaconda3/envs/islp/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (45) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=30` reached.</code></pre>
</div>
</div>
<p>Evaluating the test error yields roughly 86% accuracy.</p>
<div id="f7f6f49d" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> imdb_trainer.test(imdb_module, datamodule<span class="op">=</span>imdb_dm)</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>test_results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       Test metric             DataLoader 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      test_accuracy         0.8530399799346924
        test_loss            1.034852147102356
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>[{'test_loss': 1.034852147102356, 'test_accuracy': 0.8530399799346924}]</code></pre>
</div>
</div>
<!-- Comparison to Lasso {{{3-->
<section id="comparison-to-lasso" class="level3" data-number="10.6.1">
<h3 data-number="10.6.1" class="anchored" data-anchor-id="comparison-to-lasso"><span class="header-section-number">10.6.1</span> Comparison to Lasso</h3>
<p>We now fit a lasso logistic regression model using <code>LogisticRegression()</code> from <code>sklearn</code>. Since <code>sklearn</code> does not recognize the sparse tensors of <code>torch</code>, we use a sparse matrix that is recognized by <code>sklearn.</code></p>
<div id="cc3a847a" class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>((X_train, Y_train),</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a> (X_valid, Y_valid),</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a> (X_test, Y_test)) <span class="op">=</span> load_sparse(validation<span class="op">=</span><span class="dv">2000</span>,</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>                                 random_state<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>                                 root<span class="op">=</span><span class="st">'data/IMDB'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Similar to what we did in Section 10.9.1, we construct a series of 50 values for the lasso reguralization parameter <span class="math inline">\(\lambda\)</span>.</p>
<div id="a75f8cbe" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>lam_max <span class="op">=</span> np.<span class="bu">abs</span>(X_train.T <span class="op">*</span> (Y_train <span class="op">-</span> Y_train.mean())).<span class="bu">max</span>()</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>lam_val <span class="op">=</span> lam_max <span class="op">*</span> np.exp(np.linspace(np.log(<span class="dv">1</span>),</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>                                       np.log(<span class="fl">1e-4</span>), <span class="dv">50</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With <code>LogisticRegression()</code> the regularization parameter <span class="math inline">\(C\)</span> is specified as the inverse of <span class="math inline">\(\lambda\)</span>. There are several solvers for logistic regression; here we use <code>liblinear</code> which works well with the sparse input format.</p>
<div id="900c2ddc" class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>logit <span class="op">=</span> LogisticRegression(penalty<span class="op">=</span><span class="st">'l1'</span>,</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>                           C<span class="op">=</span><span class="dv">1</span><span class="op">/</span>lam_max,</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a>                           solver<span class="op">=</span><span class="st">'liblinear'</span>,</span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a>                           warm_start<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a>                           fit_intercept<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The path of 50 values takes approximately 40 seconds to run.</p>
<div id="07591a23" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>coefs <span class="op">=</span> []</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>intercepts <span class="op">=</span> []</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> l <span class="kw">in</span> lam_val:</span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a>    logit.C <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>l</span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a>    logit.fit(X_train, Y_train)</span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a>    coefs.append(logit.coef_.copy())</span>
<span id="cb124-8"><a href="#cb124-8" aria-hidden="true" tabindex="-1"></a>    intercepts.append(logit.intercept_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The coefficient and intercepts have an extraneous dimension which can be removed by the <code>np.squeeze()</code> function.</p>
<div id="1c394bca" class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>coefs <span class="op">=</span> np.squeeze(coefs)</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>intercepts <span class="op">=</span> np.squeeze(intercepts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Weâ€™ll now make a plot to compare our neural network results with the lasso.</p>
<div id="f9d69f3d" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>capture</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">8</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ((X_, Y_),</span>
<span id="cb126-4"><a href="#cb126-4" aria-hidden="true" tabindex="-1"></a>     data_,</span>
<span id="cb126-5"><a href="#cb126-5" aria-hidden="true" tabindex="-1"></a>     color) <span class="kw">in</span> <span class="bu">zip</span>([(X_train, Y_train),</span>
<span id="cb126-6"><a href="#cb126-6" aria-hidden="true" tabindex="-1"></a>                    (X_valid, Y_valid),</span>
<span id="cb126-7"><a href="#cb126-7" aria-hidden="true" tabindex="-1"></a>                    (X_test, Y_test)],</span>
<span id="cb126-8"><a href="#cb126-8" aria-hidden="true" tabindex="-1"></a>                    [<span class="st">'Training'</span>, <span class="st">'Validation'</span>, <span class="st">'Test'</span>],</span>
<span id="cb126-9"><a href="#cb126-9" aria-hidden="true" tabindex="-1"></a>                    [<span class="st">'black'</span>, <span class="st">'red'</span>, <span class="st">'blue'</span>]):</span>
<span id="cb126-10"><a href="#cb126-10" aria-hidden="true" tabindex="-1"></a>    linpred_ <span class="op">=</span> X_ <span class="op">*</span> coefs.T <span class="op">+</span> intercepts[<span class="va">None</span>,:]</span>
<span id="cb126-11"><a href="#cb126-11" aria-hidden="true" tabindex="-1"></a>    label_ <span class="op">=</span> np.array(linpred_ <span class="op">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb126-12"><a href="#cb126-12" aria-hidden="true" tabindex="-1"></a>    accuracy_ <span class="op">=</span> np.array([np.mean(Y_ <span class="op">==</span> l) <span class="cf">for</span> l <span class="kw">in</span> label_.T])</span>
<span id="cb126-13"><a href="#cb126-13" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].plot(<span class="op">-</span>np.log(lam_val <span class="op">/</span> X_train.shape[<span class="dv">0</span>]),</span>
<span id="cb126-14"><a href="#cb126-14" aria-hidden="true" tabindex="-1"></a>                 accuracy_,</span>
<span id="cb126-15"><a href="#cb126-15" aria-hidden="true" tabindex="-1"></a>                 <span class="st">'.--'</span>,</span>
<span id="cb126-16"><a href="#cb126-16" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span>color,</span>
<span id="cb126-17"><a href="#cb126-17" aria-hidden="true" tabindex="-1"></a>                 markersize<span class="op">=</span><span class="dv">13</span>,</span>
<span id="cb126-18"><a href="#cb126-18" aria-hidden="true" tabindex="-1"></a>                 linewidth<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb126-19"><a href="#cb126-19" aria-hidden="true" tabindex="-1"></a>                 label<span class="op">=</span>data_)</span>
<span id="cb126-20"><a href="#cb126-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb126-21"><a href="#cb126-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="vs">r'$-\log(\lambda)$'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb126-22"><a href="#cb126-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Accuracy'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Notice the use of <code>%%capture</code>, which suppresses the displaying of the partially completed figure. This is useful when making a complex figure, since the steps can be spread across two or more cells. We now add a plot of the lasso accuracy, and display the composed figure by simply entering its name at the end of the cell.</p>
<div id="26eea350" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>imdb_results <span class="op">=</span> pd.read_csv(imdb_logger.experiment.metrics_file_path)</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>summary_plot(imdb_results,</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>             axes[<span class="dv">1</span>],</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>             col<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>             ylabel<span class="op">=</span><span class="st">'Accuracy'</span>)</span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xticks(np.linspace(<span class="dv">0</span>, <span class="dv">30</span>, <span class="dv">7</span>).astype(<span class="bu">int</span>))</span>
<span id="cb127-7"><a href="#cb127-7" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Accuracy'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb127-8"><a href="#cb127-8" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Epoch'</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb127-9"><a href="#cb127-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylim([<span class="fl">0.5</span>, <span class="dv">1</span>])<span class="op">;</span></span>
<span id="cb127-10"><a href="#cb127-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axhline(test_results[<span class="dv">0</span>][<span class="st">'test_accuracy'</span>],</span>
<span id="cb127-11"><a href="#cb127-11" aria-hidden="true" tabindex="-1"></a>                color<span class="op">=</span><span class="st">'blue'</span>,</span>
<span id="cb127-12"><a href="#cb127-12" aria-hidden="true" tabindex="-1"></a>                linestyle<span class="op">=</span><span class="st">'--'</span>,</span>
<span id="cb127-13"><a href="#cb127-13" aria-hidden="true" tabindex="-1"></a>                linewidth<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb127-14"><a href="#cb127-14" aria-hidden="true" tabindex="-1"></a>fig</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<div>
<figure class="figure">
<p><a href="ch10-deeplearning-lab_files/figure-html/cell-86-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="ch10-deeplearning-lab_files/figure-html/cell-86-output-1.png" width="1272" height="671" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>From the graphs we see that the accuracy of the lasso logistic regression peaks at about <span class="math inline">\(0.88\)</span>, as it does for the neural network.</p>
<p>Once again, we end with a cleanup.</p>
<div id="81c2dbf2" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span>(imdb_model,</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>    imdb_trainer,</span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a>    imdb_logger,</span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a>    imdb_dm,</span>
<span id="cb128-5"><a href="#cb128-5" aria-hidden="true" tabindex="-1"></a>    imdb_train,</span>
<span id="cb128-6"><a href="#cb128-6" aria-hidden="true" tabindex="-1"></a>    imdb_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!--Recurrent Neural Networks {{{2-->
</section>
</section>
<section id="recurrent-neural-networks" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="recurrent-neural-networks"><span class="header-section-number">10.7</span> Recurrent Neural Networks</h2>
<p>In this lab we fit the models illustrated in Section 10.5.</p>
<!-- Sequential Models for Document Classification {{{3-->
<section id="sequential-models-for-document-classification" class="level3" data-number="10.7.1">
<h3 data-number="10.7.1" class="anchored" data-anchor-id="sequential-models-for-document-classification"><span class="header-section-number">10.7.1</span> Sequential Models for Document Classification</h3>
<p>Here we fit a simple LSTM RNN for sentiment prediction to the <code>IMDb</code> movie-review data, as discussed in Section 10.5.1. For an RNN we use the sequence of words in a document, taking their order into account. We loaded the preprocessed data at the beginning of Section 10.9.5. A script that details the preprocessing can be found in the <code>ISLP</code> library. Notably, since more than 90% of the documents had fewer than 500 words, we set the document length to 500. For longer documents, we used the last 500 words, and for shorter documents, we padded the front with blanks.</p>
<div id="8bf72e42" class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>imdb_seq_dm <span class="op">=</span> SimpleDataModule(imdb_seq_train,</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>                               imdb_seq_test,</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>                               validation<span class="op">=</span><span class="dv">2000</span>,</span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a>                               batch_size<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>                               num_workers<span class="op">=</span><span class="bu">min</span>(<span class="dv">6</span>, max_num_workers)</span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a>                               )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The first layer of the RNN is an embedding layer of size 32, which will be learned during training. This layer one-hot encodes each document as a matrix of dimension <span class="math inline">\(500 \times 10,003\)</span>, and then maps these <span class="math inline">\(10,003\)</span> dimensions down to <span class="math inline">\(32\)</span>. {The extra 3 dimensions correspond to commonly occurring non-word entries in the reviews.} Since each word is represented by an integer, this is effectively achieved by the creation of an embedding matrix of size <span class="math inline">\(10,003\times 32\)</span>; each of the 500 integers in the document are then mapped to the appropriate 32 real numbers by indexing the appropriate rows of this matrix.</p>
<p>The second layer is an LSTM with 32 units, and the output layer is a single logit for the binary classification task. In the last line of the <code>forward()</code> method below, we take the last 32-dimensional output of the LSTM and map it to our response.</p>
<div id="6a0a6d03" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LSTMModel(nn.Module):</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size):</span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(LSTMModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding <span class="op">=</span> nn.Embedding(input_size, <span class="dv">32</span>)</span>
<span id="cb130-5"><a href="#cb130-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(input_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb130-6"><a href="#cb130-6" aria-hidden="true" tabindex="-1"></a>                            hidden_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb130-7"><a href="#cb130-7" aria-hidden="true" tabindex="-1"></a>                            batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb130-8"><a href="#cb130-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense <span class="op">=</span> nn.Linear(<span class="dv">32</span>, <span class="dv">1</span>)</span>
<span id="cb130-9"><a href="#cb130-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb130-10"><a href="#cb130-10" aria-hidden="true" tabindex="-1"></a>        val, (h_n, c_n) <span class="op">=</span> <span class="va">self</span>.lstm(<span class="va">self</span>.embedding(x))</span>
<span id="cb130-11"><a href="#cb130-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.flatten(<span class="va">self</span>.dense(val[:,<span class="op">-</span><span class="dv">1</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We instantiate and take a look at the summary of the model, using the first 10 documents in the corpus.</p>
<div id="2e703c52" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>lstm_model <span class="op">=</span> LSTMModel(X_test.shape[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>summary(lstm_model,</span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a>        input_data<span class="op">=</span>imdb_seq_train.tensors[<span class="dv">0</span>][:<span class="dv">10</span>],</span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true" tabindex="-1"></a>        col_names<span class="op">=</span>[<span class="st">'input_size'</span>,</span>
<span id="cb131-5"><a href="#cb131-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'output_size'</span>,</span>
<span id="cb131-6"><a href="#cb131-6" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'num_params'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>===================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #
===================================================================================================================
LSTMModel                                [10, 500]                 [10]                      --
â”œâ”€Embedding: 1-1                         [10, 500]                 [10, 500, 32]             320,096
â”œâ”€LSTM: 1-2                              [10, 500, 32]             [10, 500, 32]             8,448
â”œâ”€Linear: 1-3                            [10, 32]                  [10, 1]                   33
===================================================================================================================
Total params: 328,577
Trainable params: 328,577
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 45.44
===================================================================================================================
Input size (MB): 50.00
Forward/backward pass size (MB): 2.56
Params size (MB): 1.31
Estimated Total Size (MB): 53.87
===================================================================================================================</code></pre>
</div>
</div>
<p>The 10,003 is suppressed in the summary, but we see it in the parameter count, since <span class="math inline">\(10,003\times 32=320,096\)</span>.</p>
<div id="7146f118" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>lstm_module <span class="op">=</span> SimpleModule.binary_classification(lstm_model)</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>lstm_logger <span class="op">=</span> CSVLogger(<span class="st">'logs'</span>, name<span class="op">=</span><span class="st">'IMDB_LSTM'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a318a20b" class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>lstm_trainer <span class="op">=</span> Trainer(deterministic<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>                       max_epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>                       logger<span class="op">=</span>lstm_logger,</span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>                       enable_progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>                       callbacks<span class="op">=</span>[ErrorTracker()])</span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a>lstm_trainer.fit(lstm_module,</span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a>                 datamodule<span class="op">=</span>imdb_seq_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type              | Params | Mode 
----------------------------------------------------
0 | model | LSTMModel         | 328 K  | train
1 | loss  | BCEWithLogitsLoss | 0      | train
----------------------------------------------------
328 K     Trainable params
0         Non-trainable params
328 K     Total params
1.314     Total estimated model params size (MB)
5         Modules in train mode
0         Modules in eval mode
`Trainer.fit` stopped: `max_epochs=20` reached.</code></pre>
</div>
</div>
<p>The rest is now similar to other networks we have fit. We track the test performance as the network is fit, and see that it attains 85% accuracy.</p>
<div id="7c2e2661" class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>lstm_trainer.test(lstm_module, datamodule<span class="op">=</span>imdb_seq_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       Test metric             DataLoader 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      test_accuracy         0.8389999866485596
        test_loss           0.8175755143165588
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>[{'test_loss': 0.8175755143165588, 'test_accuracy': 0.8389999866485596}]</code></pre>
</div>
</div>
<p>We once again show the learning progress, followed by cleanup.</p>
<div id="aa54ee1d" class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>lstm_results <span class="op">=</span> pd.read_csv(lstm_logger.experiment.metrics_file_path)</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>summary_plot(lstm_results,</span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a>             ax,</span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a>             col<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb140-6"><a href="#cb140-6" aria-hidden="true" tabindex="-1"></a>             ylabel<span class="op">=</span><span class="st">'Accuracy'</span>)</span>
<span id="cb140-7"><a href="#cb140-7" aria-hidden="true" tabindex="-1"></a>ax.set_xticks(np.linspace(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dv">5</span>).astype(<span class="bu">int</span>))</span>
<span id="cb140-8"><a href="#cb140-8" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb140-9"><a href="#cb140-9" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="fl">0.5</span>, <span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="ch10-deeplearning-lab_files/figure-html/cell-94-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="ch10-deeplearning-lab_files/figure-html/cell-94-output-1.png" width="523" height="508" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div id="a30322b2" class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span>(lstm_model,</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>    lstm_trainer,</span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a>    lstm_logger,</span>
<span id="cb141-4"><a href="#cb141-4" aria-hidden="true" tabindex="-1"></a>    imdb_seq_dm,</span>
<span id="cb141-5"><a href="#cb141-5" aria-hidden="true" tabindex="-1"></a>    imdb_seq_train,</span>
<span id="cb141-6"><a href="#cb141-6" aria-hidden="true" tabindex="-1"></a>    imdb_seq_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!-- Time Series Prediction {{{3-->
</section>
<section id="time-series-prediction" class="level3" data-number="10.7.2">
<h3 data-number="10.7.2" class="anchored" data-anchor-id="time-series-prediction"><span class="header-section-number">10.7.2</span> Time Series Prediction</h3>
<p>We now show how to fit the models in Section 10.5.2 for time series prediction. We first load and standardize the data.</p>
<div id="a919f34a" class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>NYSE <span class="op">=</span> load_data(<span class="st">'NYSE'</span>)</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">'DJ_return'</span>, <span class="st">'log_volume'</span>, <span class="st">'log_volatility'</span>]</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> pd.DataFrame(StandardScaler(</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a>                     with_mean<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a>                     with_std<span class="op">=</span><span class="va">True</span>).fit_transform(NYSE[cols]),</span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a>                 columns<span class="op">=</span>NYSE[cols].columns,</span>
<span id="cb142-7"><a href="#cb142-7" aria-hidden="true" tabindex="-1"></a>                 index<span class="op">=</span>NYSE.index)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next we set up the lagged versions of the data, dropping any rows with missing values using the <code>dropna()</code> method.</p>
<div id="155a0552" class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lag <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">6</span>):</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> cols:</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>        newcol <span class="op">=</span> np.zeros(X.shape[<span class="dv">0</span>]) <span class="op">*</span> np.nan</span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a>        newcol[lag:] <span class="op">=</span> X[col].values[:<span class="op">-</span>lag]</span>
<span id="cb143-5"><a href="#cb143-5" aria-hidden="true" tabindex="-1"></a>        X.insert(<span class="bu">len</span>(X.columns), <span class="st">"</span><span class="sc">{0}</span><span class="st">_</span><span class="sc">{1}</span><span class="st">"</span>.<span class="bu">format</span>(col, lag), newcol)</span>
<span id="cb143-6"><a href="#cb143-6" aria-hidden="true" tabindex="-1"></a>X.insert(<span class="bu">len</span>(X.columns), <span class="st">'train'</span>, NYSE[<span class="st">'train'</span>])</span>
<span id="cb143-7"><a href="#cb143-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.dropna()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, we extract the response, training indicator, and drop the current dayâ€™s <code>DJ_return</code> and <code>log_volatility</code> to predict only from previous dayâ€™s data.</p>
<div id="0472b4e3" class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>Y, train <span class="op">=</span> X[<span class="st">'log_volume'</span>], X[<span class="st">'train'</span>]</span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.drop(columns<span class="op">=</span>[<span class="st">'train'</span>] <span class="op">+</span> cols)</span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a>X.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>Index(['DJ_return_1', 'log_volume_1', 'log_volatility_1', 'DJ_return_2',
       'log_volume_2', 'log_volatility_2', 'DJ_return_3', 'log_volume_3',
       'log_volatility_3', 'DJ_return_4', 'log_volume_4', 'log_volatility_4',
       'DJ_return_5', 'log_volume_5', 'log_volatility_5'],
      dtype='object')</code></pre>
</div>
</div>
<p>We first fit a simple linear model and compute the <span class="math inline">\(R^2\)</span> on the test data using the <code>score()</code> method.</p>
<div id="b6b856a1" class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> LinearRegression()</span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a>M.fit(X[train], Y[train])</span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>M.score(X[<span class="op">~</span>train], Y[<span class="op">~</span>train])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>0.4128912938562521</code></pre>
</div>
</div>
<p>We refit this model, including the factor variable <code>day_of_week</code>. For a categorical series in <code>pandas</code>, we can form the indicators using the <code>get_dummies()</code> method.</p>
<div id="507f557b" class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>X_day <span class="op">=</span> pd.merge(X,</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>                 pd.get_dummies(NYSE[<span class="st">'day_of_week'</span>]),</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>                 on<span class="op">=</span><span class="st">'date'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that we do not have to reinstantiate the linear regression model as its <code>fit()</code> method accepts a design matrix and a response directly.</p>
<div id="33f77206" class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>M.fit(X_day[train], Y[train])</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>M.score(X_day[<span class="op">~</span>train], Y[<span class="op">~</span>train])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>0.4595563133053273</code></pre>
</div>
</div>
<p>This model achieves an <span class="math inline">\(R^2\)</span> of about 46%.</p>
<p>To fit the RNN, we must reshape the data, as it will expect 5 lagged versions of each feature as indicated by the <code>input_shape</code> argument to the layer <code>nn.RNN()</code> below. We first ensure the columns of our data frame are such that a reshaped matrix will have the variables correctly lagged. We use the <code>reindex()</code> method to do this.</p>
<p>For an input shape <code>(5,3)</code>, each row represents a lagged version of the three variables. The <code>nn.RNN()</code> layer also expects the first row of each observation to be earliest in time, so we must reverse the current order. Hence we loop over <code>range(5,0,-1)</code> below, which is an example of using a <code>slice()</code> to index iterable objects. The general notation is <code>start:end:step</code>.</p>
<div id="dad8f124" class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>ordered_cols <span class="op">=</span> []</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lag <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> cols:</span>
<span id="cb151-4"><a href="#cb151-4" aria-hidden="true" tabindex="-1"></a>        ordered_cols.append(<span class="st">'</span><span class="sc">{0}</span><span class="st">_</span><span class="sc">{1}</span><span class="st">'</span>.<span class="bu">format</span>(col, lag))</span>
<span id="cb151-5"><a href="#cb151-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.reindex(columns<span class="op">=</span>ordered_cols)</span>
<span id="cb151-6"><a href="#cb151-6" aria-hidden="true" tabindex="-1"></a>X.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="101">
<pre><code>Index(['DJ_return_5', 'log_volume_5', 'log_volatility_5', 'DJ_return_4',
       'log_volume_4', 'log_volatility_4', 'DJ_return_3', 'log_volume_3',
       'log_volatility_3', 'DJ_return_2', 'log_volume_2', 'log_volatility_2',
       'DJ_return_1', 'log_volume_1', 'log_volatility_1'],
      dtype='object')</code></pre>
</div>
</div>
<p>We now reshape the data.</p>
<div id="e2d210a6" class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>X_rnn <span class="op">=</span> X.to_numpy().reshape((<span class="op">-</span><span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">3</span>))</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>X_rnn.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>(6046, 5, 3)</code></pre>
</div>
</div>
<p>By specifying the first size as -1, <code>numpy.reshape()</code> deduces its size based on the remaining arguments.</p>
<p>Now we are ready to proceed with the RNN, which uses 12 hidden units, and 10% dropout. After passing through the RNN, we extract the final time point as <code>val[:,-1]</code> in <code>forward()</code> below. This gets passed through a 10% dropout and then flattened through a linear layer.</p>
<div id="d79ab837" class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NYSEModel(nn.Module):</span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(NYSEModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rnn <span class="op">=</span> nn.RNN(<span class="dv">3</span>,</span>
<span id="cb155-5"><a href="#cb155-5" aria-hidden="true" tabindex="-1"></a>                          <span class="dv">12</span>,</span>
<span id="cb155-6"><a href="#cb155-6" aria-hidden="true" tabindex="-1"></a>                          batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb155-7"><a href="#cb155-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense <span class="op">=</span> nn.Linear(<span class="dv">12</span>, <span class="dv">1</span>)</span>
<span id="cb155-8"><a href="#cb155-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(<span class="fl">0.1</span>)</span>
<span id="cb155-9"><a href="#cb155-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb155-10"><a href="#cb155-10" aria-hidden="true" tabindex="-1"></a>        val, h_n <span class="op">=</span> <span class="va">self</span>.rnn(x)</span>
<span id="cb155-11"><a href="#cb155-11" aria-hidden="true" tabindex="-1"></a>        val <span class="op">=</span> <span class="va">self</span>.dense(<span class="va">self</span>.dropout(val[:,<span class="op">-</span><span class="dv">1</span>]))</span>
<span id="cb155-12"><a href="#cb155-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.flatten(val)</span>
<span id="cb155-13"><a href="#cb155-13" aria-hidden="true" tabindex="-1"></a>nyse_model <span class="op">=</span> NYSEModel()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We fit the model in a similar fashion to previous networks. We supply the <code>fit</code> function with test data as validation data, so that when we monitor its progress and plot the history function we can see the progress on the test data. Of course we should not use this as a basis for early stopping, since then the test performance would be biased.</p>
<p>We form the training dataset similar to our <code>Hitters</code> example.</p>
<div id="cd3af7a0" class="cell" data-execution_count="104">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>datasets <span class="op">=</span> []</span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> mask <span class="kw">in</span> [train, <span class="op">~</span>train]:</span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>    X_rnn_t <span class="op">=</span> torch.tensor(X_rnn[mask].astype(np.float32))</span>
<span id="cb156-4"><a href="#cb156-4" aria-hidden="true" tabindex="-1"></a>    Y_t <span class="op">=</span> torch.tensor(Y[mask].astype(np.float32))</span>
<span id="cb156-5"><a href="#cb156-5" aria-hidden="true" tabindex="-1"></a>    datasets.append(TensorDataset(X_rnn_t, Y_t))</span>
<span id="cb156-6"><a href="#cb156-6" aria-hidden="true" tabindex="-1"></a>nyse_train, nyse_test <span class="op">=</span> datasets</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_18915/2100042546.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  Y_t = torch.tensor(Y[mask].astype(np.float32))
/tmp/ipykernel_18915/2100042546.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  Y_t = torch.tensor(Y[mask].astype(np.float32))</code></pre>
</div>
</div>
<p>Following our usual pattern, we inspect the summary.</p>
<div id="ecb71388" class="cell" data-execution_count="105">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>summary(nyse_model,</span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a>        input_data<span class="op">=</span>X_rnn_t,</span>
<span id="cb158-3"><a href="#cb158-3" aria-hidden="true" tabindex="-1"></a>        col_names<span class="op">=</span>[<span class="st">'input_size'</span>,</span>
<span id="cb158-4"><a href="#cb158-4" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'output_size'</span>,</span>
<span id="cb158-5"><a href="#cb158-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'num_params'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="105">
<pre><code>===================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #
===================================================================================================================
NYSEModel                                [1770, 5, 3]              [1770]                    --
â”œâ”€RNN: 1-1                               [1770, 5, 3]              [1770, 5, 12]             204
â”œâ”€Dropout: 1-2                           [1770, 12]                [1770, 12]                --
â”œâ”€Linear: 1-3                            [1770, 12]                [1770, 1]                 13
===================================================================================================================
Total params: 217
Trainable params: 217
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 1.83
===================================================================================================================
Input size (MB): 0.11
Forward/backward pass size (MB): 0.86
Params size (MB): 0.00
Estimated Total Size (MB): 0.97
===================================================================================================================</code></pre>
</div>
</div>
<p>We again put the two datasets into a data module, with a batch size of 64.</p>
<div id="4b88eca4" class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>nyse_dm <span class="op">=</span> SimpleDataModule(nyse_train,</span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a>                           nyse_test,</span>
<span id="cb160-3"><a href="#cb160-3" aria-hidden="true" tabindex="-1"></a>                           num_workers<span class="op">=</span><span class="bu">min</span>(<span class="dv">4</span>, max_num_workers),</span>
<span id="cb160-4"><a href="#cb160-4" aria-hidden="true" tabindex="-1"></a>                           validation<span class="op">=</span>nyse_test,</span>
<span id="cb160-5"><a href="#cb160-5" aria-hidden="true" tabindex="-1"></a>                           batch_size<span class="op">=</span><span class="dv">64</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We run some data through our model to be sure the sizes match up correctly.</p>
<div id="0e043e9c" class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, (x, y) <span class="kw">in</span> <span class="bu">enumerate</span>(nyse_dm.train_dataloader()):</span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> nyse_model(x)</span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(y.size(), out.size())</span>
<span id="cb161-4"><a href="#cb161-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> idx <span class="op">&gt;=</span> <span class="dv">2</span>:</span>
<span id="cb161-5"><a href="#cb161-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([64]) torch.Size([64])
torch.Size([64]) torch.Size([64])
torch.Size([64]) torch.Size([64])</code></pre>
</div>
</div>
<p>We follow our previous example for setting up a trainer for a regression problem, requesting the <span class="math inline">\(R^2\)</span> metric to be be computed at each epoch.</p>
<div id="ca5267d4" class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>nyse_optimizer <span class="op">=</span> RMSprop(nyse_model.parameters(),</span>
<span id="cb163-2"><a href="#cb163-2" aria-hidden="true" tabindex="-1"></a>                         lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb163-3"><a href="#cb163-3" aria-hidden="true" tabindex="-1"></a>nyse_module <span class="op">=</span> SimpleModule.regression(nyse_model,</span>
<span id="cb163-4"><a href="#cb163-4" aria-hidden="true" tabindex="-1"></a>                                      optimizer<span class="op">=</span>nyse_optimizer,</span>
<span id="cb163-5"><a href="#cb163-5" aria-hidden="true" tabindex="-1"></a>                                      metrics<span class="op">=</span>{<span class="st">'r2'</span>:R2Score()})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Fitting the model should by now be familiar. The results on the test data are very similar to the linear AR model.</p>
<div id="cd860181" class="cell" data-execution_count="109">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>nyse_trainer <span class="op">=</span> Trainer(deterministic<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a>                       max_epochs<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a>                       enable_progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a>                       callbacks<span class="op">=</span>[ErrorTracker()])</span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a>nyse_trainer.fit(nyse_module,</span>
<span id="cb164-6"><a href="#cb164-6" aria-hidden="true" tabindex="-1"></a>                 datamodule<span class="op">=</span>nyse_dm)</span>
<span id="cb164-7"><a href="#cb164-7" aria-hidden="true" tabindex="-1"></a>nyse_trainer.test(nyse_module,</span>
<span id="cb164-8"><a href="#cb164-8" aria-hidden="true" tabindex="-1"></a>                  datamodule<span class="op">=</span>nyse_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type      | Params | Mode 
--------------------------------------------
0 | model | NYSEModel | 217    | train
1 | loss  | MSELoss   | 0      | train
--------------------------------------------
217       Trainable params
0         Non-trainable params
217       Total params
0.001     Total estimated model params size (MB)
5         Modules in train mode
0         Modules in eval mode
`Trainer.fit` stopped: `max_epochs=200` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       Test metric             DataLoader 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        test_loss           0.6173513531684875
         test_r2            0.4141034483909607
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="109">
<pre><code>[{'test_loss': 0.6173513531684875, 'test_r2': 0.4141034483909607}]</code></pre>
</div>
</div>
<p>We could also fit a model without the <code>nn.RNN()</code> layer by just using a <code>nn.Flatten()</code> layer instead. This would be a nonlinear AR model. If in addition we excluded the hidden layer, this would be equivalent to our earlier linear AR model.</p>
<p>Instead we will fit a nonlinear AR model using the feature set <code>X_day</code> that includes the <code>day_of_week</code> indicators. To do so, we must first create our test and training datasets and a corresponding data module. This may seem a little burdensome, but is part of the general pipeline for <code>torch</code>.</p>
<div id="73785019" class="cell" data-execution_count="110">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>datasets <span class="op">=</span> []</span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> mask <span class="kw">in</span> [train, <span class="op">~</span>train]:</span>
<span id="cb168-3"><a href="#cb168-3" aria-hidden="true" tabindex="-1"></a>    X_day_t <span class="op">=</span> torch.tensor(</span>
<span id="cb168-4"><a href="#cb168-4" aria-hidden="true" tabindex="-1"></a>                   np.asarray(X_day[mask]).astype(np.float32))</span>
<span id="cb168-5"><a href="#cb168-5" aria-hidden="true" tabindex="-1"></a>    Y_t <span class="op">=</span> torch.tensor(np.asarray(Y[mask]).astype(np.float32))</span>
<span id="cb168-6"><a href="#cb168-6" aria-hidden="true" tabindex="-1"></a>    datasets.append(TensorDataset(X_day_t, Y_t))</span>
<span id="cb168-7"><a href="#cb168-7" aria-hidden="true" tabindex="-1"></a>day_train, day_test <span class="op">=</span> datasets</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Creating a data module follows a familiar pattern.</p>
<div id="9bd95a5a" class="cell" data-execution_count="111">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>day_dm <span class="op">=</span> SimpleDataModule(day_train,</span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a>                          day_test,</span>
<span id="cb169-3"><a href="#cb169-3" aria-hidden="true" tabindex="-1"></a>                          num_workers<span class="op">=</span><span class="bu">min</span>(<span class="dv">4</span>, max_num_workers),</span>
<span id="cb169-4"><a href="#cb169-4" aria-hidden="true" tabindex="-1"></a>                          validation<span class="op">=</span>day_test,</span>
<span id="cb169-5"><a href="#cb169-5" aria-hidden="true" tabindex="-1"></a>                          batch_size<span class="op">=</span><span class="dv">64</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We build a <code>NonLinearARModel()</code> that takes as input the 20 features and a hidden layer with 32 units. The remaining steps are familiar.</p>
<div id="0d0accdc" class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NonLinearARModel(nn.Module):</span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb170-3"><a href="#cb170-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(NonLinearARModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb170-4"><a href="#cb170-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._forward <span class="op">=</span> nn.Sequential(nn.Flatten(),</span>
<span id="cb170-5"><a href="#cb170-5" aria-hidden="true" tabindex="-1"></a>                                      nn.Linear(<span class="dv">20</span>, <span class="dv">32</span>),</span>
<span id="cb170-6"><a href="#cb170-6" aria-hidden="true" tabindex="-1"></a>                                      nn.ReLU(),</span>
<span id="cb170-7"><a href="#cb170-7" aria-hidden="true" tabindex="-1"></a>                                      nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb170-8"><a href="#cb170-8" aria-hidden="true" tabindex="-1"></a>                                      nn.Linear(<span class="dv">32</span>, <span class="dv">1</span>))</span>
<span id="cb170-9"><a href="#cb170-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb170-10"><a href="#cb170-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.flatten(<span class="va">self</span>._forward(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="069347fd" class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>nl_model <span class="op">=</span> NonLinearARModel()</span>
<span id="cb171-2"><a href="#cb171-2" aria-hidden="true" tabindex="-1"></a>nl_optimizer <span class="op">=</span> RMSprop(nl_model.parameters(),</span>
<span id="cb171-3"><a href="#cb171-3" aria-hidden="true" tabindex="-1"></a>                           lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb171-4"><a href="#cb171-4" aria-hidden="true" tabindex="-1"></a>nl_module <span class="op">=</span> SimpleModule.regression(nl_model,</span>
<span id="cb171-5"><a href="#cb171-5" aria-hidden="true" tabindex="-1"></a>                                        optimizer<span class="op">=</span>nl_optimizer,</span>
<span id="cb171-6"><a href="#cb171-6" aria-hidden="true" tabindex="-1"></a>                                        metrics<span class="op">=</span>{<span class="st">'r2'</span>:R2Score()})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We continue with the usual training steps, fit the model, and evaluate the test error. We see the test <span class="math inline">\(R^2\)</span> is a slight improvement over the linear AR model that also includes <code>day_of_week</code>.</p>
<div id="90069b35" class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a>nl_trainer <span class="op">=</span> Trainer(deterministic<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a>                         max_epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb172-3"><a href="#cb172-3" aria-hidden="true" tabindex="-1"></a>                         enable_progress_bar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb172-4"><a href="#cb172-4" aria-hidden="true" tabindex="-1"></a>                         callbacks<span class="op">=</span>[ErrorTracker()])</span>
<span id="cb172-5"><a href="#cb172-5" aria-hidden="true" tabindex="-1"></a>nl_trainer.fit(nl_module, datamodule<span class="op">=</span>day_dm)</span>
<span id="cb172-6"><a href="#cb172-6" aria-hidden="true" tabindex="-1"></a>nl_trainer.test(nl_module, datamodule<span class="op">=</span>day_dm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type             | Params | Mode 
---------------------------------------------------
0 | model | NonLinearARModel | 705    | train
1 | loss  | MSELoss          | 0      | train
---------------------------------------------------
705       Trainable params
0         Non-trainable params
705       Total params
0.003     Total estimated model params size (MB)
8         Modules in train mode
0         Modules in eval mode
`Trainer.fit` stopped: `max_epochs=20` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       Test metric             DataLoader 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        test_loss           0.5636991262435913
         test_r2            0.4650219678878784
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="114">
<pre><code>[{'test_loss': 0.5636991262435913, 'test_r2': 0.4650219678878784}]</code></pre>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ch9-svm-lab.html" class="pagination-link" aria-label="Lab Chapter 9: Support Vector Machines">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Lab Chapter 9: Support Vector Machines</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ch11-surv-lab.html" class="pagination-link" aria-label="Lab Chapter 11: Survival Analysis">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Lab Chapter 11: Survival Analysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, Juergen Jung</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://juejung.github.io/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>